Dataset: PDBbind v2018 with measurement KIKD
Clustering threshold: 0.3
Number of epochs: 30
Number of repeats: 10
Hyper-parameters: ['GNN_depth:4', 'inner_CNN_depth:2', 'DMA_depth:2', 'k_head:2', 'kernel_size:7', 'hidden_size1:128', 'hidden_size2:128']
/home/junseok/workspace/monn/src/pdbbind_utils.py:198: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  data_pack = [np.array(data) for data in data_pack]
setting: new_compound
fold 0 train  4699 test  1665 valid  625
fold 1 train  4895 test  1359 valid  735
fold 2 train  5005 test  1297 valid  687
fold 3 train  5050 test  1337 valid  602
fold 4 train  4994 test  1331 valid  664
repeat 1 fold 1 begin
train num: 4699 valid num: 625 test num: 1665
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 674.583637 affinity loss 14.738294 pairwise loss 6598.453491
train 4699 RMSE 2.2998 Pearson 0.563141 Spearman 0.577172 avg pairwise AUC 0.850422
valid 625 RMSE 2.14323 Pearson 0.465702 Spearman 0.496856 avg pairwise AUC 0.845251
test  1665 RMSE 2.239758 Pearson 0.536527 Spearman 0.558238 avg pairwise AUC 0.83188
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.230044 affinity loss 3.408945 pairwise loss 98.210988
valid 625 RMSE 1.750664 Pearson 0.54444 Spearman 0.55918 avg pairwise AUC 0.892798
test  1665 RMSE 1.726398 Pearson 0.57472 Spearman 0.587944 avg pairwise AUC 0.878558
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 12.212445 affinity loss 3.22786 pairwise loss 89.845852
valid 625 RMSE 1.705715 Pearson 0.539454 Spearman 0.544675 avg pairwise AUC 0.904112
test  1665 RMSE 1.834733 Pearson 0.59506 Spearman 0.607323 avg pairwise AUC 0.88756
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 11.126663 affinity loss 2.899898 pairwise loss 82.267647
valid 625 RMSE 1.633872 Pearson 0.56762 Spearman 0.57202 avg pairwise AUC 0.920458
test  1665 RMSE 1.634369 Pearson 0.596455 Spearman 0.613733 avg pairwise AUC 0.903747
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.277391 affinity loss 2.513897 pairwise loss 77.634934
valid 625 RMSE 1.577948 Pearson 0.588633 Spearman 0.585383 avg pairwise AUC 0.926413
test  1665 RMSE 1.675764 Pearson 0.623019 Spearman 0.637882 avg pairwise AUC 0.908283
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.705352 affinity loss 2.36497 pairwise loss 73.403814
valid 625 RMSE 1.500882 Pearson 0.597131 Spearman 0.595521 avg pairwise AUC 0.929877
test  1665 RMSE 1.530992 Pearson 0.635682 Spearman 0.653487 avg pairwise AUC 0.911262
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.309632 affinity loss 2.288991 pairwise loss 70.206408
valid 625 RMSE 1.434739 Pearson 0.62876 Spearman 0.62902 avg pairwise AUC 0.932389
test  1665 RMSE 1.520509 Pearson 0.635451 Spearman 0.65594 avg pairwise AUC 0.913912
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.042613 affinity loss 2.232821 pairwise loss 68.097924
valid 625 RMSE 1.553601 Pearson 0.588794 Spearman 0.585534 avg pairwise AUC 0.934396
test  1665 RMSE 1.520509 Pearson 0.635451 Spearman 0.65594 avg pairwise AUC 0.913912
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.561475 affinity loss 2.003773 pairwise loss 65.577022
valid 625 RMSE 1.516326 Pearson 0.631237 Spearman 0.628395 avg pairwise AUC 0.937393
test  1665 RMSE 1.520509 Pearson 0.635451 Spearman 0.65594 avg pairwise AUC 0.913912
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.36649 affinity loss 1.929585 pairwise loss 64.369053
valid 625 RMSE 1.513096 Pearson 0.621703 Spearman 0.615481 avg pairwise AUC 0.937839
test  1665 RMSE 1.520509 Pearson 0.635451 Spearman 0.65594 avg pairwise AUC 0.913912
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.032536 affinity loss 1.705006 pairwise loss 63.275292
train 4699 RMSE 1.207829 Pearson 0.83288 Spearman 0.831431 avg pairwise AUC 0.973589
valid 625 RMSE 1.464999 Pearson 0.629186 Spearman 0.632251 avg pairwise AUC 0.939351
test  1665 RMSE 1.520509 Pearson 0.635451 Spearman 0.65594 avg pairwise AUC 0.913912
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 7.742276 affinity loss 1.587053 pairwise loss 61.552227
valid 625 RMSE 1.80183 Pearson 0.606409 Spearman 0.607646 avg pairwise AUC 0.939385
test  1665 RMSE 1.520509 Pearson 0.635451 Spearman 0.65594 avg pairwise AUC 0.913912
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.569808 affinity loss 1.561255 pairwise loss 60.085532
valid 625 RMSE 1.512993 Pearson 0.632739 Spearman 0.62534 avg pairwise AUC 0.939971
test  1665 RMSE 1.520509 Pearson 0.635451 Spearman 0.65594 avg pairwise AUC 0.913912
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.304136 affinity loss 1.45624 pairwise loss 58.478956
valid 625 RMSE 1.403489 Pearson 0.617595 Spearman 0.609065 avg pairwise AUC 0.941732
test  1665 RMSE 1.506152 Pearson 0.644765 Spearman 0.656285 avg pairwise AUC 0.919411
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.160645 affinity loss 1.388907 pairwise loss 57.717383
valid 625 RMSE 1.53459 Pearson 0.646064 Spearman 0.635542 avg pairwise AUC 0.942716
test  1665 RMSE 1.506152 Pearson 0.644765 Spearman 0.656285 avg pairwise AUC 0.919411
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.033929 affinity loss 1.306405 pairwise loss 57.275241
valid 625 RMSE 1.409735 Pearson 0.636747 Spearman 0.622261 avg pairwise AUC 0.942218
test  1665 RMSE 1.506152 Pearson 0.644765 Spearman 0.656285 avg pairwise AUC 0.919411
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 6.915113 affinity loss 1.272922 pairwise loss 56.421909
valid 625 RMSE 1.697256 Pearson 0.641373 Spearman 0.63748 avg pairwise AUC 0.94245
test  1665 RMSE 1.506152 Pearson 0.644765 Spearman 0.656285 avg pairwise AUC 0.919411
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.824327 affinity loss 1.256829 pairwise loss 55.67497
valid 625 RMSE 1.476479 Pearson 0.631022 Spearman 0.621223 avg pairwise AUC 0.942977
test  1665 RMSE 1.506152 Pearson 0.644765 Spearman 0.656285 avg pairwise AUC 0.919411
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.571068 affinity loss 1.112224 pairwise loss 54.588442
valid 625 RMSE 1.44295 Pearson 0.652401 Spearman 0.641287 avg pairwise AUC 0.943864
test  1665 RMSE 1.506152 Pearson 0.644765 Spearman 0.656285 avg pairwise AUC 0.919411
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.078994 affinity loss 0.902865 pairwise loss 51.761297
valid 625 RMSE 1.455696 Pearson 0.655049 Spearman 0.6439 avg pairwise AUC 0.945265
test  1665 RMSE 1.506152 Pearson 0.644765 Spearman 0.656285 avg pairwise AUC 0.919411
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 5.859359 affinity loss 0.862863 pairwise loss 49.964959
train 4699 RMSE 0.824285 Pearson 0.919129 Spearman 0.915973 avg pairwise AUC 0.988455
valid 625 RMSE 1.41916 Pearson 0.65155 Spearman 0.633745 avg pairwise AUC 0.945344
test  1665 RMSE 1.506152 Pearson 0.644765 Spearman 0.656285 avg pairwise AUC 0.919411
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.706119 affinity loss 0.776696 pairwise loss 49.294229
valid 625 RMSE 1.438581 Pearson 0.637301 Spearman 0.624435 avg pairwise AUC 0.946336
test  1665 RMSE 1.506152 Pearson 0.644765 Spearman 0.656285 avg pairwise AUC 0.919411
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.650552 affinity loss 0.8153 pairwise loss 48.352528
valid 625 RMSE 1.417685 Pearson 0.64791 Spearman 0.631169 avg pairwise AUC 0.945775
test  1665 RMSE 1.506152 Pearson 0.644765 Spearman 0.656285 avg pairwise AUC 0.919411
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.542803 affinity loss 0.741571 pairwise loss 48.012317
valid 625 RMSE 1.487403 Pearson 0.633376 Spearman 0.620785 avg pairwise AUC 0.945595
test  1665 RMSE 1.506152 Pearson 0.644765 Spearman 0.656285 avg pairwise AUC 0.919411
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.384653 affinity loss 0.654975 pairwise loss 47.296777
valid 625 RMSE 1.472406 Pearson 0.645082 Spearman 0.631644 avg pairwise AUC 0.946722
test  1665 RMSE 1.506152 Pearson 0.644765 Spearman 0.656285 avg pairwise AUC 0.919411
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.391417 affinity loss 0.681967 pairwise loss 47.094498
valid 625 RMSE 1.499831 Pearson 0.629912 Spearman 0.623599 avg pairwise AUC 0.94599
test  1665 RMSE 1.506152 Pearson 0.644765 Spearman 0.656285 avg pairwise AUC 0.919411
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.228368 affinity loss 0.60127 pairwise loss 46.270976
valid 625 RMSE 1.472263 Pearson 0.64274 Spearman 0.634601 avg pairwise AUC 0.947374
test  1665 RMSE 1.506152 Pearson 0.644765 Spearman 0.656285 avg pairwise AUC 0.919411
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.135894 affinity loss 0.558096 pairwise loss 45.777985
valid 625 RMSE 1.478965 Pearson 0.643719 Spearman 0.633466 avg pairwise AUC 0.947763
test  1665 RMSE 1.506152 Pearson 0.644765 Spearman 0.656285 avg pairwise AUC 0.919411
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.04593 affinity loss 0.535113 pairwise loss 45.108161
valid 625 RMSE 1.5086 Pearson 0.622118 Spearman 0.610224 avg pairwise AUC 0.947059
test  1665 RMSE 1.506152 Pearson 0.644765 Spearman 0.656285 avg pairwise AUC 0.919411
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 4.972085 affinity loss 0.517918 pairwise loss 44.54167
valid 625 RMSE 1.483614 Pearson 0.632621 Spearman 0.626217 avg pairwise AUC 0.947279
test  1665 RMSE 1.506152 Pearson 0.644765 Spearman 0.656285 avg pairwise AUC 0.919411
Finished Training
------------------------------
repeat 1 fold 2 begin
train num: 4895 valid num: 735 test num: 1359
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 947.075966 affinity loss 7.346787 pairwise loss 9397.291036
train 4895 RMSE 1.677769 Pearson 0.587683 Spearman 0.58756 avg pairwise AUC 0.848101
valid 735 RMSE 1.646039 Pearson 0.590358 Spearman 0.617049 avg pairwise AUC 0.826784
test  1359 RMSE 1.71398 Pearson 0.518796 Spearman 0.523351 avg pairwise AUC 0.838256
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.351232 affinity loss 3.237237 pairwise loss 101.139946
valid 735 RMSE 1.616838 Pearson 0.630606 Spearman 0.651266 avg pairwise AUC 0.878233
test  1359 RMSE 1.733125 Pearson 0.564385 Spearman 0.575536 avg pairwise AUC 0.88837
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 12.04911 affinity loss 2.857386 pairwise loss 91.917243
valid 735 RMSE 1.733589 Pearson 0.634155 Spearman 0.662379 avg pairwise AUC 0.902915
test  1359 RMSE 1.733125 Pearson 0.564385 Spearman 0.575536 avg pairwise AUC 0.88837
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 11.097196 affinity loss 2.655154 pairwise loss 84.420425
valid 735 RMSE 1.553512 Pearson 0.638904 Spearman 0.667489 avg pairwise AUC 0.910756
test  1359 RMSE 1.656383 Pearson 0.573047 Spearman 0.591846 avg pairwise AUC 0.920601
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.502883 affinity loss 2.406795 pairwise loss 80.960877
valid 735 RMSE 1.86458 Pearson 0.658182 Spearman 0.678107 avg pairwise AUC 0.917065
test  1359 RMSE 1.656383 Pearson 0.573047 Spearman 0.591846 avg pairwise AUC 0.920601
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 10.0915 affinity loss 2.498833 pairwise loss 75.926665
valid 735 RMSE 1.515616 Pearson 0.667688 Spearman 0.693888 avg pairwise AUC 0.92
test  1359 RMSE 1.578912 Pearson 0.623367 Spearman 0.635327 avg pairwise AUC 0.928374
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.565416 affinity loss 2.227966 pairwise loss 73.3745
valid 735 RMSE 1.652818 Pearson 0.662621 Spearman 0.679053 avg pairwise AUC 0.923621
test  1359 RMSE 1.578912 Pearson 0.623367 Spearman 0.635327 avg pairwise AUC 0.928374
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.07913 affinity loss 2.058341 pairwise loss 70.207886
valid 735 RMSE 1.525481 Pearson 0.670175 Spearman 0.686243 avg pairwise AUC 0.926319
test  1359 RMSE 1.578912 Pearson 0.623367 Spearman 0.635327 avg pairwise AUC 0.928374
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.613813 affinity loss 1.915094 pairwise loss 66.987188
valid 735 RMSE 1.482071 Pearson 0.677934 Spearman 0.692955 avg pairwise AUC 0.928167
test  1359 RMSE 1.543411 Pearson 0.636859 Spearman 0.656547 avg pairwise AUC 0.937126
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.33777 affinity loss 1.816035 pairwise loss 65.217348
valid 735 RMSE 1.522236 Pearson 0.685707 Spearman 0.701404 avg pairwise AUC 0.927117
test  1359 RMSE 1.543411 Pearson 0.636859 Spearman 0.656547 avg pairwise AUC 0.937126
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.177965 affinity loss 1.788556 pairwise loss 63.89409
train 4895 RMSE 1.343336 Pearson 0.823799 Spearman 0.823637 avg pairwise AUC 0.974707
valid 735 RMSE 1.553093 Pearson 0.70852 Spearman 0.720575 avg pairwise AUC 0.931171
test  1359 RMSE 1.543411 Pearson 0.636859 Spearman 0.656547 avg pairwise AUC 0.937126
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 7.867911 affinity loss 1.600576 pairwise loss 62.673349
valid 735 RMSE 1.520898 Pearson 0.714941 Spearman 0.727231 avg pairwise AUC 0.929955
test  1359 RMSE 1.543411 Pearson 0.636859 Spearman 0.656547 avg pairwise AUC 0.937126
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.574962 affinity loss 1.409658 pairwise loss 61.653035
valid 735 RMSE 1.40814 Pearson 0.719187 Spearman 0.728752 avg pairwise AUC 0.929771
test  1359 RMSE 1.492691 Pearson 0.674568 Spearman 0.67708 avg pairwise AUC 0.94055
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.434382 affinity loss 1.43869 pairwise loss 59.956919
valid 735 RMSE 1.495074 Pearson 0.685752 Spearman 0.693759 avg pairwise AUC 0.931797
test  1359 RMSE 1.492691 Pearson 0.674568 Spearman 0.67708 avg pairwise AUC 0.94055
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.264566 affinity loss 1.402871 pairwise loss 58.616945
valid 735 RMSE 1.435148 Pearson 0.705662 Spearman 0.712393 avg pairwise AUC 0.931125
test  1359 RMSE 1.492691 Pearson 0.674568 Spearman 0.67708 avg pairwise AUC 0.94055
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.103403 affinity loss 1.264771 pairwise loss 58.386327
valid 735 RMSE 1.472143 Pearson 0.685029 Spearman 0.691289 avg pairwise AUC 0.931829
test  1359 RMSE 1.492691 Pearson 0.674568 Spearman 0.67708 avg pairwise AUC 0.94055
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 6.985864 affinity loss 1.249378 pairwise loss 57.364854
valid 735 RMSE 1.440772 Pearson 0.707087 Spearman 0.714607 avg pairwise AUC 0.931889
test  1359 RMSE 1.492691 Pearson 0.674568 Spearman 0.67708 avg pairwise AUC 0.94055
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.741673 affinity loss 1.134825 pairwise loss 56.068478
valid 735 RMSE 1.486523 Pearson 0.684182 Spearman 0.694639 avg pairwise AUC 0.931017
test  1359 RMSE 1.492691 Pearson 0.674568 Spearman 0.67708 avg pairwise AUC 0.94055
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.660013 affinity loss 1.080829 pairwise loss 55.791836
valid 735 RMSE 1.614426 Pearson 0.711024 Spearman 0.721191 avg pairwise AUC 0.93349
test  1359 RMSE 1.492691 Pearson 0.674568 Spearman 0.67708 avg pairwise AUC 0.94055
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.073839 affinity loss 0.861125 pairwise loss 52.127138
valid 735 RMSE 1.474941 Pearson 0.700213 Spearman 0.705482 avg pairwise AUC 0.934251
test  1359 RMSE 1.492691 Pearson 0.674568 Spearman 0.67708 avg pairwise AUC 0.94055
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 5.850616 affinity loss 0.792789 pairwise loss 50.578275
train 4895 RMSE 0.888333 Pearson 0.919199 Spearman 0.918396 avg pairwise AUC 0.988783
valid 735 RMSE 1.487492 Pearson 0.70923 Spearman 0.710857 avg pairwise AUC 0.933175
test  1359 RMSE 1.492691 Pearson 0.674568 Spearman 0.67708 avg pairwise AUC 0.94055
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.720034 affinity loss 0.751805 pairwise loss 49.682285
valid 735 RMSE 1.456067 Pearson 0.713496 Spearman 0.717265 avg pairwise AUC 0.931865
test  1359 RMSE 1.492691 Pearson 0.674568 Spearman 0.67708 avg pairwise AUC 0.94055
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.604766 affinity loss 0.721077 pairwise loss 48.836887
valid 735 RMSE 1.465413 Pearson 0.713182 Spearman 0.716155 avg pairwise AUC 0.933515
test  1359 RMSE 1.492691 Pearson 0.674568 Spearman 0.67708 avg pairwise AUC 0.94055
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.52896 affinity loss 0.689115 pairwise loss 48.39845
valid 735 RMSE 1.463684 Pearson 0.709484 Spearman 0.715893 avg pairwise AUC 0.934005
test  1359 RMSE 1.492691 Pearson 0.674568 Spearman 0.67708 avg pairwise AUC 0.94055
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.445619 affinity loss 0.6875 pairwise loss 47.581192
valid 735 RMSE 1.451319 Pearson 0.715962 Spearman 0.717161 avg pairwise AUC 0.932415
test  1359 RMSE 1.492691 Pearson 0.674568 Spearman 0.67708 avg pairwise AUC 0.94055
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.33277 affinity loss 0.60685 pairwise loss 47.259196
valid 735 RMSE 1.452447 Pearson 0.707199 Spearman 0.708455 avg pairwise AUC 0.932391
test  1359 RMSE 1.492691 Pearson 0.674568 Spearman 0.67708 avg pairwise AUC 0.94055
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.256483 affinity loss 0.588116 pairwise loss 46.683668
valid 735 RMSE 1.49811 Pearson 0.697899 Spearman 0.698103 avg pairwise AUC 0.931471
test  1359 RMSE 1.492691 Pearson 0.674568 Spearman 0.67708 avg pairwise AUC 0.94055
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.163495 affinity loss 0.573603 pairwise loss 45.898911
valid 735 RMSE 1.497174 Pearson 0.705895 Spearman 0.707208 avg pairwise AUC 0.932447
test  1359 RMSE 1.492691 Pearson 0.674568 Spearman 0.67708 avg pairwise AUC 0.94055
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.128399 affinity loss 0.562626 pairwise loss 45.65773
valid 735 RMSE 1.448404 Pearson 0.714235 Spearman 0.714715 avg pairwise AUC 0.932023
test  1359 RMSE 1.492691 Pearson 0.674568 Spearman 0.67708 avg pairwise AUC 0.94055
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.01693 affinity loss 0.524806 pairwise loss 44.921242
valid 735 RMSE 1.46888 Pearson 0.70567 Spearman 0.70845 avg pairwise AUC 0.931923
test  1359 RMSE 1.492691 Pearson 0.674568 Spearman 0.67708 avg pairwise AUC 0.94055
Finished Training
------------------------------
repeat 1 fold 3 begin
train num: 5005 valid num: 687 test num: 1297
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 4118.945412 affinity loss 10.411261 pairwise loss 41085.341687
train 5005 RMSE 1.8575 Pearson 0.576295 Spearman 0.596871 avg pairwise AUC 0.848101
valid 687 RMSE 1.771082 Pearson 0.545669 Spearman 0.536115 avg pairwise AUC 0.825347
test  1297 RMSE 1.932633 Pearson 0.595082 Spearman 0.613627 avg pairwise AUC 0.838606
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.256745 affinity loss 3.123293 pairwise loss 101.33451
valid 687 RMSE 1.69827 Pearson 0.574868 Spearman 0.571727 avg pairwise AUC 0.869005
test  1297 RMSE 1.762206 Pearson 0.589332 Spearman 0.606245 avg pairwise AUC 0.881712
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 12.347089 affinity loss 2.972394 pairwise loss 93.746944
valid 687 RMSE 2.162527 Pearson 0.579964 Spearman 0.564166 avg pairwise AUC 0.89158
test  1297 RMSE 1.762206 Pearson 0.589332 Spearman 0.606245 avg pairwise AUC 0.881712
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 11.275018 affinity loss 2.601564 pairwise loss 86.734539
valid 687 RMSE 1.558172 Pearson 0.621352 Spearman 0.607512 avg pairwise AUC 0.908156
test  1297 RMSE 1.602256 Pearson 0.659285 Spearman 0.6613 avg pairwise AUC 0.909377
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.664665 affinity loss 2.583446 pairwise loss 80.812196
valid 687 RMSE 1.53952 Pearson 0.609262 Spearman 0.619863 avg pairwise AUC 0.914841
test  1297 RMSE 1.612596 Pearson 0.661845 Spearman 0.663516 avg pairwise AUC 0.918649
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.949535 affinity loss 2.407343 pairwise loss 75.421924
valid 687 RMSE 1.501173 Pearson 0.632862 Spearman 0.62968 avg pairwise AUC 0.917479
test  1297 RMSE 1.579652 Pearson 0.672551 Spearman 0.676558 avg pairwise AUC 0.922042
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.653165 affinity loss 2.414678 pairwise loss 72.384868
valid 687 RMSE 1.472152 Pearson 0.651634 Spearman 0.646723 avg pairwise AUC 0.922514
test  1297 RMSE 1.548085 Pearson 0.69302 Spearman 0.693323 avg pairwise AUC 0.925243
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.149536 affinity loss 2.151286 pairwise loss 69.982497
valid 687 RMSE 1.482019 Pearson 0.657459 Spearman 0.657468 avg pairwise AUC 0.924449
test  1297 RMSE 1.548085 Pearson 0.69302 Spearman 0.693323 avg pairwise AUC 0.925243
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.922714 affinity loss 2.090754 pairwise loss 68.319602
valid 687 RMSE 1.518691 Pearson 0.661869 Spearman 0.665189 avg pairwise AUC 0.92663
test  1297 RMSE 1.548085 Pearson 0.69302 Spearman 0.693323 avg pairwise AUC 0.925243
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.477358 affinity loss 1.880119 pairwise loss 65.972387
valid 687 RMSE 1.554905 Pearson 0.680304 Spearman 0.67926 avg pairwise AUC 0.926403
test  1297 RMSE 1.548085 Pearson 0.69302 Spearman 0.693323 avg pairwise AUC 0.925243
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.214001 affinity loss 1.790539 pairwise loss 64.234617
train 5005 RMSE 1.190215 Pearson 0.813539 Spearman 0.824749 avg pairwise AUC 0.97434
valid 687 RMSE 1.429618 Pearson 0.673423 Spearman 0.679194 avg pairwise AUC 0.929628
test  1297 RMSE 1.480674 Pearson 0.710402 Spearman 0.706843 avg pairwise AUC 0.93169
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 8.001864 affinity loss 1.70067 pairwise loss 63.011938
valid 687 RMSE 1.402628 Pearson 0.690064 Spearman 0.687368 avg pairwise AUC 0.929221
test  1297 RMSE 1.461776 Pearson 0.7213 Spearman 0.713519 avg pairwise AUC 0.932554
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.757872 affinity loss 1.516759 pairwise loss 62.411129
valid 687 RMSE 1.415332 Pearson 0.701807 Spearman 0.690477 avg pairwise AUC 0.928299
test  1297 RMSE 1.461776 Pearson 0.7213 Spearman 0.713519 avg pairwise AUC 0.932554
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.514258 affinity loss 1.458924 pairwise loss 60.553345
valid 687 RMSE 1.382654 Pearson 0.702008 Spearman 0.698199 avg pairwise AUC 0.929446
test  1297 RMSE 1.499109 Pearson 0.709979 Spearman 0.706711 avg pairwise AUC 0.931811
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.342065 affinity loss 1.370636 pairwise loss 59.714288
valid 687 RMSE 1.373853 Pearson 0.706052 Spearman 0.698614 avg pairwise AUC 0.9299
test  1297 RMSE 1.457346 Pearson 0.721436 Spearman 0.71305 avg pairwise AUC 0.930907
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.134714 affinity loss 1.267279 pairwise loss 58.674351
valid 687 RMSE 1.391986 Pearson 0.705463 Spearman 0.692554 avg pairwise AUC 0.933348
test  1297 RMSE 1.457346 Pearson 0.721436 Spearman 0.71305 avg pairwise AUC 0.930907
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 7.001664 affinity loss 1.255664 pairwise loss 57.46
valid 687 RMSE 1.443281 Pearson 0.702239 Spearman 0.684487 avg pairwise AUC 0.933799
test  1297 RMSE 1.457346 Pearson 0.721436 Spearman 0.71305 avg pairwise AUC 0.930907
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.876288 affinity loss 1.206381 pairwise loss 56.699066
valid 687 RMSE 1.677565 Pearson 0.701003 Spearman 0.68401 avg pairwise AUC 0.934046
test  1297 RMSE 1.457346 Pearson 0.721436 Spearman 0.71305 avg pairwise AUC 0.930907
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.790496 affinity loss 1.192141 pairwise loss 55.98355
valid 687 RMSE 1.452882 Pearson 0.694212 Spearman 0.687069 avg pairwise AUC 0.93655
test  1297 RMSE 1.457346 Pearson 0.721436 Spearman 0.71305 avg pairwise AUC 0.930907
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.222724 affinity loss 0.92204 pairwise loss 53.006833
valid 687 RMSE 1.398289 Pearson 0.712948 Spearman 0.696922 avg pairwise AUC 0.937126
test  1297 RMSE 1.457346 Pearson 0.721436 Spearman 0.71305 avg pairwise AUC 0.930907
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 6.003703 affinity loss 0.831976 pairwise loss 51.717269
train 5005 RMSE 0.868445 Pearson 0.912629 Spearman 0.912326 avg pairwise AUC 0.988525
valid 687 RMSE 1.393755 Pearson 0.715243 Spearman 0.704212 avg pairwise AUC 0.936921
test  1297 RMSE 1.457346 Pearson 0.721436 Spearman 0.71305 avg pairwise AUC 0.930907
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.839598 affinity loss 0.776295 pairwise loss 50.633037
valid 687 RMSE 1.42359 Pearson 0.71355 Spearman 0.70244 avg pairwise AUC 0.93743
test  1297 RMSE 1.457346 Pearson 0.721436 Spearman 0.71305 avg pairwise AUC 0.930907
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.728007 affinity loss 0.734391 pairwise loss 49.936154
valid 687 RMSE 1.419146 Pearson 0.705827 Spearman 0.690923 avg pairwise AUC 0.936944
test  1297 RMSE 1.457346 Pearson 0.721436 Spearman 0.71305 avg pairwise AUC 0.930907
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.642583 affinity loss 0.715651 pairwise loss 49.269322
valid 687 RMSE 1.391008 Pearson 0.709631 Spearman 0.690153 avg pairwise AUC 0.937219
test  1297 RMSE 1.457346 Pearson 0.721436 Spearman 0.71305 avg pairwise AUC 0.930907
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.539217 affinity loss 0.676173 pairwise loss 48.630443
valid 687 RMSE 1.457119 Pearson 0.707281 Spearman 0.694412 avg pairwise AUC 0.936674
test  1297 RMSE 1.457346 Pearson 0.721436 Spearman 0.71305 avg pairwise AUC 0.930907
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.455939 affinity loss 0.642935 pairwise loss 48.130038
valid 687 RMSE 1.416177 Pearson 0.714024 Spearman 0.699329 avg pairwise AUC 0.938617
test  1297 RMSE 1.457346 Pearson 0.721436 Spearman 0.71305 avg pairwise AUC 0.930907
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.389307 affinity loss 0.620164 pairwise loss 47.691434
valid 687 RMSE 1.430278 Pearson 0.707356 Spearman 0.698772 avg pairwise AUC 0.937858
test  1297 RMSE 1.457346 Pearson 0.721436 Spearman 0.71305 avg pairwise AUC 0.930907
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.311998 affinity loss 0.610198 pairwise loss 47.018001
valid 687 RMSE 1.420231 Pearson 0.697715 Spearman 0.678846 avg pairwise AUC 0.934626
test  1297 RMSE 1.457346 Pearson 0.721436 Spearman 0.71305 avg pairwise AUC 0.930907
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.246854 affinity loss 0.571252 pairwise loss 46.756016
valid 687 RMSE 1.398659 Pearson 0.705512 Spearman 0.692911 avg pairwise AUC 0.935757
test  1297 RMSE 1.457346 Pearson 0.721436 Spearman 0.71305 avg pairwise AUC 0.930907
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.161873 affinity loss 0.527911 pairwise loss 46.339619
valid 687 RMSE 1.466878 Pearson 0.706137 Spearman 0.696458 avg pairwise AUC 0.934876
test  1297 RMSE 1.457346 Pearson 0.721436 Spearman 0.71305 avg pairwise AUC 0.930907
Finished Training
------------------------------
repeat 1 fold 4 begin
train num: 5050 valid num: 602 test num: 1337
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 2370.259947 affinity loss 9.628928 pairwise loss 23606.310237
train 5050 RMSE 1.652541 Pearson 0.58726 Spearman 0.59666 avg pairwise AUC 0.860394
valid 602 RMSE 1.808274 Pearson 0.472132 Spearman 0.493375 avg pairwise AUC 0.842726
test  1337 RMSE 1.637045 Pearson 0.56834 Spearman 0.554422 avg pairwise AUC 0.84805
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 12.824044 affinity loss 2.941837 pairwise loss 98.822066
valid 602 RMSE 1.783796 Pearson 0.512194 Spearman 0.537242 avg pairwise AUC 0.885573
test  1337 RMSE 1.603281 Pearson 0.609225 Spearman 0.596745 avg pairwise AUC 0.892439
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 11.777464 affinity loss 2.80598 pairwise loss 89.714835
valid 602 RMSE 1.826575 Pearson 0.533305 Spearman 0.557917 avg pairwise AUC 0.902312
test  1337 RMSE 1.603281 Pearson 0.609225 Spearman 0.596745 avg pairwise AUC 0.892439
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 10.954441 affinity loss 2.595172 pairwise loss 83.592687
valid 602 RMSE 1.680738 Pearson 0.559722 Spearman 0.580755 avg pairwise AUC 0.909515
test  1337 RMSE 1.530591 Pearson 0.642355 Spearman 0.63115 avg pairwise AUC 0.917179
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.290221 affinity loss 2.501949 pairwise loss 77.882716
valid 602 RMSE 2.175893 Pearson 0.551925 Spearman 0.588884 avg pairwise AUC 0.917076
test  1337 RMSE 1.530591 Pearson 0.642355 Spearman 0.63115 avg pairwise AUC 0.917179
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.887618 affinity loss 2.341897 pairwise loss 75.457212
valid 602 RMSE 1.709056 Pearson 0.575385 Spearman 0.596656 avg pairwise AUC 0.921074
test  1337 RMSE 1.530591 Pearson 0.642355 Spearman 0.63115 avg pairwise AUC 0.917179
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.337725 affinity loss 2.189997 pairwise loss 71.477277
valid 602 RMSE 1.671735 Pearson 0.604936 Spearman 0.634729 avg pairwise AUC 0.923346
test  1337 RMSE 1.546659 Pearson 0.673978 Spearman 0.66299 avg pairwise AUC 0.929778
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.037952 affinity loss 2.057589 pairwise loss 69.803625
valid 602 RMSE 1.710135 Pearson 0.612437 Spearman 0.633824 avg pairwise AUC 0.92389
test  1337 RMSE 1.546659 Pearson 0.673978 Spearman 0.66299 avg pairwise AUC 0.929778
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.690177 affinity loss 1.892234 pairwise loss 67.979432
valid 602 RMSE 1.614102 Pearson 0.626004 Spearman 0.658925 avg pairwise AUC 0.925533
test  1337 RMSE 1.486304 Pearson 0.691912 Spearman 0.680714 avg pairwise AUC 0.93303
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.341381 affinity loss 1.760683 pairwise loss 65.806976
valid 602 RMSE 1.623559 Pearson 0.638147 Spearman 0.659387 avg pairwise AUC 0.927221
test  1337 RMSE 1.486304 Pearson 0.691912 Spearman 0.680714 avg pairwise AUC 0.93303
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.183247 affinity loss 1.65776 pairwise loss 65.254871
train 5050 RMSE 1.182369 Pearson 0.830464 Spearman 0.83218 avg pairwise AUC 0.972438
valid 602 RMSE 1.679321 Pearson 0.618002 Spearman 0.633293 avg pairwise AUC 0.927497
test  1337 RMSE 1.486304 Pearson 0.691912 Spearman 0.680714 avg pairwise AUC 0.93303
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 7.892169 affinity loss 1.535853 pairwise loss 63.563153
valid 602 RMSE 1.545644 Pearson 0.656736 Spearman 0.673129 avg pairwise AUC 0.927875
test  1337 RMSE 1.409778 Pearson 0.711697 Spearman 0.691076 avg pairwise AUC 0.934147
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.662871 affinity loss 1.432897 pairwise loss 62.299742
valid 602 RMSE 1.66665 Pearson 0.601024 Spearman 0.616441 avg pairwise AUC 0.928203
test  1337 RMSE 1.409778 Pearson 0.711697 Spearman 0.691076 avg pairwise AUC 0.934147
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.465125 affinity loss 1.345576 pairwise loss 61.19549
valid 602 RMSE 1.609958 Pearson 0.632622 Spearman 0.651833 avg pairwise AUC 0.930848
test  1337 RMSE 1.409778 Pearson 0.711697 Spearman 0.691076 avg pairwise AUC 0.934147
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.327772 affinity loss 1.315 pairwise loss 60.127716
valid 602 RMSE 1.645366 Pearson 0.639564 Spearman 0.650873 avg pairwise AUC 0.932598
test  1337 RMSE 1.409778 Pearson 0.711697 Spearman 0.691076 avg pairwise AUC 0.934147
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.173985 affinity loss 1.254763 pairwise loss 59.192219
valid 602 RMSE 1.675207 Pearson 0.636728 Spearman 0.652717 avg pairwise AUC 0.931322
test  1337 RMSE 1.409778 Pearson 0.711697 Spearman 0.691076 avg pairwise AUC 0.934147
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 6.956486 affinity loss 1.160486 pairwise loss 57.960002
valid 602 RMSE 1.607036 Pearson 0.654627 Spearman 0.666249 avg pairwise AUC 0.931889
test  1337 RMSE 1.409778 Pearson 0.711697 Spearman 0.691076 avg pairwise AUC 0.934147
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.82309 affinity loss 1.062762 pairwise loss 57.603287
valid 602 RMSE 1.636706 Pearson 0.628806 Spearman 0.638574 avg pairwise AUC 0.931911
test  1337 RMSE 1.409778 Pearson 0.711697 Spearman 0.691076 avg pairwise AUC 0.934147
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.710844 affinity loss 1.086996 pairwise loss 56.238473
valid 602 RMSE 1.583701 Pearson 0.649192 Spearman 0.664388 avg pairwise AUC 0.93423
test  1337 RMSE 1.409778 Pearson 0.711697 Spearman 0.691076 avg pairwise AUC 0.934147
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.183164 affinity loss 0.846693 pairwise loss 53.364704
valid 602 RMSE 1.60278 Pearson 0.648208 Spearman 0.657357 avg pairwise AUC 0.935299
test  1337 RMSE 1.409778 Pearson 0.711697 Spearman 0.691076 avg pairwise AUC 0.934147
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 5.955943 affinity loss 0.765917 pairwise loss 51.900266
train 5050 RMSE 0.844688 Pearson 0.920343 Spearman 0.921512 avg pairwise AUC 0.987225
valid 602 RMSE 1.600948 Pearson 0.659976 Spearman 0.670797 avg pairwise AUC 0.935335
test  1337 RMSE 1.409778 Pearson 0.711697 Spearman 0.691076 avg pairwise AUC 0.934147
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.833724 affinity loss 0.732706 pairwise loss 51.010182
valid 602 RMSE 1.588656 Pearson 0.646481 Spearman 0.663851 avg pairwise AUC 0.934782
test  1337 RMSE 1.409778 Pearson 0.711697 Spearman 0.691076 avg pairwise AUC 0.934147
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.727228 affinity loss 0.711821 pairwise loss 50.15407
valid 602 RMSE 1.607223 Pearson 0.649535 Spearman 0.659555 avg pairwise AUC 0.935701
test  1337 RMSE 1.409778 Pearson 0.711697 Spearman 0.691076 avg pairwise AUC 0.934147
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.636818 affinity loss 0.650777 pairwise loss 49.860409
valid 602 RMSE 1.590244 Pearson 0.660198 Spearman 0.676191 avg pairwise AUC 0.935664
test  1337 RMSE 1.409778 Pearson 0.711697 Spearman 0.691076 avg pairwise AUC 0.934147
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.555442 affinity loss 0.642455 pairwise loss 49.129876
valid 602 RMSE 1.573981 Pearson 0.656498 Spearman 0.671324 avg pairwise AUC 0.935164
test  1337 RMSE 1.409778 Pearson 0.711697 Spearman 0.691076 avg pairwise AUC 0.934147
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.441769 affinity loss 0.600502 pairwise loss 48.412673
valid 602 RMSE 1.595783 Pearson 0.648561 Spearman 0.661133 avg pairwise AUC 0.93513
test  1337 RMSE 1.409778 Pearson 0.711697 Spearman 0.691076 avg pairwise AUC 0.934147
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.396794 affinity loss 0.596821 pairwise loss 47.99973
valid 602 RMSE 1.591438 Pearson 0.647923 Spearman 0.658351 avg pairwise AUC 0.93564
test  1337 RMSE 1.409778 Pearson 0.711697 Spearman 0.691076 avg pairwise AUC 0.934147
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.311813 affinity loss 0.570942 pairwise loss 47.408708
valid 602 RMSE 1.6006 Pearson 0.651047 Spearman 0.664769 avg pairwise AUC 0.93591
test  1337 RMSE 1.409778 Pearson 0.711697 Spearman 0.691076 avg pairwise AUC 0.934147
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.263312 affinity loss 0.563902 pairwise loss 46.994104
valid 602 RMSE 1.587273 Pearson 0.649565 Spearman 0.661521 avg pairwise AUC 0.935864
test  1337 RMSE 1.409778 Pearson 0.711697 Spearman 0.691076 avg pairwise AUC 0.934147
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.194174 affinity loss 0.516436 pairwise loss 46.777379
valid 602 RMSE 1.617655 Pearson 0.63958 Spearman 0.65501 avg pairwise AUC 0.93527
test  1337 RMSE 1.409778 Pearson 0.711697 Spearman 0.691076 avg pairwise AUC 0.934147
Finished Training
------------------------------
repeat 1 fold 5 begin
train num: 4994 valid num: 664 test num: 1331
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 1035.026964 affinity loss 24.279079 pairwise loss 10107.477941
train 4994 RMSE 1.655802 Pearson 0.586228 Spearman 0.589862 avg pairwise AUC 0.845334
valid 664 RMSE 1.782543 Pearson 0.506253 Spearman 0.524707 avg pairwise AUC 0.830299
test  1331 RMSE 1.803689 Pearson 0.532242 Spearman 0.546175 avg pairwise AUC 0.825949
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.040876 affinity loss 2.907377 pairwise loss 101.334984
valid 664 RMSE 1.644392 Pearson 0.566269 Spearman 0.582091 avg pairwise AUC 0.887714
test  1331 RMSE 1.743493 Pearson 0.561 Spearman 0.58205 avg pairwise AUC 0.884619
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 12.07779 affinity loss 2.794567 pairwise loss 92.832232
valid 664 RMSE 1.641208 Pearson 0.5721 Spearman 0.595444 avg pairwise AUC 0.903633
test  1331 RMSE 1.72857 Pearson 0.569267 Spearman 0.593877 avg pairwise AUC 0.90016
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 11.093734 affinity loss 2.467423 pairwise loss 86.263101
valid 664 RMSE 1.664936 Pearson 0.604065 Spearman 0.625877 avg pairwise AUC 0.913645
test  1331 RMSE 1.72857 Pearson 0.569267 Spearman 0.593877 avg pairwise AUC 0.90016
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.467762 affinity loss 2.367222 pairwise loss 81.005397
valid 664 RMSE 1.665465 Pearson 0.594043 Spearman 0.621375 avg pairwise AUC 0.922357
test  1331 RMSE 1.72857 Pearson 0.569267 Spearman 0.593877 avg pairwise AUC 0.90016
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.932576 affinity loss 2.254793 pairwise loss 76.777833
valid 664 RMSE 1.567783 Pearson 0.626594 Spearman 0.651854 avg pairwise AUC 0.926064
test  1331 RMSE 1.651581 Pearson 0.618983 Spearman 0.634818 avg pairwise AUC 0.922585
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.466361 affinity loss 2.074835 pairwise loss 73.915257
valid 664 RMSE 1.576294 Pearson 0.637646 Spearman 0.659738 avg pairwise AUC 0.929857
test  1331 RMSE 1.651581 Pearson 0.618983 Spearman 0.634818 avg pairwise AUC 0.922585
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.095691 affinity loss 2.031663 pairwise loss 70.640281
valid 664 RMSE 1.655766 Pearson 0.645077 Spearman 0.670769 avg pairwise AUC 0.930566
test  1331 RMSE 1.651581 Pearson 0.618983 Spearman 0.634818 avg pairwise AUC 0.922585
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.735475 affinity loss 1.813928 pairwise loss 69.215472
valid 664 RMSE 1.536837 Pearson 0.663417 Spearman 0.686624 avg pairwise AUC 0.930654
test  1331 RMSE 1.654351 Pearson 0.643334 Spearman 0.665215 avg pairwise AUC 0.927862
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.448479 affinity loss 1.66216 pairwise loss 67.863188
valid 664 RMSE 1.536596 Pearson 0.659158 Spearman 0.69325 avg pairwise AUC 0.934635
test  1331 RMSE 1.650679 Pearson 0.63859 Spearman 0.660901 avg pairwise AUC 0.930764
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.061911 affinity loss 1.521996 pairwise loss 65.399153
train 4994 RMSE 1.120008 Pearson 0.833741 Spearman 0.832075 avg pairwise AUC 0.972453
valid 664 RMSE 1.517235 Pearson 0.659938 Spearman 0.681317 avg pairwise AUC 0.93392
test  1331 RMSE 1.61221 Pearson 0.642777 Spearman 0.658154 avg pairwise AUC 0.931668
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 7.867777 affinity loss 1.421676 pairwise loss 64.461008
valid 664 RMSE 1.582197 Pearson 0.6552 Spearman 0.672992 avg pairwise AUC 0.936005
test  1331 RMSE 1.61221 Pearson 0.642777 Spearman 0.658154 avg pairwise AUC 0.931668
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.767431 affinity loss 1.481563 pairwise loss 62.858676
valid 664 RMSE 1.530096 Pearson 0.678408 Spearman 0.709828 avg pairwise AUC 0.937871
test  1331 RMSE 1.61221 Pearson 0.642777 Spearman 0.658154 avg pairwise AUC 0.931668
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.560091 affinity loss 1.373298 pairwise loss 61.867928
valid 664 RMSE 1.529489 Pearson 0.665887 Spearman 0.687539 avg pairwise AUC 0.938429
test  1331 RMSE 1.61221 Pearson 0.642777 Spearman 0.658154 avg pairwise AUC 0.931668
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.326168 affinity loss 1.195693 pairwise loss 61.304748
valid 664 RMSE 1.474659 Pearson 0.677917 Spearman 0.697817 avg pairwise AUC 0.937831
test  1331 RMSE 1.589385 Pearson 0.65538 Spearman 0.670971 avg pairwise AUC 0.935507
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.194696 affinity loss 1.272836 pairwise loss 59.218606
valid 664 RMSE 1.597874 Pearson 0.670798 Spearman 0.698987 avg pairwise AUC 0.940283
test  1331 RMSE 1.589385 Pearson 0.65538 Spearman 0.670971 avg pairwise AUC 0.935507
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 6.982648 affinity loss 1.123616 pairwise loss 58.590321
valid 664 RMSE 1.548849 Pearson 0.680086 Spearman 0.700415 avg pairwise AUC 0.939515
test  1331 RMSE 1.589385 Pearson 0.65538 Spearman 0.670971 avg pairwise AUC 0.935507
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.920051 affinity loss 1.153904 pairwise loss 57.661474
valid 664 RMSE 1.679517 Pearson 0.68162 Spearman 0.70407 avg pairwise AUC 0.939793
test  1331 RMSE 1.589385 Pearson 0.65538 Spearman 0.670971 avg pairwise AUC 0.935507
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.713629 affinity loss 1.029356 pairwise loss 56.842731
valid 664 RMSE 1.573551 Pearson 0.673086 Spearman 0.698267 avg pairwise AUC 0.939528
test  1331 RMSE 1.589385 Pearson 0.65538 Spearman 0.670971 avg pairwise AUC 0.935507
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.232831 affinity loss 0.869327 pairwise loss 53.635041
valid 664 RMSE 1.489319 Pearson 0.684855 Spearman 0.712054 avg pairwise AUC 0.941385
test  1331 RMSE 1.589385 Pearson 0.65538 Spearman 0.670971 avg pairwise AUC 0.935507
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 5.970597 affinity loss 0.791117 pairwise loss 51.794798
train 4994 RMSE 0.775003 Pearson 0.923353 Spearman 0.920678 avg pairwise AUC 0.987373
valid 664 RMSE 1.456383 Pearson 0.692688 Spearman 0.716569 avg pairwise AUC 0.941588
test  1331 RMSE 1.565274 Pearson 0.673418 Spearman 0.690609 avg pairwise AUC 0.939084
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.827729 affinity loss 0.722198 pairwise loss 51.05531
valid 664 RMSE 1.51024 Pearson 0.687487 Spearman 0.707323 avg pairwise AUC 0.941467
test  1331 RMSE 1.565274 Pearson 0.673418 Spearman 0.690609 avg pairwise AUC 0.939084
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.731689 affinity loss 0.708026 pairwise loss 50.236627
valid 664 RMSE 1.478065 Pearson 0.683282 Spearman 0.701778 avg pairwise AUC 0.942175
test  1331 RMSE 1.565274 Pearson 0.673418 Spearman 0.690609 avg pairwise AUC 0.939084
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.641348 affinity loss 0.678603 pairwise loss 49.627456
valid 664 RMSE 1.510847 Pearson 0.67848 Spearman 0.702324 avg pairwise AUC 0.942033
test  1331 RMSE 1.565274 Pearson 0.673418 Spearman 0.690609 avg pairwise AUC 0.939084
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.534412 affinity loss 0.615575 pairwise loss 49.188378
valid 664 RMSE 1.47205 Pearson 0.686229 Spearman 0.70304 avg pairwise AUC 0.941395
test  1331 RMSE 1.565274 Pearson 0.673418 Spearman 0.690609 avg pairwise AUC 0.939084
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.426375 affinity loss 0.591913 pairwise loss 48.344618
valid 664 RMSE 1.478872 Pearson 0.685614 Spearman 0.70528 avg pairwise AUC 0.94219
test  1331 RMSE 1.565274 Pearson 0.673418 Spearman 0.690609 avg pairwise AUC 0.939084
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.351043 affinity loss 0.591732 pairwise loss 47.593108
valid 664 RMSE 1.494368 Pearson 0.677504 Spearman 0.694447 avg pairwise AUC 0.943176
test  1331 RMSE 1.565274 Pearson 0.673418 Spearman 0.690609 avg pairwise AUC 0.939084
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.295655 affinity loss 0.555954 pairwise loss 47.397015
valid 664 RMSE 1.500127 Pearson 0.671237 Spearman 0.683476 avg pairwise AUC 0.941607
test  1331 RMSE 1.565274 Pearson 0.673418 Spearman 0.690609 avg pairwise AUC 0.939084
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.2052 affinity loss 0.515791 pairwise loss 46.894091
valid 664 RMSE 1.552395 Pearson 0.6746 Spearman 0.687478 avg pairwise AUC 0.942444
test  1331 RMSE 1.565274 Pearson 0.673418 Spearman 0.690609 avg pairwise AUC 0.939084
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.102471 affinity loss 0.489331 pairwise loss 46.131398
valid 664 RMSE 1.524826 Pearson 0.685611 Spearman 0.700472 avg pairwise AUC 0.942729
test  1331 RMSE 1.565274 Pearson 0.673418 Spearman 0.690609 avg pairwise AUC 0.939084
Finished Training
------------------------------
fold avg performance [1.48624822 0.68517676 0.68562001 0.93281969]
/home/junseok/workspace/monn/src/pdbbind_utils.py:198: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  data_pack = [np.array(data) for data in data_pack]
setting: new_compound
fold 0 train  4955 test  1391 valid  643
fold 1 train  4999 test  1302 valid  688
fold 2 train  4741 test  1613 valid  635
fold 3 train  5005 test  1299 valid  685
fold 4 train  4636 test  1384 valid  969
repeat 2 fold 1 begin
train num: 4955 valid num: 643 test num: 1391
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 2311.619636 affinity loss 11.793696 pairwise loss 22998.259782
train 4955 RMSE 1.688336 Pearson 0.611025 Spearman 0.616792 avg pairwise AUC 0.849094
valid 643 RMSE 1.786421 Pearson 0.493712 Spearman 0.513021 avg pairwise AUC 0.834444
test  1391 RMSE 1.737123 Pearson 0.549973 Spearman 0.562627 avg pairwise AUC 0.83647
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.424205 affinity loss 3.27448 pairwise loss 101.497247
valid 643 RMSE 1.819832 Pearson 0.522229 Spearman 0.545615 avg pairwise AUC 0.885924
test  1391 RMSE 1.737123 Pearson 0.549973 Spearman 0.562627 avg pairwise AUC 0.83647
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 12.067318 affinity loss 2.860859 pairwise loss 92.064585
valid 643 RMSE 1.868383 Pearson 0.523928 Spearman 0.532168 avg pairwise AUC 0.901286
test  1391 RMSE 1.737123 Pearson 0.549973 Spearman 0.562627 avg pairwise AUC 0.83647
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 11.227017 affinity loss 2.67492 pairwise loss 85.520964
valid 643 RMSE 1.714991 Pearson 0.564016 Spearman 0.588603 avg pairwise AUC 0.914826
test  1391 RMSE 1.600234 Pearson 0.605694 Spearman 0.619467 avg pairwise AUC 0.914345
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.572329 affinity loss 2.526243 pairwise loss 80.460861
valid 643 RMSE 1.675612 Pearson 0.574073 Spearman 0.587162 avg pairwise AUC 0.922601
test  1391 RMSE 1.606761 Pearson 0.602006 Spearman 0.613938 avg pairwise AUC 0.921478
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.892004 affinity loss 2.276404 pairwise loss 76.156003
valid 643 RMSE 1.718451 Pearson 0.583195 Spearman 0.60156 avg pairwise AUC 0.92338
test  1391 RMSE 1.606761 Pearson 0.602006 Spearman 0.613938 avg pairwise AUC 0.921478
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.458464 affinity loss 2.118462 pairwise loss 73.400021
valid 643 RMSE 1.675828 Pearson 0.620118 Spearman 0.640378 avg pairwise AUC 0.929009
test  1391 RMSE 1.606761 Pearson 0.602006 Spearman 0.613938 avg pairwise AUC 0.921478
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.221366 affinity loss 2.133452 pairwise loss 70.879134
valid 643 RMSE 1.896844 Pearson 0.620461 Spearman 0.644134 avg pairwise AUC 0.930331
test  1391 RMSE 1.606761 Pearson 0.602006 Spearman 0.613938 avg pairwise AUC 0.921478
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.799225 affinity loss 1.911355 pairwise loss 68.878702
valid 643 RMSE 1.542349 Pearson 0.658352 Spearman 0.684701 avg pairwise AUC 0.932476
test  1391 RMSE 1.49554 Pearson 0.663088 Spearman 0.673548 avg pairwise AUC 0.931613
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.541237 affinity loss 1.814739 pairwise loss 67.264981
valid 643 RMSE 1.585806 Pearson 0.639213 Spearman 0.660564 avg pairwise AUC 0.933426
test  1391 RMSE 1.49554 Pearson 0.663088 Spearman 0.673548 avg pairwise AUC 0.931613
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.184032 affinity loss 1.559291 pairwise loss 66.247407
train 4955 RMSE 1.289192 Pearson 0.83476 Spearman 0.834918 avg pairwise AUC 0.970442
valid 643 RMSE 1.808318 Pearson 0.654048 Spearman 0.675635 avg pairwise AUC 0.934084
test  1391 RMSE 1.49554 Pearson 0.663088 Spearman 0.673548 avg pairwise AUC 0.931613
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 8.012265 affinity loss 1.51787 pairwise loss 64.94395
valid 643 RMSE 1.642279 Pearson 0.645238 Spearman 0.669266 avg pairwise AUC 0.936046
test  1391 RMSE 1.49554 Pearson 0.663088 Spearman 0.673548 avg pairwise AUC 0.931613
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.772009 affinity loss 1.381224 pairwise loss 63.907845
valid 643 RMSE 1.571349 Pearson 0.664247 Spearman 0.685026 avg pairwise AUC 0.937134
test  1391 RMSE 1.49554 Pearson 0.663088 Spearman 0.673548 avg pairwise AUC 0.931613
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.596604 affinity loss 1.285831 pairwise loss 63.107725
valid 643 RMSE 1.800612 Pearson 0.669034 Spearman 0.689866 avg pairwise AUC 0.93867
test  1391 RMSE 1.49554 Pearson 0.663088 Spearman 0.673548 avg pairwise AUC 0.931613
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.316974 affinity loss 1.218627 pairwise loss 60.983472
valid 643 RMSE 1.826756 Pearson 0.672456 Spearman 0.691089 avg pairwise AUC 0.941807
test  1391 RMSE 1.49554 Pearson 0.663088 Spearman 0.673548 avg pairwise AUC 0.931613
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.168744 affinity loss 1.146993 pairwise loss 60.217514
valid 643 RMSE 1.638169 Pearson 0.665776 Spearman 0.682904 avg pairwise AUC 0.94035
test  1391 RMSE 1.49554 Pearson 0.663088 Spearman 0.673548 avg pairwise AUC 0.931613
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 7.0112 affinity loss 1.105558 pairwise loss 59.056415
valid 643 RMSE 1.528403 Pearson 0.675189 Spearman 0.694878 avg pairwise AUC 0.942296
test  1391 RMSE 1.538362 Pearson 0.661486 Spearman 0.661325 avg pairwise AUC 0.936576
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.867158 affinity loss 1.036611 pairwise loss 58.305463
valid 643 RMSE 1.564578 Pearson 0.6768 Spearman 0.695147 avg pairwise AUC 0.942562
test  1391 RMSE 1.538362 Pearson 0.661486 Spearman 0.661325 avg pairwise AUC 0.936576
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.740866 affinity loss 1.010775 pairwise loss 57.300915
valid 643 RMSE 1.662423 Pearson 0.690171 Spearman 0.707488 avg pairwise AUC 0.943546
test  1391 RMSE 1.538362 Pearson 0.661486 Spearman 0.661325 avg pairwise AUC 0.936576
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.24452 affinity loss 0.830231 pairwise loss 54.142891
valid 643 RMSE 1.516587 Pearson 0.685463 Spearman 0.706097 avg pairwise AUC 0.94509
test  1391 RMSE 1.536939 Pearson 0.674766 Spearman 0.677223 avg pairwise AUC 0.938632
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 6.023696 affinity loss 0.738031 pairwise loss 52.856649
train 4955 RMSE 0.816445 Pearson 0.921945 Spearman 0.921183 avg pairwise AUC 0.986724
valid 643 RMSE 1.598381 Pearson 0.680954 Spearman 0.702858 avg pairwise AUC 0.945422
test  1391 RMSE 1.536939 Pearson 0.674766 Spearman 0.677223 avg pairwise AUC 0.938632
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.872982 affinity loss 0.690842 pairwise loss 51.821405
valid 643 RMSE 1.562945 Pearson 0.680668 Spearman 0.696247 avg pairwise AUC 0.946122
test  1391 RMSE 1.536939 Pearson 0.674766 Spearman 0.677223 avg pairwise AUC 0.938632
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.783967 affinity loss 0.680488 pairwise loss 51.034794
valid 643 RMSE 1.527425 Pearson 0.683401 Spearman 0.701467 avg pairwise AUC 0.946035
test  1391 RMSE 1.536939 Pearson 0.674766 Spearman 0.677223 avg pairwise AUC 0.938632
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.65971 affinity loss 0.628213 pairwise loss 50.314972
valid 643 RMSE 1.613652 Pearson 0.68 Spearman 0.696941 avg pairwise AUC 0.946268
test  1391 RMSE 1.536939 Pearson 0.674766 Spearman 0.677223 avg pairwise AUC 0.938632
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.601582 affinity loss 0.623429 pairwise loss 49.781527
valid 643 RMSE 1.543633 Pearson 0.671021 Spearman 0.689522 avg pairwise AUC 0.946663
test  1391 RMSE 1.536939 Pearson 0.674766 Spearman 0.677223 avg pairwise AUC 0.938632
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.525951 affinity loss 0.591772 pairwise loss 49.341792
valid 643 RMSE 1.5805 Pearson 0.675979 Spearman 0.695 avg pairwise AUC 0.946299
test  1391 RMSE 1.536939 Pearson 0.674766 Spearman 0.677223 avg pairwise AUC 0.938632
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.422818 affinity loss 0.574168 pairwise loss 48.486498
valid 643 RMSE 1.518488 Pearson 0.687811 Spearman 0.703564 avg pairwise AUC 0.947213
test  1391 RMSE 1.536939 Pearson 0.674766 Spearman 0.677223 avg pairwise AUC 0.938632
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.388113 affinity loss 0.561604 pairwise loss 48.265083
valid 643 RMSE 1.556935 Pearson 0.683788 Spearman 0.698284 avg pairwise AUC 0.947382
test  1391 RMSE 1.536939 Pearson 0.674766 Spearman 0.677223 avg pairwise AUC 0.938632
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.30578 affinity loss 0.532485 pairwise loss 47.732943
valid 643 RMSE 1.544421 Pearson 0.675089 Spearman 0.689947 avg pairwise AUC 0.947367
test  1391 RMSE 1.536939 Pearson 0.674766 Spearman 0.677223 avg pairwise AUC 0.938632
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.217015 affinity loss 0.49201 pairwise loss 47.250046
valid 643 RMSE 1.631426 Pearson 0.669463 Spearman 0.679331 avg pairwise AUC 0.947685
test  1391 RMSE 1.536939 Pearson 0.674766 Spearman 0.677223 avg pairwise AUC 0.938632
Finished Training
------------------------------
repeat 2 fold 2 begin
train num: 4999 valid num: 688 test num: 1302
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 8283.339529 affinity loss 37.656398 pairwise loss 82456.831157
train 4999 RMSE 1.660026 Pearson 0.574152 Spearman 0.589915 avg pairwise AUC 0.846469
valid 688 RMSE 1.815836 Pearson 0.596459 Spearman 0.609803 avg pairwise AUC 0.853057
test  1302 RMSE 1.634875 Pearson 0.552112 Spearman 0.570994 avg pairwise AUC 0.846818
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.315406 affinity loss 3.167855 pairwise loss 101.475507
valid 688 RMSE 1.84872 Pearson 0.645075 Spearman 0.658656 avg pairwise AUC 0.896745
test  1302 RMSE 1.634875 Pearson 0.552112 Spearman 0.570994 avg pairwise AUC 0.846818
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 12.146091 affinity loss 2.994092 pairwise loss 91.519987
valid 688 RMSE 2.580797 Pearson 0.661437 Spearman 0.676756 avg pairwise AUC 0.919774
test  1302 RMSE 1.634875 Pearson 0.552112 Spearman 0.570994 avg pairwise AUC 0.846818
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 11.21003 affinity loss 2.643705 pairwise loss 85.663248
valid 688 RMSE 1.648346 Pearson 0.684137 Spearman 0.694607 avg pairwise AUC 0.928989
test  1302 RMSE 1.557784 Pearson 0.6027 Spearman 0.622682 avg pairwise AUC 0.916799
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.413066 affinity loss 2.385123 pairwise loss 80.279424
valid 688 RMSE 1.695343 Pearson 0.688815 Spearman 0.704667 avg pairwise AUC 0.932912
test  1302 RMSE 1.557784 Pearson 0.6027 Spearman 0.622682 avg pairwise AUC 0.916799
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.848557 affinity loss 2.327192 pairwise loss 75.213652
valid 688 RMSE 1.593776 Pearson 0.709109 Spearman 0.724671 avg pairwise AUC 0.937544
test  1302 RMSE 1.505764 Pearson 0.645035 Spearman 0.661576 avg pairwise AUC 0.92716
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.528007 affinity loss 2.2268 pairwise loss 73.012066
valid 688 RMSE 1.603861 Pearson 0.710663 Spearman 0.721053 avg pairwise AUC 0.940902
test  1302 RMSE 1.505764 Pearson 0.645035 Spearman 0.661576 avg pairwise AUC 0.92716
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.243367 affinity loss 2.073296 pairwise loss 71.700709
valid 688 RMSE 1.777982 Pearson 0.734322 Spearman 0.740618 avg pairwise AUC 0.942324
test  1302 RMSE 1.505764 Pearson 0.645035 Spearman 0.661576 avg pairwise AUC 0.92716
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.886236 affinity loss 1.886459 pairwise loss 69.997769
valid 688 RMSE 1.622817 Pearson 0.715926 Spearman 0.728864 avg pairwise AUC 0.940274
test  1302 RMSE 1.505764 Pearson 0.645035 Spearman 0.661576 avg pairwise AUC 0.92716
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.498208 affinity loss 1.66721 pairwise loss 68.309979
valid 688 RMSE 1.549539 Pearson 0.741109 Spearman 0.747058 avg pairwise AUC 0.941722
test  1302 RMSE 1.554801 Pearson 0.661496 Spearman 0.659516 avg pairwise AUC 0.93173
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.306761 affinity loss 1.624894 pairwise loss 66.81867
train 4999 RMSE 1.143041 Pearson 0.835477 Spearman 0.837669 avg pairwise AUC 0.969741
valid 688 RMSE 1.512788 Pearson 0.740636 Spearman 0.75105 avg pairwise AUC 0.942273
test  1302 RMSE 1.464506 Pearson 0.667923 Spearman 0.674539 avg pairwise AUC 0.934123
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 8.099018 affinity loss 1.545708 pairwise loss 65.533101
valid 688 RMSE 1.621923 Pearson 0.737835 Spearman 0.743582 avg pairwise AUC 0.944035
test  1302 RMSE 1.464506 Pearson 0.667923 Spearman 0.674539 avg pairwise AUC 0.934123
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.811457 affinity loss 1.410087 pairwise loss 64.013691
valid 688 RMSE 1.598456 Pearson 0.729536 Spearman 0.743686 avg pairwise AUC 0.945837
test  1302 RMSE 1.464506 Pearson 0.667923 Spearman 0.674539 avg pairwise AUC 0.934123
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.605468 affinity loss 1.315134 pairwise loss 62.903334
valid 688 RMSE 1.580154 Pearson 0.749405 Spearman 0.751987 avg pairwise AUC 0.94447
test  1302 RMSE 1.464506 Pearson 0.667923 Spearman 0.674539 avg pairwise AUC 0.934123
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.438379 affinity loss 1.282898 pairwise loss 61.554806
valid 688 RMSE 1.532678 Pearson 0.753526 Spearman 0.752065 avg pairwise AUC 0.944799
test  1302 RMSE 1.464506 Pearson 0.667923 Spearman 0.674539 avg pairwise AUC 0.934123
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.313343 affinity loss 1.192755 pairwise loss 61.205874
valid 688 RMSE 1.530749 Pearson 0.764935 Spearman 0.763611 avg pairwise AUC 0.94593
test  1302 RMSE 1.464506 Pearson 0.667923 Spearman 0.674539 avg pairwise AUC 0.934123
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 7.185551 affinity loss 1.201675 pairwise loss 59.838766
valid 688 RMSE 1.518573 Pearson 0.74296 Spearman 0.745382 avg pairwise AUC 0.946616
test  1302 RMSE 1.464506 Pearson 0.667923 Spearman 0.674539 avg pairwise AUC 0.934123
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 7.059562 affinity loss 1.165966 pairwise loss 58.93596
valid 688 RMSE 1.601294 Pearson 0.758633 Spearman 0.757588 avg pairwise AUC 0.946845
test  1302 RMSE 1.464506 Pearson 0.667923 Spearman 0.674539 avg pairwise AUC 0.934123
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.881207 affinity loss 1.082167 pairwise loss 57.990404
valid 688 RMSE 1.499294 Pearson 0.74989 Spearman 0.757626 avg pairwise AUC 0.946432
test  1302 RMSE 1.484468 Pearson 0.666533 Spearman 0.670075 avg pairwise AUC 0.938141
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.348465 affinity loss 0.864505 pairwise loss 54.839607
valid 688 RMSE 1.486475 Pearson 0.774081 Spearman 0.761966 avg pairwise AUC 0.949487
test  1302 RMSE 1.520836 Pearson 0.658793 Spearman 0.659737 avg pairwise AUC 0.940898
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 6.131742 affinity loss 0.79996 pairwise loss 53.317821
train 4999 RMSE 0.795415 Pearson 0.919668 Spearman 0.920038 avg pairwise AUC 0.985256
valid 688 RMSE 1.449808 Pearson 0.768278 Spearman 0.756516 avg pairwise AUC 0.948814
test  1302 RMSE 1.49901 Pearson 0.666108 Spearman 0.662343 avg pairwise AUC 0.940706
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.987127 affinity loss 0.729555 pairwise loss 52.575717
valid 688 RMSE 1.444063 Pearson 0.779749 Spearman 0.763318 avg pairwise AUC 0.948692
test  1302 RMSE 1.508667 Pearson 0.674803 Spearman 0.672717 avg pairwise AUC 0.939649
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.876091 affinity loss 0.698868 pairwise loss 51.772229
valid 688 RMSE 1.440523 Pearson 0.772788 Spearman 0.767056 avg pairwise AUC 0.950348
test  1302 RMSE 1.463119 Pearson 0.682693 Spearman 0.679923 avg pairwise AUC 0.941929
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.756901 affinity loss 0.663271 pairwise loss 50.936306
valid 688 RMSE 1.402364 Pearson 0.78877 Spearman 0.774523 avg pairwise AUC 0.949538
test  1302 RMSE 1.466804 Pearson 0.679831 Spearman 0.678655 avg pairwise AUC 0.941126
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.689982 affinity loss 0.645925 pairwise loss 50.440578
valid 688 RMSE 1.42403 Pearson 0.786653 Spearman 0.771039 avg pairwise AUC 0.950147
test  1302 RMSE 1.466804 Pearson 0.679831 Spearman 0.678655 avg pairwise AUC 0.941126
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.593996 affinity loss 0.606452 pairwise loss 49.875447
valid 688 RMSE 1.497923 Pearson 0.778051 Spearman 0.767423 avg pairwise AUC 0.950108
test  1302 RMSE 1.466804 Pearson 0.679831 Spearman 0.678655 avg pairwise AUC 0.941126
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.55963 affinity loss 0.645771 pairwise loss 49.13859
valid 688 RMSE 1.542993 Pearson 0.776878 Spearman 0.762055 avg pairwise AUC 0.950273
test  1302 RMSE 1.466804 Pearson 0.679831 Spearman 0.678655 avg pairwise AUC 0.941126
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.418292 affinity loss 0.553362 pairwise loss 48.649304
valid 688 RMSE 1.454009 Pearson 0.788606 Spearman 0.771399 avg pairwise AUC 0.950356
test  1302 RMSE 1.466804 Pearson 0.679831 Spearman 0.678655 avg pairwise AUC 0.941126
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.348286 affinity loss 0.522857 pairwise loss 48.254285
valid 688 RMSE 1.462299 Pearson 0.765124 Spearman 0.759938 avg pairwise AUC 0.95028
test  1302 RMSE 1.466804 Pearson 0.679831 Spearman 0.678655 avg pairwise AUC 0.941126
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.278794 affinity loss 0.504393 pairwise loss 47.744008
valid 688 RMSE 1.460673 Pearson 0.772883 Spearman 0.764356 avg pairwise AUC 0.951302
test  1302 RMSE 1.466804 Pearson 0.679831 Spearman 0.678655 avg pairwise AUC 0.941126
Finished Training
------------------------------
repeat 2 fold 3 begin
train num: 4741 valid num: 635 test num: 1613
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 1467.362113 affinity loss 21.073556 pairwise loss 14462.885813
train 4741 RMSE 2.291843 Pearson 0.584761 Spearman 0.593001 avg pairwise AUC 0.854031
valid 635 RMSE 2.230126 Pearson 0.583867 Spearman 0.595146 avg pairwise AUC 0.847748
test  1613 RMSE 2.437036 Pearson 0.560303 Spearman 0.559681 avg pairwise AUC 0.827357
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 12.755231 affinity loss 3.070095 pairwise loss 96.851359
valid 635 RMSE 1.982855 Pearson 0.581416 Spearman 0.589697 avg pairwise AUC 0.89635
test  1613 RMSE 2.272272 Pearson 0.534937 Spearman 0.537909 avg pairwise AUC 0.878028
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 11.475355 affinity loss 2.79025 pairwise loss 86.85105
valid 635 RMSE 1.617528 Pearson 0.609634 Spearman 0.620229 avg pairwise AUC 0.917288
test  1613 RMSE 1.540498 Pearson 0.615502 Spearman 0.604513 avg pairwise AUC 0.897198
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 10.711212 affinity loss 2.62244 pairwise loss 80.887716
valid 635 RMSE 1.582951 Pearson 0.621433 Spearman 0.637468 avg pairwise AUC 0.926221
test  1613 RMSE 1.525285 Pearson 0.633893 Spearman 0.629426 avg pairwise AUC 0.905979
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.103973 affinity loss 2.451279 pairwise loss 76.52694
valid 635 RMSE 2.13983 Pearson 0.62167 Spearman 0.618346 avg pairwise AUC 0.92468
test  1613 RMSE 1.525285 Pearson 0.633893 Spearman 0.629426 avg pairwise AUC 0.905979
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.551473 affinity loss 2.35718 pairwise loss 71.942925
valid 635 RMSE 1.613746 Pearson 0.622816 Spearman 0.630728 avg pairwise AUC 0.930912
test  1613 RMSE 1.525285 Pearson 0.633893 Spearman 0.629426 avg pairwise AUC 0.905979
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.089449 affinity loss 2.189809 pairwise loss 68.996398
valid 635 RMSE 1.5949 Pearson 0.625716 Spearman 0.639205 avg pairwise AUC 0.933584
test  1613 RMSE 1.525285 Pearson 0.633893 Spearman 0.629426 avg pairwise AUC 0.905979
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 8.817835 affinity loss 2.159654 pairwise loss 66.581808
valid 635 RMSE 1.746116 Pearson 0.640307 Spearman 0.648315 avg pairwise AUC 0.934941
test  1613 RMSE 1.525285 Pearson 0.633893 Spearman 0.629426 avg pairwise AUC 0.905979
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.377033 affinity loss 1.962449 pairwise loss 64.145847
valid 635 RMSE 1.605458 Pearson 0.617703 Spearman 0.618823 avg pairwise AUC 0.936321
test  1613 RMSE 1.525285 Pearson 0.633893 Spearman 0.629426 avg pairwise AUC 0.905979
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.043136 affinity loss 1.778505 pairwise loss 62.646313
valid 635 RMSE 1.580496 Pearson 0.631472 Spearman 0.642346 avg pairwise AUC 0.935019
test  1613 RMSE 1.428333 Pearson 0.683817 Spearman 0.67528 avg pairwise AUC 0.916028
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 7.974216 affinity loss 1.835105 pairwise loss 61.391109
train 4741 RMSE 1.293162 Pearson 0.811391 Spearman 0.809244 avg pairwise AUC 0.975155
valid 635 RMSE 1.609078 Pearson 0.661181 Spearman 0.668623 avg pairwise AUC 0.936793
test  1613 RMSE 1.428333 Pearson 0.683817 Spearman 0.67528 avg pairwise AUC 0.916028
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 7.650669 affinity loss 1.708967 pairwise loss 59.417022
valid 635 RMSE 1.844809 Pearson 0.662348 Spearman 0.671107 avg pairwise AUC 0.937278
test  1613 RMSE 1.428333 Pearson 0.683817 Spearman 0.67528 avg pairwise AUC 0.916028
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.462096 affinity loss 1.555109 pairwise loss 59.06986
valid 635 RMSE 1.650315 Pearson 0.642086 Spearman 0.651542 avg pairwise AUC 0.937466
test  1613 RMSE 1.428333 Pearson 0.683817 Spearman 0.67528 avg pairwise AUC 0.916028
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.516908 affinity loss 1.680202 pairwise loss 58.367058
valid 635 RMSE 1.659649 Pearson 0.64601 Spearman 0.66367 avg pairwise AUC 0.93786
test  1613 RMSE 1.428333 Pearson 0.683817 Spearman 0.67528 avg pairwise AUC 0.916028
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.279494 affinity loss 1.549016 pairwise loss 57.304773
valid 635 RMSE 1.604929 Pearson 0.65811 Spearman 0.666255 avg pairwise AUC 0.938403
test  1613 RMSE 1.428333 Pearson 0.683817 Spearman 0.67528 avg pairwise AUC 0.916028
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 6.990283 affinity loss 1.35106 pairwise loss 56.392225
valid 635 RMSE 1.545587 Pearson 0.654576 Spearman 0.661884 avg pairwise AUC 0.93854
test  1613 RMSE 1.383175 Pearson 0.707858 Spearman 0.704484 avg pairwise AUC 0.921111
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 6.880932 affinity loss 1.275512 pairwise loss 56.054205
valid 635 RMSE 1.58832 Pearson 0.663058 Spearman 0.672392 avg pairwise AUC 0.937176
test  1613 RMSE 1.383175 Pearson 0.707858 Spearman 0.704484 avg pairwise AUC 0.921111
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.692614 affinity loss 1.234986 pairwise loss 54.576278
valid 635 RMSE 1.575443 Pearson 0.664679 Spearman 0.668204 avg pairwise AUC 0.940899
test  1613 RMSE 1.383175 Pearson 0.707858 Spearman 0.704484 avg pairwise AUC 0.921111
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.55444 affinity loss 1.190383 pairwise loss 53.640574
valid 635 RMSE 1.568172 Pearson 0.648629 Spearman 0.665216 avg pairwise AUC 0.940591
test  1613 RMSE 1.383175 Pearson 0.707858 Spearman 0.704484 avg pairwise AUC 0.921111
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.081324 affinity loss 1.008733 pairwise loss 50.72591
valid 635 RMSE 1.527087 Pearson 0.662134 Spearman 0.664685 avg pairwise AUC 0.94057
test  1613 RMSE 1.417592 Pearson 0.699788 Spearman 0.694455 avg pairwise AUC 0.921839
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 5.820633 affinity loss 0.884893 pairwise loss 49.357398
train 4741 RMSE 0.923266 Pearson 0.909864 Spearman 0.903154 avg pairwise AUC 0.988469
valid 635 RMSE 1.521732 Pearson 0.682842 Spearman 0.682065 avg pairwise AUC 0.941264
test  1613 RMSE 1.417784 Pearson 0.703834 Spearman 0.697576 avg pairwise AUC 0.92112
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.726427 affinity loss 0.851078 pairwise loss 48.753488
valid 635 RMSE 1.589909 Pearson 0.64645 Spearman 0.644246 avg pairwise AUC 0.940606
test  1613 RMSE 1.417784 Pearson 0.703834 Spearman 0.697576 avg pairwise AUC 0.92112
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.635552 affinity loss 0.816702 pairwise loss 48.188493
valid 635 RMSE 1.582647 Pearson 0.675784 Spearman 0.677034 avg pairwise AUC 0.940049
test  1613 RMSE 1.417784 Pearson 0.703834 Spearman 0.697576 avg pairwise AUC 0.92112
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.522598 affinity loss 0.77774 pairwise loss 47.448582
valid 635 RMSE 1.531835 Pearson 0.673641 Spearman 0.675534 avg pairwise AUC 0.941386
test  1613 RMSE 1.417784 Pearson 0.703834 Spearman 0.697576 avg pairwise AUC 0.92112
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.462763 affinity loss 0.766192 pairwise loss 46.965715
valid 635 RMSE 1.615142 Pearson 0.672796 Spearman 0.674221 avg pairwise AUC 0.940379
test  1613 RMSE 1.417784 Pearson 0.703834 Spearman 0.697576 avg pairwise AUC 0.92112
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.323025 affinity loss 0.697892 pairwise loss 46.251333
valid 635 RMSE 1.528801 Pearson 0.671515 Spearman 0.679007 avg pairwise AUC 0.941352
test  1613 RMSE 1.417784 Pearson 0.703834 Spearman 0.697576 avg pairwise AUC 0.92112
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.262004 affinity loss 0.673951 pairwise loss 45.880534
valid 635 RMSE 1.544023 Pearson 0.681096 Spearman 0.685661 avg pairwise AUC 0.940842
test  1613 RMSE 1.417784 Pearson 0.703834 Spearman 0.697576 avg pairwise AUC 0.92112
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.164946 affinity loss 0.607353 pairwise loss 45.575924
valid 635 RMSE 1.537908 Pearson 0.66917 Spearman 0.665476 avg pairwise AUC 0.941619
test  1613 RMSE 1.417784 Pearson 0.703834 Spearman 0.697576 avg pairwise AUC 0.92112
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.120789 affinity loss 0.620385 pairwise loss 45.004033
valid 635 RMSE 1.550034 Pearson 0.6734 Spearman 0.674079 avg pairwise AUC 0.940231
test  1613 RMSE 1.417784 Pearson 0.703834 Spearman 0.697576 avg pairwise AUC 0.92112
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.026206 affinity loss 0.60064 pairwise loss 44.255664
valid 635 RMSE 1.531094 Pearson 0.673007 Spearman 0.677163 avg pairwise AUC 0.941306
test  1613 RMSE 1.417784 Pearson 0.703834 Spearman 0.697576 avg pairwise AUC 0.92112
Finished Training
------------------------------
repeat 2 fold 4 begin
train num: 5005 valid num: 685 test num: 1299
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 1323.065981 affinity loss 11.410312 pairwise loss 13116.556449
train 5005 RMSE 1.626127 Pearson 0.575 Spearman 0.590945 avg pairwise AUC 0.848147
valid 685 RMSE 1.99724 Pearson 0.559147 Spearman 0.591335 avg pairwise AUC 0.857465
test  1299 RMSE 1.657672 Pearson 0.562528 Spearman 0.562255 avg pairwise AUC 0.84103
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.094044 affinity loss 3.01249 pairwise loss 100.815538
valid 685 RMSE 1.943245 Pearson 0.640848 Spearman 0.662017 avg pairwise AUC 0.902322
test  1299 RMSE 1.637494 Pearson 0.602855 Spearman 0.606272 avg pairwise AUC 0.896284
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 12.124331 affinity loss 2.833281 pairwise loss 92.910494
valid 685 RMSE 2.059255 Pearson 0.642274 Spearman 0.666578 avg pairwise AUC 0.914685
test  1299 RMSE 1.637494 Pearson 0.602855 Spearman 0.606272 avg pairwise AUC 0.896284
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 11.363016 affinity loss 2.670278 pairwise loss 86.927376
valid 685 RMSE 1.911928 Pearson 0.6667 Spearman 0.682256 avg pairwise AUC 0.923962
test  1299 RMSE 1.619316 Pearson 0.626622 Spearman 0.633036 avg pairwise AUC 0.920426
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.591965 affinity loss 2.432165 pairwise loss 81.597996
valid 685 RMSE 1.781086 Pearson 0.667314 Spearman 0.692043 avg pairwise AUC 0.928367
test  1299 RMSE 1.60177 Pearson 0.622164 Spearman 0.629787 avg pairwise AUC 0.926304
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.954394 affinity loss 2.276611 pairwise loss 76.777828
valid 685 RMSE 1.822006 Pearson 0.675106 Spearman 0.693757 avg pairwise AUC 0.934693
test  1299 RMSE 1.60177 Pearson 0.622164 Spearman 0.629787 avg pairwise AUC 0.926304
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.585126 affinity loss 2.252208 pairwise loss 73.32918
valid 685 RMSE 1.760635 Pearson 0.703399 Spearman 0.721914 avg pairwise AUC 0.937485
test  1299 RMSE 1.538348 Pearson 0.651119 Spearman 0.655526 avg pairwise AUC 0.937107
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.122237 affinity loss 2.098393 pairwise loss 70.238433
valid 685 RMSE 1.707269 Pearson 0.724769 Spearman 0.734899 avg pairwise AUC 0.941537
test  1299 RMSE 1.545813 Pearson 0.665238 Spearman 0.673624 avg pairwise AUC 0.939008
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.93336 affinity loss 2.130624 pairwise loss 68.027354
valid 685 RMSE 1.791679 Pearson 0.710181 Spearman 0.73164 avg pairwise AUC 0.944045
test  1299 RMSE 1.545813 Pearson 0.665238 Spearman 0.673624 avg pairwise AUC 0.939008
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.524752 affinity loss 1.872409 pairwise loss 66.52343
valid 685 RMSE 1.678538 Pearson 0.724332 Spearman 0.736813 avg pairwise AUC 0.940805
test  1299 RMSE 1.532481 Pearson 0.682964 Spearman 0.694328 avg pairwise AUC 0.939052
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.207057 affinity loss 1.734634 pairwise loss 64.724227
train 5005 RMSE 1.2159 Pearson 0.795835 Spearman 0.798397 avg pairwise AUC 0.973362
valid 685 RMSE 1.761817 Pearson 0.687637 Spearman 0.705514 avg pairwise AUC 0.944174
test  1299 RMSE 1.532481 Pearson 0.682964 Spearman 0.694328 avg pairwise AUC 0.939052
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 8.216215 affinity loss 1.854013 pairwise loss 63.622018
valid 685 RMSE 1.969642 Pearson 0.734401 Spearman 0.741653 avg pairwise AUC 0.945025
test  1299 RMSE 1.532481 Pearson 0.682964 Spearman 0.694328 avg pairwise AUC 0.939052
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.827416 affinity loss 1.621422 pairwise loss 62.059938
valid 685 RMSE 1.646725 Pearson 0.753335 Spearman 0.762062 avg pairwise AUC 0.944651
test  1299 RMSE 1.474848 Pearson 0.70435 Spearman 0.703527 avg pairwise AUC 0.94187
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.522616 affinity loss 1.406547 pairwise loss 61.160691
valid 685 RMSE 1.588427 Pearson 0.742849 Spearman 0.74654 avg pairwise AUC 0.944945
test  1299 RMSE 1.46274 Pearson 0.690145 Spearman 0.696447 avg pairwise AUC 0.94363
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.396864 affinity loss 1.346154 pairwise loss 60.507101
valid 685 RMSE 1.727569 Pearson 0.73934 Spearman 0.753156 avg pairwise AUC 0.946683
test  1299 RMSE 1.46274 Pearson 0.690145 Spearman 0.696447 avg pairwise AUC 0.94363
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.229917 affinity loss 1.335412 pairwise loss 58.94505
valid 685 RMSE 1.533853 Pearson 0.765285 Spearman 0.769264 avg pairwise AUC 0.947985
test  1299 RMSE 1.402934 Pearson 0.719173 Spearman 0.721454 avg pairwise AUC 0.945474
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 7.045898 affinity loss 1.22471 pairwise loss 58.211874
valid 685 RMSE 1.623401 Pearson 0.731064 Spearman 0.745964 avg pairwise AUC 0.948034
test  1299 RMSE 1.402934 Pearson 0.719173 Spearman 0.721454 avg pairwise AUC 0.945474
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.907053 affinity loss 1.210551 pairwise loss 56.965024
valid 685 RMSE 1.596583 Pearson 0.737425 Spearman 0.753645 avg pairwise AUC 0.948534
test  1299 RMSE 1.402934 Pearson 0.719173 Spearman 0.721454 avg pairwise AUC 0.945474
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.758147 affinity loss 1.124473 pairwise loss 56.336744
valid 685 RMSE 1.561098 Pearson 0.754493 Spearman 0.765127 avg pairwise AUC 0.947824
test  1299 RMSE 1.402934 Pearson 0.719173 Spearman 0.721454 avg pairwise AUC 0.945474
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.251987 affinity loss 0.926832 pairwise loss 53.251549
valid 685 RMSE 1.494144 Pearson 0.774619 Spearman 0.770255 avg pairwise AUC 0.949753
test  1299 RMSE 1.393874 Pearson 0.729242 Spearman 0.732881 avg pairwise AUC 0.948074
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 6.007204 affinity loss 0.843541 pairwise loss 51.636632
train 5005 RMSE 0.860542 Pearson 0.909884 Spearman 0.909915 avg pairwise AUC 0.98811
valid 685 RMSE 1.635693 Pearson 0.742555 Spearman 0.755235 avg pairwise AUC 0.948973
test  1299 RMSE 1.393874 Pearson 0.729242 Spearman 0.732881 avg pairwise AUC 0.948074
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.866709 affinity loss 0.803675 pairwise loss 50.630334
valid 685 RMSE 1.56455 Pearson 0.748071 Spearman 0.764612 avg pairwise AUC 0.949974
test  1299 RMSE 1.393874 Pearson 0.729242 Spearman 0.732881 avg pairwise AUC 0.948074
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.781085 affinity loss 0.776577 pairwise loss 50.04508
valid 685 RMSE 1.633402 Pearson 0.751937 Spearman 0.754118 avg pairwise AUC 0.949116
test  1299 RMSE 1.393874 Pearson 0.729242 Spearman 0.732881 avg pairwise AUC 0.948074
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.649883 affinity loss 0.71028 pairwise loss 49.396036
valid 685 RMSE 1.508695 Pearson 0.769474 Spearman 0.765075 avg pairwise AUC 0.949414
test  1299 RMSE 1.393874 Pearson 0.729242 Spearman 0.732881 avg pairwise AUC 0.948074
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.575128 affinity loss 0.670804 pairwise loss 49.043234
valid 685 RMSE 1.607873 Pearson 0.731766 Spearman 0.737578 avg pairwise AUC 0.948581
test  1299 RMSE 1.393874 Pearson 0.729242 Spearman 0.732881 avg pairwise AUC 0.948074
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.487645 affinity loss 0.651476 pairwise loss 48.361682
valid 685 RMSE 1.532649 Pearson 0.759637 Spearman 0.764453 avg pairwise AUC 0.948785
test  1299 RMSE 1.393874 Pearson 0.729242 Spearman 0.732881 avg pairwise AUC 0.948074
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.408692 affinity loss 0.628041 pairwise loss 47.806513
valid 685 RMSE 1.658735 Pearson 0.725202 Spearman 0.735354 avg pairwise AUC 0.949218
test  1299 RMSE 1.393874 Pearson 0.729242 Spearman 0.732881 avg pairwise AUC 0.948074
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.294761 affinity loss 0.567109 pairwise loss 47.276514
valid 685 RMSE 1.600285 Pearson 0.761377 Spearman 0.768842 avg pairwise AUC 0.948111
test  1299 RMSE 1.393874 Pearson 0.729242 Spearman 0.732881 avg pairwise AUC 0.948074
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.212803 affinity loss 0.550634 pairwise loss 46.621694
valid 685 RMSE 1.626891 Pearson 0.74286 Spearman 0.743967 avg pairwise AUC 0.948428
test  1299 RMSE 1.393874 Pearson 0.729242 Spearman 0.732881 avg pairwise AUC 0.948074
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.131516 affinity loss 0.525106 pairwise loss 46.064106
valid 685 RMSE 1.567785 Pearson 0.746711 Spearman 0.762143 avg pairwise AUC 0.948465
test  1299 RMSE 1.393874 Pearson 0.729242 Spearman 0.732881 avg pairwise AUC 0.948074
Finished Training
------------------------------
repeat 2 fold 5 begin
train num: 4636 valid num: 969 test num: 1384
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 966.639635 affinity loss 8.82867 pairwise loss 9578.109336
train 4636 RMSE 1.7386 Pearson 0.585298 Spearman 0.58928 avg pairwise AUC 0.855159
valid 969 RMSE 1.652538 Pearson 0.4699 Spearman 0.450072 avg pairwise AUC 0.827218
test  1384 RMSE 1.918575 Pearson 0.567012 Spearman 0.588717 avg pairwise AUC 0.842547
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 12.328205 affinity loss 2.896638 pairwise loss 94.315669
valid 969 RMSE 1.64822 Pearson 0.459994 Spearman 0.432713 avg pairwise AUC 0.867907
test  1384 RMSE 1.807484 Pearson 0.596502 Spearman 0.610766 avg pairwise AUC 0.884751
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 11.354861 affinity loss 2.770276 pairwise loss 85.845843
valid 969 RMSE 1.600148 Pearson 0.524797 Spearman 0.491296 avg pairwise AUC 0.887979
test  1384 RMSE 1.755009 Pearson 0.602241 Spearman 0.624893 avg pairwise AUC 0.904637
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 10.797215 affinity loss 2.596471 pairwise loss 82.007433
valid 969 RMSE 1.588509 Pearson 0.536308 Spearman 0.51147 avg pairwise AUC 0.880163
test  1384 RMSE 1.706742 Pearson 0.630781 Spearman 0.648017 avg pairwise AUC 0.905707
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.211538 affinity loss 2.53195 pairwise loss 76.795871
valid 969 RMSE 1.539343 Pearson 0.566786 Spearman 0.531013 avg pairwise AUC 0.89705
test  1384 RMSE 1.741665 Pearson 0.652441 Spearman 0.670525 avg pairwise AUC 0.916982
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.552456 affinity loss 2.349308 pairwise loss 72.03148
valid 969 RMSE 1.786815 Pearson 0.582666 Spearman 0.551791 avg pairwise AUC 0.898375
test  1384 RMSE 1.741665 Pearson 0.652441 Spearman 0.670525 avg pairwise AUC 0.916982
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.126543 affinity loss 2.221131 pairwise loss 69.054121
valid 969 RMSE 1.601044 Pearson 0.521766 Spearman 0.479513 avg pairwise AUC 0.902478
test  1384 RMSE 1.741665 Pearson 0.652441 Spearman 0.670525 avg pairwise AUC 0.916982
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 8.750497 affinity loss 2.074665 pairwise loss 66.758324
valid 969 RMSE 1.538084 Pearson 0.591107 Spearman 0.558284 avg pairwise AUC 0.903594
test  1384 RMSE 1.618131 Pearson 0.682875 Spearman 0.698723 avg pairwise AUC 0.926218
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.57004 affinity loss 2.089916 pairwise loss 64.801235
valid 969 RMSE 1.582016 Pearson 0.534529 Spearman 0.478434 avg pairwise AUC 0.902501
test  1384 RMSE 1.618131 Pearson 0.682875 Spearman 0.698723 avg pairwise AUC 0.926218
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.248277 affinity loss 1.92245 pairwise loss 63.258272
valid 969 RMSE 1.489442 Pearson 0.596667 Spearman 0.558238 avg pairwise AUC 0.902074
test  1384 RMSE 1.605948 Pearson 0.693533 Spearman 0.708322 avg pairwise AUC 0.927731
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 7.984255 affinity loss 1.771247 pairwise loss 62.130077
train 4636 RMSE 1.253529 Pearson 0.801851 Spearman 0.804864 avg pairwise AUC 0.97403
valid 969 RMSE 1.595644 Pearson 0.518736 Spearman 0.454324 avg pairwise AUC 0.901671
test  1384 RMSE 1.605948 Pearson 0.693533 Spearman 0.708322 avg pairwise AUC 0.927731
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 7.637478 affinity loss 1.611726 pairwise loss 60.257518
valid 969 RMSE 1.498676 Pearson 0.588291 Spearman 0.55196 avg pairwise AUC 0.901262
test  1384 RMSE 1.605948 Pearson 0.693533 Spearman 0.708322 avg pairwise AUC 0.927731
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.504345 affinity loss 1.591288 pairwise loss 59.130569
valid 969 RMSE 1.60696 Pearson 0.610183 Spearman 0.569938 avg pairwise AUC 0.901464
test  1384 RMSE 1.605948 Pearson 0.693533 Spearman 0.708322 avg pairwise AUC 0.927731
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.274352 affinity loss 1.483744 pairwise loss 57.906072
valid 969 RMSE 1.769652 Pearson 0.575752 Spearman 0.538486 avg pairwise AUC 0.901307
test  1384 RMSE 1.605948 Pearson 0.693533 Spearman 0.708322 avg pairwise AUC 0.927731
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.076626 affinity loss 1.377923 pairwise loss 56.987031
valid 969 RMSE 1.576799 Pearson 0.531836 Spearman 0.481126 avg pairwise AUC 0.900148
test  1384 RMSE 1.605948 Pearson 0.693533 Spearman 0.708322 avg pairwise AUC 0.927731
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 6.895043 affinity loss 1.270505 pairwise loss 56.245383
valid 969 RMSE 1.534198 Pearson 0.623739 Spearman 0.587616 avg pairwise AUC 0.899291
test  1384 RMSE 1.605948 Pearson 0.693533 Spearman 0.708322 avg pairwise AUC 0.927731
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 6.795266 affinity loss 1.281892 pairwise loss 55.133743
valid 969 RMSE 1.540843 Pearson 0.610481 Spearman 0.560889 avg pairwise AUC 0.902007
test  1384 RMSE 1.605948 Pearson 0.693533 Spearman 0.708322 avg pairwise AUC 0.927731
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.580993 affinity loss 1.214994 pairwise loss 53.659994
valid 969 RMSE 1.617752 Pearson 0.599414 Spearman 0.562312 avg pairwise AUC 0.901872
test  1384 RMSE 1.605948 Pearson 0.693533 Spearman 0.708322 avg pairwise AUC 0.927731
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.535855 affinity loss 1.156986 pairwise loss 53.788696
valid 969 RMSE 1.5628 Pearson 0.583826 Spearman 0.552153 avg pairwise AUC 0.905645
test  1384 RMSE 1.605948 Pearson 0.693533 Spearman 0.708322 avg pairwise AUC 0.927731
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.030533 affinity loss 0.964226 pairwise loss 50.663066
valid 969 RMSE 1.505387 Pearson 0.599555 Spearman 0.560556 avg pairwise AUC 0.904271
test  1384 RMSE 1.605948 Pearson 0.693533 Spearman 0.708322 avg pairwise AUC 0.927731
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 5.76485 affinity loss 0.876046 pairwise loss 48.888037
train 4636 RMSE 0.876738 Pearson 0.910313 Spearman 0.90746 avg pairwise AUC 0.988366
valid 969 RMSE 1.491096 Pearson 0.601764 Spearman 0.548767 avg pairwise AUC 0.902046
test  1384 RMSE 1.605948 Pearson 0.693533 Spearman 0.708322 avg pairwise AUC 0.927731
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.64811 affinity loss 0.814665 pairwise loss 48.334453
valid 969 RMSE 1.540329 Pearson 0.60363 Spearman 0.564497 avg pairwise AUC 0.903327
test  1384 RMSE 1.605948 Pearson 0.693533 Spearman 0.708322 avg pairwise AUC 0.927731
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.532478 affinity loss 0.761741 pairwise loss 47.70737
valid 969 RMSE 1.497332 Pearson 0.613204 Spearman 0.570686 avg pairwise AUC 0.902041
test  1384 RMSE 1.605948 Pearson 0.693533 Spearman 0.708322 avg pairwise AUC 0.927731
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.462043 affinity loss 0.755835 pairwise loss 47.062086
valid 969 RMSE 1.496886 Pearson 0.626607 Spearman 0.591277 avg pairwise AUC 0.902852
test  1384 RMSE 1.605948 Pearson 0.693533 Spearman 0.708322 avg pairwise AUC 0.927731
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.36142 affinity loss 0.731943 pairwise loss 46.29477
valid 969 RMSE 1.523368 Pearson 0.610383 Spearman 0.571503 avg pairwise AUC 0.90232
test  1384 RMSE 1.605948 Pearson 0.693533 Spearman 0.708322 avg pairwise AUC 0.927731
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.285396 affinity loss 0.684416 pairwise loss 46.009801
valid 969 RMSE 1.500782 Pearson 0.612556 Spearman 0.567421 avg pairwise AUC 0.902297
test  1384 RMSE 1.605948 Pearson 0.693533 Spearman 0.708322 avg pairwise AUC 0.927731
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.172557 affinity loss 0.635266 pairwise loss 45.372914
valid 969 RMSE 1.572227 Pearson 0.606243 Spearman 0.566312 avg pairwise AUC 0.902352
test  1384 RMSE 1.605948 Pearson 0.693533 Spearman 0.708322 avg pairwise AUC 0.927731
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.129287 affinity loss 0.623316 pairwise loss 45.05971
valid 969 RMSE 1.505661 Pearson 0.612206 Spearman 0.572608 avg pairwise AUC 0.901645
test  1384 RMSE 1.605948 Pearson 0.693533 Spearman 0.708322 avg pairwise AUC 0.927731
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.047637 affinity loss 0.601181 pairwise loss 44.464552
valid 969 RMSE 1.50925 Pearson 0.622145 Spearman 0.583185 avg pairwise AUC 0.89909
test  1384 RMSE 1.605948 Pearson 0.693533 Spearman 0.708322 avg pairwise AUC 0.927731
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 4.985731 affinity loss 0.584128 pairwise loss 44.016029
valid 969 RMSE 1.499978 Pearson 0.625007 Spearman 0.58443 avg pairwise AUC 0.899
test  1384 RMSE 1.605948 Pearson 0.693533 Spearman 0.708322 avg pairwise AUC 0.927731
Finished Training
------------------------------
fold avg performance [1.48426999 0.69624129 0.69893129 0.93533685]
/home/junseok/workspace/monn/src/pdbbind_utils.py:198: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  data_pack = [np.array(data) for data in data_pack]
setting: new_compound
fold 0 train  4597 test  1656 valid  736
fold 1 train  5103 test  1288 valid  598
fold 2 train  5078 test  1275 valid  636
fold 3 train  4932 test  1332 valid  725
fold 4 train  4912 test  1438 valid  639
repeat 3 fold 1 begin
train num: 4597 valid num: 736 test num: 1656
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 824.316018 affinity loss 9.790606 pairwise loss 8145.254106
train 4597 RMSE 1.773415 Pearson 0.605202 Spearman 0.608043 avg pairwise AUC 0.858136
valid 736 RMSE 1.761798 Pearson 0.56048 Spearman 0.558625 avg pairwise AUC 0.835358
test  1656 RMSE 1.925728 Pearson 0.507925 Spearman 0.499333 avg pairwise AUC 0.833302
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 12.923095 affinity loss 3.322545 pairwise loss 96.005499
valid 736 RMSE 1.558419 Pearson 0.587562 Spearman 0.595979 avg pairwise AUC 0.869494
test  1656 RMSE 1.626141 Pearson 0.542917 Spearman 0.544935 avg pairwise AUC 0.866298
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 11.862306 affinity loss 3.152984 pairwise loss 87.09321
valid 736 RMSE 1.590437 Pearson 0.583379 Spearman 0.593181 avg pairwise AUC 0.88356
test  1656 RMSE 1.626141 Pearson 0.542917 Spearman 0.544935 avg pairwise AUC 0.866298
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 10.929009 affinity loss 2.756031 pairwise loss 81.729773
valid 736 RMSE 1.647972 Pearson 0.526396 Spearman 0.590016 avg pairwise AUC 0.90058
test  1656 RMSE 1.626141 Pearson 0.542917 Spearman 0.544935 avg pairwise AUC 0.866298
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.096739 affinity loss 2.462647 pairwise loss 76.340916
valid 736 RMSE 1.532896 Pearson 0.59628 Spearman 0.608769 avg pairwise AUC 0.907087
test  1656 RMSE 1.627683 Pearson 0.553522 Spearman 0.540814 avg pairwise AUC 0.905723
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.505149 affinity loss 2.268456 pairwise loss 72.366929
valid 736 RMSE 1.447029 Pearson 0.652281 Spearman 0.664274 avg pairwise AUC 0.912434
test  1656 RMSE 1.560891 Pearson 0.605724 Spearman 0.604641 avg pairwise AUC 0.910421
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.268829 affinity loss 2.302833 pairwise loss 69.659961
valid 736 RMSE 1.653474 Pearson 0.606357 Spearman 0.602005 avg pairwise AUC 0.913385
test  1656 RMSE 1.560891 Pearson 0.605724 Spearman 0.604641 avg pairwise AUC 0.910421
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 8.837336 affinity loss 2.127902 pairwise loss 67.094344
valid 736 RMSE 1.494281 Pearson 0.635021 Spearman 0.639989 avg pairwise AUC 0.913949
test  1656 RMSE 1.560891 Pearson 0.605724 Spearman 0.604641 avg pairwise AUC 0.910421
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.537255 affinity loss 1.876195 pairwise loss 66.610597
valid 736 RMSE 1.581992 Pearson 0.639611 Spearman 0.649687 avg pairwise AUC 0.912463
test  1656 RMSE 1.560891 Pearson 0.605724 Spearman 0.604641 avg pairwise AUC 0.910421
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.215983 affinity loss 1.772169 pairwise loss 64.438143
valid 736 RMSE 1.453647 Pearson 0.658029 Spearman 0.669904 avg pairwise AUC 0.913633
test  1656 RMSE 1.560891 Pearson 0.605724 Spearman 0.604641 avg pairwise AUC 0.910421
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 7.967074 affinity loss 1.625769 pairwise loss 63.413041
train 4597 RMSE 1.136115 Pearson 0.83991 Spearman 0.841611 avg pairwise AUC 0.972392
valid 736 RMSE 1.431158 Pearson 0.673903 Spearman 0.689354 avg pairwise AUC 0.917943
test  1656 RMSE 1.490795 Pearson 0.640422 Spearman 0.639318 avg pairwise AUC 0.916275
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 7.724683 affinity loss 1.559903 pairwise loss 61.647806
valid 736 RMSE 1.43972 Pearson 0.665433 Spearman 0.67896 avg pairwise AUC 0.917005
test  1656 RMSE 1.490795 Pearson 0.640422 Spearman 0.639318 avg pairwise AUC 0.916275
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.495685 affinity loss 1.430949 pairwise loss 60.647359
valid 736 RMSE 1.554959 Pearson 0.675709 Spearman 0.680243 avg pairwise AUC 0.91794
test  1656 RMSE 1.490795 Pearson 0.640422 Spearman 0.639318 avg pairwise AUC 0.916275
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.424654 affinity loss 1.499269 pairwise loss 59.253847
valid 736 RMSE 1.438142 Pearson 0.661071 Spearman 0.658977 avg pairwise AUC 0.920007
test  1656 RMSE 1.490795 Pearson 0.640422 Spearman 0.639318 avg pairwise AUC 0.916275
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.116356 affinity loss 1.278106 pairwise loss 58.382497
valid 736 RMSE 1.47131 Pearson 0.659796 Spearman 0.652208 avg pairwise AUC 0.920055
test  1656 RMSE 1.490795 Pearson 0.640422 Spearman 0.639318 avg pairwise AUC 0.916275
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.009359 affinity loss 1.343979 pairwise loss 56.653795
valid 736 RMSE 1.460663 Pearson 0.641533 Spearman 0.642835 avg pairwise AUC 0.920204
test  1656 RMSE 1.490795 Pearson 0.640422 Spearman 0.639318 avg pairwise AUC 0.916275
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 6.883196 affinity loss 1.256239 pairwise loss 56.269577
valid 736 RMSE 1.414816 Pearson 0.691276 Spearman 0.691726 avg pairwise AUC 0.92154
test  1656 RMSE 1.521913 Pearson 0.654063 Spearman 0.652461 avg pairwise AUC 0.918118
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.745203 affinity loss 1.209839 pairwise loss 55.353641
valid 736 RMSE 1.426525 Pearson 0.665828 Spearman 0.658899 avg pairwise AUC 0.92177
test  1656 RMSE 1.521913 Pearson 0.654063 Spearman 0.652461 avg pairwise AUC 0.918118
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.569406 affinity loss 1.11999 pairwise loss 54.494157
valid 736 RMSE 1.477937 Pearson 0.691107 Spearman 0.693476 avg pairwise AUC 0.921671
test  1656 RMSE 1.521913 Pearson 0.654063 Spearman 0.652461 avg pairwise AUC 0.918118
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.040554 affinity loss 0.880274 pairwise loss 51.602807
valid 736 RMSE 1.420272 Pearson 0.69602 Spearman 0.699374 avg pairwise AUC 0.924138
test  1656 RMSE 1.521913 Pearson 0.654063 Spearman 0.652461 avg pairwise AUC 0.918118
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 5.863579 affinity loss 0.822572 pairwise loss 50.410077
train 4597 RMSE 0.833899 Pearson 0.922791 Spearman 0.920021 avg pairwise AUC 0.98812
valid 736 RMSE 1.417743 Pearson 0.70963 Spearman 0.708738 avg pairwise AUC 0.923656
test  1656 RMSE 1.521913 Pearson 0.654063 Spearman 0.652461 avg pairwise AUC 0.918118
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.712362 affinity loss 0.761817 pairwise loss 49.505451
valid 736 RMSE 1.387853 Pearson 0.706238 Spearman 0.708335 avg pairwise AUC 0.923582
test  1656 RMSE 1.464104 Pearson 0.667025 Spearman 0.660189 avg pairwise AUC 0.919882
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.624739 affinity loss 0.771019 pairwise loss 48.537199
valid 736 RMSE 1.381655 Pearson 0.701192 Spearman 0.700178 avg pairwise AUC 0.924087
test  1656 RMSE 1.46789 Pearson 0.659464 Spearman 0.657011 avg pairwise AUC 0.920385
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.529301 affinity loss 0.73464 pairwise loss 47.946616
valid 736 RMSE 1.404428 Pearson 0.696755 Spearman 0.695876 avg pairwise AUC 0.924457
test  1656 RMSE 1.46789 Pearson 0.659464 Spearman 0.657011 avg pairwise AUC 0.920385
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.441011 affinity loss 0.679847 pairwise loss 47.611635
valid 736 RMSE 1.390131 Pearson 0.70392 Spearman 0.707831 avg pairwise AUC 0.92331
test  1656 RMSE 1.46789 Pearson 0.659464 Spearman 0.657011 avg pairwise AUC 0.920385
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.38144 affinity loss 0.668717 pairwise loss 47.127233
valid 736 RMSE 1.421297 Pearson 0.697953 Spearman 0.698083 avg pairwise AUC 0.923318
test  1656 RMSE 1.46789 Pearson 0.659464 Spearman 0.657011 avg pairwise AUC 0.920385
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.269098 affinity loss 0.615131 pairwise loss 46.539668
valid 736 RMSE 1.437501 Pearson 0.693966 Spearman 0.69473 avg pairwise AUC 0.923805
test  1656 RMSE 1.46789 Pearson 0.659464 Spearman 0.657011 avg pairwise AUC 0.920385
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.21076 affinity loss 0.606498 pairwise loss 46.042623
valid 736 RMSE 1.418348 Pearson 0.703351 Spearman 0.703013 avg pairwise AUC 0.924155
test  1656 RMSE 1.46789 Pearson 0.659464 Spearman 0.657011 avg pairwise AUC 0.920385
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.085987 affinity loss 0.555218 pairwise loss 45.307697
valid 736 RMSE 1.441257 Pearson 0.700155 Spearman 0.709879 avg pairwise AUC 0.922839
test  1656 RMSE 1.46789 Pearson 0.659464 Spearman 0.657011 avg pairwise AUC 0.920385
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.023182 affinity loss 0.543206 pairwise loss 44.799761
valid 736 RMSE 1.465228 Pearson 0.688888 Spearman 0.69704 avg pairwise AUC 0.923974
test  1656 RMSE 1.46789 Pearson 0.659464 Spearman 0.657011 avg pairwise AUC 0.920385
Finished Training
------------------------------
repeat 3 fold 2 begin
train num: 5103 valid num: 598 test num: 1288
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 591.106356 affinity loss 16.796898 pairwise loss 5743.09483
train 5103 RMSE 1.752626 Pearson 0.57219 Spearman 0.579195 avg pairwise AUC 0.851427
valid 598 RMSE 1.80474 Pearson 0.545109 Spearman 0.583976 avg pairwise AUC 0.839883
test  1288 RMSE 1.641184 Pearson 0.597661 Spearman 0.597696 avg pairwise AUC 0.843547
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 12.964024 affinity loss 3.042316 pairwise loss 99.217077
valid 598 RMSE 1.89683 Pearson 0.578179 Spearman 0.619314 avg pairwise AUC 0.896142
test  1288 RMSE 1.641184 Pearson 0.597661 Spearman 0.597696 avg pairwise AUC 0.843547
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 11.765913 affinity loss 2.809065 pairwise loss 89.568472
valid 598 RMSE 1.874708 Pearson 0.589834 Spearman 0.62818 avg pairwise AUC 0.91098
test  1288 RMSE 1.641184 Pearson 0.597661 Spearman 0.597696 avg pairwise AUC 0.843547
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 10.877127 affinity loss 2.512608 pairwise loss 83.645183
valid 598 RMSE 2.167235 Pearson 0.600071 Spearman 0.640627 avg pairwise AUC 0.921687
test  1288 RMSE 1.641184 Pearson 0.597661 Spearman 0.597696 avg pairwise AUC 0.843547
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.324591 affinity loss 2.468279 pairwise loss 78.563119
valid 598 RMSE 1.692596 Pearson 0.614498 Spearman 0.649104 avg pairwise AUC 0.925537
test  1288 RMSE 1.48175 Pearson 0.675162 Spearman 0.674437 avg pairwise AUC 0.92791
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.768944 affinity loss 2.221379 pairwise loss 75.475647
valid 598 RMSE 1.7221 Pearson 0.627839 Spearman 0.664539 avg pairwise AUC 0.927437
test  1288 RMSE 1.48175 Pearson 0.675162 Spearman 0.674437 avg pairwise AUC 0.92791
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.341124 affinity loss 2.051141 pairwise loss 72.899826
valid 598 RMSE 1.730656 Pearson 0.61544 Spearman 0.648873 avg pairwise AUC 0.933309
test  1288 RMSE 1.48175 Pearson 0.675162 Spearman 0.674437 avg pairwise AUC 0.92791
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.055347 affinity loss 1.955175 pairwise loss 71.001719
valid 598 RMSE 1.650633 Pearson 0.633403 Spearman 0.66998 avg pairwise AUC 0.933433
test  1288 RMSE 1.409381 Pearson 0.706615 Spearman 0.709159 avg pairwise AUC 0.934403
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.672859 affinity loss 1.755528 pairwise loss 69.173306
valid 598 RMSE 1.627317 Pearson 0.652183 Spearman 0.681894 avg pairwise AUC 0.932571
test  1288 RMSE 1.38833 Pearson 0.723713 Spearman 0.720504 avg pairwise AUC 0.93523
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.412523 affinity loss 1.696361 pairwise loss 67.161626
valid 598 RMSE 1.618826 Pearson 0.652177 Spearman 0.680789 avg pairwise AUC 0.936078
test  1288 RMSE 1.344512 Pearson 0.735226 Spearman 0.729672 avg pairwise AUC 0.937025
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.035861 affinity loss 1.544425 pairwise loss 64.914361
train 5103 RMSE 1.100092 Pearson 0.844729 Spearman 0.846144 avg pairwise AUC 0.974105
valid 598 RMSE 1.640452 Pearson 0.637032 Spearman 0.659653 avg pairwise AUC 0.936729
test  1288 RMSE 1.344512 Pearson 0.735226 Spearman 0.729672 avg pairwise AUC 0.937025
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 7.861859 affinity loss 1.428607 pairwise loss 64.332518
valid 598 RMSE 1.601479 Pearson 0.653931 Spearman 0.6798 avg pairwise AUC 0.937227
test  1288 RMSE 1.360768 Pearson 0.727182 Spearman 0.726528 avg pairwise AUC 0.937267
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.706185 affinity loss 1.430861 pairwise loss 62.753236
valid 598 RMSE 1.61375 Pearson 0.660365 Spearman 0.685791 avg pairwise AUC 0.937299
test  1288 RMSE 1.360768 Pearson 0.727182 Spearman 0.726528 avg pairwise AUC 0.937267
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.550021 affinity loss 1.349765 pairwise loss 62.002557
valid 598 RMSE 1.682794 Pearson 0.66595 Spearman 0.690384 avg pairwise AUC 0.937223
test  1288 RMSE 1.360768 Pearson 0.727182 Spearman 0.726528 avg pairwise AUC 0.937267
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.380569 affinity loss 1.267085 pairwise loss 61.134841
valid 598 RMSE 1.56423 Pearson 0.679927 Spearman 0.697481 avg pairwise AUC 0.939405
test  1288 RMSE 1.360757 Pearson 0.735195 Spearman 0.73127 avg pairwise AUC 0.939692
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.174493 affinity loss 1.214031 pairwise loss 59.604619
valid 598 RMSE 1.570062 Pearson 0.689472 Spearman 0.703481 avg pairwise AUC 0.940102
test  1288 RMSE 1.360757 Pearson 0.735195 Spearman 0.73127 avg pairwise AUC 0.939692
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 7.074811 affinity loss 1.162467 pairwise loss 59.123436
valid 598 RMSE 1.645383 Pearson 0.656846 Spearman 0.679805 avg pairwise AUC 0.941023
test  1288 RMSE 1.360757 Pearson 0.735195 Spearman 0.73127 avg pairwise AUC 0.939692
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.827085 affinity loss 1.072674 pairwise loss 57.544109
valid 598 RMSE 1.646411 Pearson 0.645083 Spearman 0.67351 avg pairwise AUC 0.941442
test  1288 RMSE 1.360757 Pearson 0.735195 Spearman 0.73127 avg pairwise AUC 0.939692
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.769249 affinity loss 1.087185 pairwise loss 56.820645
valid 598 RMSE 1.617113 Pearson 0.661392 Spearman 0.678125 avg pairwise AUC 0.941358
test  1288 RMSE 1.360757 Pearson 0.735195 Spearman 0.73127 avg pairwise AUC 0.939692
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.191025 affinity loss 0.837154 pairwise loss 53.538709
valid 598 RMSE 1.622212 Pearson 0.669644 Spearman 0.679164 avg pairwise AUC 0.94376
test  1288 RMSE 1.360757 Pearson 0.735195 Spearman 0.73127 avg pairwise AUC 0.939692
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 6.018073 affinity loss 0.816552 pairwise loss 52.015209
train 5103 RMSE 0.880586 Pearson 0.918384 Spearman 0.917662 avg pairwise AUC 0.98801
valid 598 RMSE 1.633376 Pearson 0.677976 Spearman 0.695065 avg pairwise AUC 0.943383
test  1288 RMSE 1.360757 Pearson 0.735195 Spearman 0.73127 avg pairwise AUC 0.939692
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.846594 affinity loss 0.723154 pairwise loss 51.234401
valid 598 RMSE 1.608715 Pearson 0.680754 Spearman 0.692859 avg pairwise AUC 0.943442
test  1288 RMSE 1.360757 Pearson 0.735195 Spearman 0.73127 avg pairwise AUC 0.939692
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.747646 affinity loss 0.68941 pairwise loss 50.582359
valid 598 RMSE 1.588436 Pearson 0.671673 Spearman 0.694655 avg pairwise AUC 0.943706
test  1288 RMSE 1.360757 Pearson 0.735195 Spearman 0.73127 avg pairwise AUC 0.939692
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.651359 affinity loss 0.65862 pairwise loss 49.927384
valid 598 RMSE 1.634125 Pearson 0.667403 Spearman 0.682101 avg pairwise AUC 0.943185
test  1288 RMSE 1.360757 Pearson 0.735195 Spearman 0.73127 avg pairwise AUC 0.939692
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.566677 affinity loss 0.642024 pairwise loss 49.246533
valid 598 RMSE 1.53446 Pearson 0.70027 Spearman 0.710386 avg pairwise AUC 0.943991
test  1288 RMSE 1.377548 Pearson 0.733787 Spearman 0.726727 avg pairwise AUC 0.942636
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.472216 affinity loss 0.607354 pairwise loss 48.648623
valid 598 RMSE 1.590729 Pearson 0.675049 Spearman 0.685359 avg pairwise AUC 0.944479
test  1288 RMSE 1.377548 Pearson 0.733787 Spearman 0.726727 avg pairwise AUC 0.942636
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.371654 affinity loss 0.563258 pairwise loss 48.083961
valid 598 RMSE 1.615699 Pearson 0.672536 Spearman 0.691395 avg pairwise AUC 0.944542
test  1288 RMSE 1.377548 Pearson 0.733787 Spearman 0.726727 avg pairwise AUC 0.942636
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.286681 affinity loss 0.54431 pairwise loss 47.423712
valid 598 RMSE 1.654125 Pearson 0.675943 Spearman 0.688866 avg pairwise AUC 0.943957
test  1288 RMSE 1.377548 Pearson 0.733787 Spearman 0.726727 avg pairwise AUC 0.942636
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.21295 affinity loss 0.520287 pairwise loss 46.926626
valid 598 RMSE 1.600404 Pearson 0.678626 Spearman 0.693415 avg pairwise AUC 0.944272
test  1288 RMSE 1.377548 Pearson 0.733787 Spearman 0.726727 avg pairwise AUC 0.942636
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.167868 affinity loss 0.526347 pairwise loss 46.415205
valid 598 RMSE 1.598808 Pearson 0.683061 Spearman 0.697397 avg pairwise AUC 0.943238
test  1288 RMSE 1.377548 Pearson 0.733787 Spearman 0.726727 avg pairwise AUC 0.942636
Finished Training
------------------------------
repeat 3 fold 3 begin
train num: 5078 valid num: 636 test num: 1275
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 1764.262003 affinity loss 15.00575 pairwise loss 17492.561472
train 5078 RMSE 1.767937 Pearson 0.573146 Spearman 0.586079 avg pairwise AUC 0.854487
valid 636 RMSE 1.760079 Pearson 0.572222 Spearman 0.574983 avg pairwise AUC 0.855482
test  1275 RMSE 1.858931 Pearson 0.536017 Spearman 0.545816 avg pairwise AUC 0.839138
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 12.91465 affinity loss 3.057631 pairwise loss 98.570186
valid 636 RMSE 1.795557 Pearson 0.609834 Spearman 0.607395 avg pairwise AUC 0.899454
test  1275 RMSE 1.858931 Pearson 0.536017 Spearman 0.545816 avg pairwise AUC 0.839138
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 11.646283 affinity loss 2.734251 pairwise loss 89.120316
valid 636 RMSE 1.700367 Pearson 0.620242 Spearman 0.62326 avg pairwise AUC 0.917382
test  1275 RMSE 1.718358 Pearson 0.595239 Spearman 0.607131 avg pairwise AUC 0.901547
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 11.010185 affinity loss 2.728 pairwise loss 82.821848
valid 636 RMSE 1.6281 Pearson 0.623682 Spearman 0.616874 avg pairwise AUC 0.927352
test  1275 RMSE 1.646837 Pearson 0.607389 Spearman 0.616761 avg pairwise AUC 0.911551
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.405424 affinity loss 2.520627 pairwise loss 78.847967
valid 636 RMSE 1.58585 Pearson 0.638432 Spearman 0.644414 avg pairwise AUC 0.93146
test  1275 RMSE 1.599186 Pearson 0.625126 Spearman 0.637846 avg pairwise AUC 0.917055
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.750026 affinity loss 2.27665 pairwise loss 74.733755
valid 636 RMSE 1.766205 Pearson 0.651878 Spearman 0.645557 avg pairwise AUC 0.935924
test  1275 RMSE 1.599186 Pearson 0.625126 Spearman 0.637846 avg pairwise AUC 0.917055
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.233626 affinity loss 2.07257 pairwise loss 71.610552
valid 636 RMSE 1.583051 Pearson 0.662793 Spearman 0.662722 avg pairwise AUC 0.932535
test  1275 RMSE 1.609289 Pearson 0.644242 Spearman 0.659749 avg pairwise AUC 0.919141
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 8.972171 affinity loss 1.957049 pairwise loss 70.151214
valid 636 RMSE 1.560742 Pearson 0.675151 Spearman 0.673795 avg pairwise AUC 0.940571
test  1275 RMSE 1.550841 Pearson 0.668303 Spearman 0.675601 avg pairwise AUC 0.924197
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.684449 affinity loss 1.84554 pairwise loss 68.38909
valid 636 RMSE 1.536065 Pearson 0.672505 Spearman 0.66517 avg pairwise AUC 0.939225
test  1275 RMSE 1.531072 Pearson 0.669434 Spearman 0.676111 avg pairwise AUC 0.924336
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.312087 affinity loss 1.643435 pairwise loss 66.686514
valid 636 RMSE 1.564628 Pearson 0.668178 Spearman 0.656514 avg pairwise AUC 0.941157
test  1275 RMSE 1.531072 Pearson 0.669434 Spearman 0.676111 avg pairwise AUC 0.924336
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.077191 affinity loss 1.534507 pairwise loss 65.426845
train 5078 RMSE 1.172551 Pearson 0.828326 Spearman 0.829413 avg pairwise AUC 0.972158
valid 636 RMSE 1.532786 Pearson 0.683142 Spearman 0.67934 avg pairwise AUC 0.941354
test  1275 RMSE 1.526501 Pearson 0.67761 Spearman 0.692723 avg pairwise AUC 0.926274
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 7.840819 affinity loss 1.522183 pairwise loss 63.186357
valid 636 RMSE 1.522326 Pearson 0.691126 Spearman 0.689071 avg pairwise AUC 0.942505
test  1275 RMSE 1.527629 Pearson 0.686944 Spearman 0.695082 avg pairwise AUC 0.927263
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.586963 affinity loss 1.341215 pairwise loss 62.457484
valid 636 RMSE 1.468944 Pearson 0.711267 Spearman 0.706227 avg pairwise AUC 0.943494
test  1275 RMSE 1.490728 Pearson 0.696096 Spearman 0.697657 avg pairwise AUC 0.928154
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.373471 affinity loss 1.25505 pairwise loss 61.184208
valid 636 RMSE 1.431601 Pearson 0.716365 Spearman 0.709164 avg pairwise AUC 0.943381
test  1275 RMSE 1.469331 Pearson 0.695874 Spearman 0.703173 avg pairwise AUC 0.92883
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.185109 affinity loss 1.221396 pairwise loss 59.63713
valid 636 RMSE 1.488009 Pearson 0.698081 Spearman 0.688103 avg pairwise AUC 0.944494
test  1275 RMSE 1.469331 Pearson 0.695874 Spearman 0.703173 avg pairwise AUC 0.92883
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.036344 affinity loss 1.165193 pairwise loss 58.711512
valid 636 RMSE 1.548527 Pearson 0.708947 Spearman 0.69931 avg pairwise AUC 0.946322
test  1275 RMSE 1.469331 Pearson 0.695874 Spearman 0.703173 avg pairwise AUC 0.92883
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 6.901115 affinity loss 1.163463 pairwise loss 57.376515
valid 636 RMSE 1.5039 Pearson 0.687821 Spearman 0.680092 avg pairwise AUC 0.946688
test  1275 RMSE 1.469331 Pearson 0.695874 Spearman 0.703173 avg pairwise AUC 0.92883
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.801933 affinity loss 1.116383 pairwise loss 56.855494
valid 636 RMSE 1.649153 Pearson 0.712872 Spearman 0.708308 avg pairwise AUC 0.945192
test  1275 RMSE 1.469331 Pearson 0.695874 Spearman 0.703173 avg pairwise AUC 0.92883
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.615973 affinity loss 0.985729 pairwise loss 56.302445
valid 636 RMSE 1.4613 Pearson 0.717385 Spearman 0.712976 avg pairwise AUC 0.947239
test  1275 RMSE 1.469331 Pearson 0.695874 Spearman 0.703173 avg pairwise AUC 0.92883
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.182122 affinity loss 0.873039 pairwise loss 53.09083
valid 636 RMSE 1.462303 Pearson 0.709571 Spearman 0.700089 avg pairwise AUC 0.948852
test  1275 RMSE 1.469331 Pearson 0.695874 Spearman 0.703173 avg pairwise AUC 0.92883
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 5.905666 affinity loss 0.768902 pairwise loss 51.367644
train 5078 RMSE 0.790671 Pearson 0.922848 Spearman 0.922108 avg pairwise AUC 0.987314
valid 636 RMSE 1.429495 Pearson 0.721384 Spearman 0.712396 avg pairwise AUC 0.948307
test  1275 RMSE 1.466959 Pearson 0.70041 Spearman 0.70027 avg pairwise AUC 0.93219
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.770627 affinity loss 0.73146 pairwise loss 50.391673
valid 636 RMSE 1.503922 Pearson 0.712467 Spearman 0.704512 avg pairwise AUC 0.948521
test  1275 RMSE 1.466959 Pearson 0.70041 Spearman 0.70027 avg pairwise AUC 0.93219
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.659556 affinity loss 0.688789 pairwise loss 49.707671
valid 636 RMSE 1.449123 Pearson 0.715974 Spearman 0.701821 avg pairwise AUC 0.948483
test  1275 RMSE 1.466959 Pearson 0.70041 Spearman 0.70027 avg pairwise AUC 0.93219
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.554446 affinity loss 0.644731 pairwise loss 49.097151
valid 636 RMSE 1.435726 Pearson 0.722355 Spearman 0.720059 avg pairwise AUC 0.948397
test  1275 RMSE 1.466959 Pearson 0.70041 Spearman 0.70027 avg pairwise AUC 0.93219
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.430738 affinity loss 0.596232 pairwise loss 48.34506
valid 636 RMSE 1.543694 Pearson 0.709568 Spearman 0.696259 avg pairwise AUC 0.948794
test  1275 RMSE 1.466959 Pearson 0.70041 Spearman 0.70027 avg pairwise AUC 0.93219
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.355731 affinity loss 0.577936 pairwise loss 47.777949
valid 636 RMSE 1.46012 Pearson 0.710693 Spearman 0.702927 avg pairwise AUC 0.949523
test  1275 RMSE 1.466959 Pearson 0.70041 Spearman 0.70027 avg pairwise AUC 0.93219
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.279436 affinity loss 0.581018 pairwise loss 46.984172
valid 636 RMSE 1.516116 Pearson 0.712507 Spearman 0.71036 avg pairwise AUC 0.949283
test  1275 RMSE 1.466959 Pearson 0.70041 Spearman 0.70027 avg pairwise AUC 0.93219
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.188688 affinity loss 0.534166 pairwise loss 46.545226
valid 636 RMSE 1.470015 Pearson 0.70898 Spearman 0.705498 avg pairwise AUC 0.949187
test  1275 RMSE 1.466959 Pearson 0.70041 Spearman 0.70027 avg pairwise AUC 0.93219
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.117932 affinity loss 0.516884 pairwise loss 46.010475
valid 636 RMSE 1.468716 Pearson 0.707395 Spearman 0.704257 avg pairwise AUC 0.94834
test  1275 RMSE 1.466959 Pearson 0.70041 Spearman 0.70027 avg pairwise AUC 0.93219
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.066742 affinity loss 0.494416 pairwise loss 45.723258
valid 636 RMSE 1.467575 Pearson 0.71053 Spearman 0.701891 avg pairwise AUC 0.949049
test  1275 RMSE 1.466959 Pearson 0.70041 Spearman 0.70027 avg pairwise AUC 0.93219
Finished Training
------------------------------
repeat 3 fold 4 begin
train num: 4932 valid num: 725 test num: 1332
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 1300.023651 affinity loss 30.425849 pairwise loss 12695.977284
train 4932 RMSE 1.670117 Pearson 0.571938 Spearman 0.579705 avg pairwise AUC 0.861663
valid 725 RMSE 1.973227 Pearson 0.571572 Spearman 0.601156 avg pairwise AUC 0.86336
test  1332 RMSE 1.687667 Pearson 0.550336 Spearman 0.563983 avg pairwise AUC 0.85305
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.331836 affinity loss 2.995793 pairwise loss 103.360435
valid 725 RMSE 1.756283 Pearson 0.659587 Spearman 0.696301 avg pairwise AUC 0.90134
test  1332 RMSE 1.573031 Pearson 0.606875 Spearman 0.6264 avg pairwise AUC 0.89167
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 11.943031 affinity loss 2.717308 pairwise loss 92.257229
valid 725 RMSE 1.765475 Pearson 0.662593 Spearman 0.698675 avg pairwise AUC 0.915765
test  1332 RMSE 1.573031 Pearson 0.606875 Spearman 0.6264 avg pairwise AUC 0.89167
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 11.025984 affinity loss 2.504817 pairwise loss 85.21167
valid 725 RMSE 1.738435 Pearson 0.669044 Spearman 0.704229 avg pairwise AUC 0.924079
test  1332 RMSE 1.560809 Pearson 0.634216 Spearman 0.654959 avg pairwise AUC 0.919618
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.62026 affinity loss 2.543931 pairwise loss 80.763286
valid 725 RMSE 1.762243 Pearson 0.684971 Spearman 0.715127 avg pairwise AUC 0.927713
test  1332 RMSE 1.560809 Pearson 0.634216 Spearman 0.654959 avg pairwise AUC 0.919618
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.947434 affinity loss 2.209582 pairwise loss 77.378517
valid 725 RMSE 1.719156 Pearson 0.70835 Spearman 0.730005 avg pairwise AUC 0.933348
test  1332 RMSE 1.495737 Pearson 0.665551 Spearman 0.682805 avg pairwise AUC 0.928301
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.454194 affinity loss 2.120072 pairwise loss 73.341218
valid 725 RMSE 1.617629 Pearson 0.715953 Spearman 0.74187 avg pairwise AUC 0.935727
test  1332 RMSE 1.468995 Pearson 0.673399 Spearman 0.689545 avg pairwise AUC 0.931877
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.180008 affinity loss 2.132958 pairwise loss 70.470505
valid 725 RMSE 1.672879 Pearson 0.704457 Spearman 0.740362 avg pairwise AUC 0.934696
test  1332 RMSE 1.468995 Pearson 0.673399 Spearman 0.689545 avg pairwise AUC 0.931877
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.760554 affinity loss 1.907342 pairwise loss 68.532115
valid 725 RMSE 1.658996 Pearson 0.719868 Spearman 0.742816 avg pairwise AUC 0.938881
test  1332 RMSE 1.468995 Pearson 0.673399 Spearman 0.689545 avg pairwise AUC 0.931877
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.5839 affinity loss 1.946159 pairwise loss 66.377408
valid 725 RMSE 1.683671 Pearson 0.701741 Spearman 0.732173 avg pairwise AUC 0.939708
test  1332 RMSE 1.468995 Pearson 0.673399 Spearman 0.689545 avg pairwise AUC 0.931877
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.298013 affinity loss 1.813617 pairwise loss 64.843954
train 4932 RMSE 1.239158 Pearson 0.788325 Spearman 0.810281 avg pairwise AUC 0.975571
valid 725 RMSE 1.604348 Pearson 0.720529 Spearman 0.752089 avg pairwise AUC 0.941772
test  1332 RMSE 1.427487 Pearson 0.697301 Spearman 0.724244 avg pairwise AUC 0.935526
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 8.048756 affinity loss 1.661665 pairwise loss 63.87091
valid 725 RMSE 1.701469 Pearson 0.719902 Spearman 0.747427 avg pairwise AUC 0.943653
test  1332 RMSE 1.427487 Pearson 0.697301 Spearman 0.724244 avg pairwise AUC 0.935526
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.857432 affinity loss 1.623072 pairwise loss 62.343601
valid 725 RMSE 1.854117 Pearson 0.731042 Spearman 0.751327 avg pairwise AUC 0.942243
test  1332 RMSE 1.427487 Pearson 0.697301 Spearman 0.724244 avg pairwise AUC 0.935526
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.625572 affinity loss 1.479402 pairwise loss 61.461701
valid 725 RMSE 1.60103 Pearson 0.729467 Spearman 0.755055 avg pairwise AUC 0.943765
test  1332 RMSE 1.461217 Pearson 0.703603 Spearman 0.720834 avg pairwise AUC 0.938942
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.552546 affinity loss 1.477239 pairwise loss 60.753075
valid 725 RMSE 1.909151 Pearson 0.735594 Spearman 0.755404 avg pairwise AUC 0.945122
test  1332 RMSE 1.461217 Pearson 0.703603 Spearman 0.720834 avg pairwise AUC 0.938942
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.341169 affinity loss 1.381036 pairwise loss 59.601326
valid 725 RMSE 1.622341 Pearson 0.715974 Spearman 0.733227 avg pairwise AUC 0.944446
test  1332 RMSE 1.461217 Pearson 0.703603 Spearman 0.720834 avg pairwise AUC 0.938942
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 7.177989 affinity loss 1.318244 pairwise loss 58.59745
valid 725 RMSE 1.825578 Pearson 0.73612 Spearman 0.761514 avg pairwise AUC 0.943446
test  1332 RMSE 1.461217 Pearson 0.703603 Spearman 0.720834 avg pairwise AUC 0.938942
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 7.061726 affinity loss 1.254668 pairwise loss 58.070577
valid 725 RMSE 1.597501 Pearson 0.735615 Spearman 0.763962 avg pairwise AUC 0.943617
test  1332 RMSE 1.49729 Pearson 0.700445 Spearman 0.718393 avg pairwise AUC 0.938144
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.905149 affinity loss 1.226301 pairwise loss 56.788485
valid 725 RMSE 1.56107 Pearson 0.738379 Spearman 0.756337 avg pairwise AUC 0.945424
test  1332 RMSE 1.411485 Pearson 0.707648 Spearman 0.728696 avg pairwise AUC 0.940188
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.386857 affinity loss 1.016299 pairwise loss 53.70557
valid 725 RMSE 1.6297 Pearson 0.749626 Spearman 0.766755 avg pairwise AUC 0.94753
test  1332 RMSE 1.411485 Pearson 0.707648 Spearman 0.728696 avg pairwise AUC 0.940188
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 6.167077 affinity loss 0.921038 pairwise loss 52.46039
train 4932 RMSE 0.845029 Pearson 0.906965 Spearman 0.903694 avg pairwise AUC 0.9887
valid 725 RMSE 1.523064 Pearson 0.754041 Spearman 0.768303 avg pairwise AUC 0.946617
test  1332 RMSE 1.4193 Pearson 0.710185 Spearman 0.727023 avg pairwise AUC 0.940285
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 6.042856 affinity loss 0.876012 pairwise loss 51.668436
valid 725 RMSE 1.552084 Pearson 0.743036 Spearman 0.762126 avg pairwise AUC 0.947649
test  1332 RMSE 1.4193 Pearson 0.710185 Spearman 0.727023 avg pairwise AUC 0.940285
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.936191 affinity loss 0.832365 pairwise loss 51.038258
valid 725 RMSE 1.522236 Pearson 0.756934 Spearman 0.772298 avg pairwise AUC 0.946662
test  1332 RMSE 1.478615 Pearson 0.70962 Spearman 0.733018 avg pairwise AUC 0.94106
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.832079 affinity loss 0.790746 pairwise loss 50.413335
valid 725 RMSE 1.578882 Pearson 0.730669 Spearman 0.754441 avg pairwise AUC 0.946328
test  1332 RMSE 1.478615 Pearson 0.70962 Spearman 0.733018 avg pairwise AUC 0.94106
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.741381 affinity loss 0.754041 pairwise loss 49.873401
valid 725 RMSE 1.527849 Pearson 0.758555 Spearman 0.764104 avg pairwise AUC 0.946527
test  1332 RMSE 1.478615 Pearson 0.70962 Spearman 0.733018 avg pairwise AUC 0.94106
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.6525 affinity loss 0.725128 pairwise loss 49.273717
valid 725 RMSE 1.532114 Pearson 0.756015 Spearman 0.765854 avg pairwise AUC 0.947258
test  1332 RMSE 1.478615 Pearson 0.70962 Spearman 0.733018 avg pairwise AUC 0.94106
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.542454 affinity loss 0.661118 pairwise loss 48.813359
valid 725 RMSE 1.546248 Pearson 0.747399 Spearman 0.764769 avg pairwise AUC 0.947237
test  1332 RMSE 1.478615 Pearson 0.70962 Spearman 0.733018 avg pairwise AUC 0.94106
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.509549 affinity loss 0.679595 pairwise loss 48.29954
valid 725 RMSE 1.572746 Pearson 0.735617 Spearman 0.755913 avg pairwise AUC 0.946874
test  1332 RMSE 1.478615 Pearson 0.70962 Spearman 0.733018 avg pairwise AUC 0.94106
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.394306 affinity loss 0.614643 pairwise loss 47.796629
valid 725 RMSE 1.532439 Pearson 0.757113 Spearman 0.773983 avg pairwise AUC 0.945864
test  1332 RMSE 1.478615 Pearson 0.70962 Spearman 0.733018 avg pairwise AUC 0.94106
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.357176 affinity loss 0.646494 pairwise loss 47.10681
valid 725 RMSE 1.582869 Pearson 0.756088 Spearman 0.754295 avg pairwise AUC 0.947365
test  1332 RMSE 1.478615 Pearson 0.70962 Spearman 0.733018 avg pairwise AUC 0.94106
Finished Training
------------------------------
repeat 3 fold 5 begin
train num: 4912 valid num: 639 test num: 1438
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 5374.389747 affinity loss 26.666397 pairwise loss 53477.233818
train 4912 RMSE 1.816554 Pearson 0.575523 Spearman 0.583024 avg pairwise AUC 0.837177
valid 639 RMSE 1.796537 Pearson 0.571622 Spearman 0.585986 avg pairwise AUC 0.83017
test  1438 RMSE 1.918685 Pearson 0.572777 Spearman 0.595072 avg pairwise AUC 0.833496
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.279718 affinity loss 3.018412 pairwise loss 102.613053
valid 639 RMSE 1.700898 Pearson 0.593184 Spearman 0.61214 avg pairwise AUC 0.887083
test  1438 RMSE 1.858718 Pearson 0.595492 Spearman 0.625704 avg pairwise AUC 0.889531
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 12.293497 affinity loss 2.873206 pairwise loss 94.202908
valid 639 RMSE 1.552117 Pearson 0.608528 Spearman 0.627946 avg pairwise AUC 0.907595
test  1438 RMSE 1.870456 Pearson 0.616144 Spearman 0.638255 avg pairwise AUC 0.909455
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 11.192471 affinity loss 2.534981 pairwise loss 86.574898
valid 639 RMSE 2.688516 Pearson 0.62179 Spearman 0.637197 avg pairwise AUC 0.912843
test  1438 RMSE 1.870456 Pearson 0.616144 Spearman 0.638255 avg pairwise AUC 0.909455
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.580053 affinity loss 2.443669 pairwise loss 81.36383
valid 639 RMSE 1.639566 Pearson 0.644539 Spearman 0.661618 avg pairwise AUC 0.917074
test  1438 RMSE 1.870456 Pearson 0.616144 Spearman 0.638255 avg pairwise AUC 0.909455
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.858475 affinity loss 2.231613 pairwise loss 76.268626
valid 639 RMSE 1.564296 Pearson 0.65848 Spearman 0.675109 avg pairwise AUC 0.926101
test  1438 RMSE 1.870456 Pearson 0.616144 Spearman 0.638255 avg pairwise AUC 0.909455
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.506936 affinity loss 2.176062 pairwise loss 73.308742
valid 639 RMSE 1.523977 Pearson 0.655278 Spearman 0.668832 avg pairwise AUC 0.926226
test  1438 RMSE 1.693451 Pearson 0.657312 Spearman 0.676046 avg pairwise AUC 0.929267
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.208863 affinity loss 2.094998 pairwise loss 71.138647
valid 639 RMSE 1.415759 Pearson 0.681423 Spearman 0.70137 avg pairwise AUC 0.929115
test  1438 RMSE 1.630183 Pearson 0.679441 Spearman 0.693461 avg pairwise AUC 0.931962
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.837233 affinity loss 1.901567 pairwise loss 69.356658
valid 639 RMSE 1.44441 Pearson 0.672804 Spearman 0.690581 avg pairwise AUC 0.92978
test  1438 RMSE 1.630183 Pearson 0.679441 Spearman 0.693461 avg pairwise AUC 0.931962
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.512742 affinity loss 1.74311 pairwise loss 67.696314
valid 639 RMSE 1.416736 Pearson 0.66618 Spearman 0.681719 avg pairwise AUC 0.930907
test  1438 RMSE 1.630183 Pearson 0.679441 Spearman 0.693461 avg pairwise AUC 0.931962
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.255539 affinity loss 1.6591 pairwise loss 65.964392
train 4912 RMSE 1.149543 Pearson 0.820098 Spearman 0.819123 avg pairwise AUC 0.972593
valid 639 RMSE 1.450204 Pearson 0.674215 Spearman 0.685306 avg pairwise AUC 0.931379
test  1438 RMSE 1.630183 Pearson 0.679441 Spearman 0.693461 avg pairwise AUC 0.931962
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 8.145951 affinity loss 1.682147 pairwise loss 64.638032
valid 639 RMSE 1.396193 Pearson 0.684398 Spearman 0.698067 avg pairwise AUC 0.934643
test  1438 RMSE 1.633473 Pearson 0.687474 Spearman 0.703022 avg pairwise AUC 0.936769
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.813853 affinity loss 1.420061 pairwise loss 63.93791
valid 639 RMSE 1.446357 Pearson 0.684381 Spearman 0.696508 avg pairwise AUC 0.93508
test  1438 RMSE 1.633473 Pearson 0.687474 Spearman 0.703022 avg pairwise AUC 0.936769
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.669472 affinity loss 1.412046 pairwise loss 62.574265
valid 639 RMSE 1.441173 Pearson 0.683069 Spearman 0.693666 avg pairwise AUC 0.934995
test  1438 RMSE 1.633473 Pearson 0.687474 Spearman 0.703022 avg pairwise AUC 0.936769
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.441424 affinity loss 1.302852 pairwise loss 61.385721
valid 639 RMSE 1.427435 Pearson 0.678925 Spearman 0.689757 avg pairwise AUC 0.938282
test  1438 RMSE 1.633473 Pearson 0.687474 Spearman 0.703022 avg pairwise AUC 0.936769
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.266015 affinity loss 1.251803 pairwise loss 60.142113
valid 639 RMSE 1.467476 Pearson 0.637131 Spearman 0.640228 avg pairwise AUC 0.936643
test  1438 RMSE 1.633473 Pearson 0.687474 Spearman 0.703022 avg pairwise AUC 0.936769
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 7.146049 affinity loss 1.281477 pairwise loss 58.645717
valid 639 RMSE 1.436766 Pearson 0.685526 Spearman 0.692996 avg pairwise AUC 0.936343
test  1438 RMSE 1.633473 Pearson 0.687474 Spearman 0.703022 avg pairwise AUC 0.936769
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.957542 affinity loss 1.125406 pairwise loss 58.321362
valid 639 RMSE 1.472222 Pearson 0.683462 Spearman 0.692979 avg pairwise AUC 0.937336
test  1438 RMSE 1.633473 Pearson 0.687474 Spearman 0.703022 avg pairwise AUC 0.936769
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.827514 affinity loss 1.126548 pairwise loss 57.009659
valid 639 RMSE 1.416271 Pearson 0.687809 Spearman 0.694564 avg pairwise AUC 0.937928
test  1438 RMSE 1.633473 Pearson 0.687474 Spearman 0.703022 avg pairwise AUC 0.936769
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.286274 affinity loss 0.886442 pairwise loss 53.998325
valid 639 RMSE 1.508857 Pearson 0.689426 Spearman 0.699236 avg pairwise AUC 0.937892
test  1438 RMSE 1.633473 Pearson 0.687474 Spearman 0.703022 avg pairwise AUC 0.936769
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 6.086312 affinity loss 0.816046 pairwise loss 52.70266
train 4912 RMSE 0.818364 Pearson 0.913066 Spearman 0.911561 avg pairwise AUC 0.987507
valid 639 RMSE 1.364195 Pearson 0.709505 Spearman 0.719675 avg pairwise AUC 0.93819
test  1438 RMSE 1.550731 Pearson 0.716486 Spearman 0.718862 avg pairwise AUC 0.942387
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.946527 affinity loss 0.756897 pairwise loss 51.896303
valid 639 RMSE 1.388404 Pearson 0.705607 Spearman 0.716282 avg pairwise AUC 0.938235
test  1438 RMSE 1.550731 Pearson 0.716486 Spearman 0.718862 avg pairwise AUC 0.942387
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.844178 affinity loss 0.734516 pairwise loss 51.096622
valid 639 RMSE 1.389193 Pearson 0.710298 Spearman 0.71697 avg pairwise AUC 0.939215
test  1438 RMSE 1.550731 Pearson 0.716486 Spearman 0.718862 avg pairwise AUC 0.942387
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.741143 affinity loss 0.694175 pairwise loss 50.469678
valid 639 RMSE 1.412266 Pearson 0.690619 Spearman 0.703499 avg pairwise AUC 0.938739
test  1438 RMSE 1.550731 Pearson 0.716486 Spearman 0.718862 avg pairwise AUC 0.942387
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.638484 affinity loss 0.645485 pairwise loss 49.929984
valid 639 RMSE 1.40456 Pearson 0.694575 Spearman 0.707509 avg pairwise AUC 0.939954
test  1438 RMSE 1.550731 Pearson 0.716486 Spearman 0.718862 avg pairwise AUC 0.942387
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.56741 affinity loss 0.634876 pairwise loss 49.325344
valid 639 RMSE 1.416216 Pearson 0.692665 Spearman 0.702907 avg pairwise AUC 0.939432
test  1438 RMSE 1.550731 Pearson 0.716486 Spearman 0.718862 avg pairwise AUC 0.942387
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.48428 affinity loss 0.610745 pairwise loss 48.735343
valid 639 RMSE 1.465684 Pearson 0.683133 Spearman 0.689817 avg pairwise AUC 0.9388
test  1438 RMSE 1.550731 Pearson 0.716486 Spearman 0.718862 avg pairwise AUC 0.942387
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.420201 affinity loss 0.593352 pairwise loss 48.268492
valid 639 RMSE 1.529193 Pearson 0.689458 Spearman 0.700907 avg pairwise AUC 0.939318
test  1438 RMSE 1.550731 Pearson 0.716486 Spearman 0.718862 avg pairwise AUC 0.942387
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.302637 affinity loss 0.539298 pairwise loss 47.633389
valid 639 RMSE 1.412275 Pearson 0.689491 Spearman 0.700042 avg pairwise AUC 0.93804
test  1438 RMSE 1.550731 Pearson 0.716486 Spearman 0.718862 avg pairwise AUC 0.942387
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.267407 affinity loss 0.532836 pairwise loss 47.345707
valid 639 RMSE 1.407877 Pearson 0.702978 Spearman 0.717237 avg pairwise AUC 0.940111
test  1438 RMSE 1.550731 Pearson 0.716486 Spearman 0.718862 avg pairwise AUC 0.942387
Finished Training
------------------------------
fold avg performance [1.46834861 0.70395326 0.70717739 0.93573155]
/home/junseok/workspace/monn/src/pdbbind_utils.py:198: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  data_pack = [np.array(data) for data in data_pack]
setting: new_compound
fold 0 train  5023 test  1332 valid  634
fold 1 train  5088 test  1229 valid  672
fold 2 train  4982 test  1355 valid  652
fold 3 train  5051 test  1313 valid  625
fold 4 train  4624 test  1760 valid  605
repeat 4 fold 1 begin
train num: 5023 valid num: 634 test num: 1332
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 1167.009966 affinity loss 7.741065 pairwise loss 11592.687962
train 5023 RMSE 1.657614 Pearson 0.594933 Spearman 0.599546 avg pairwise AUC 0.852909
valid 634 RMSE 1.695816 Pearson 0.554613 Spearman 0.563427 avg pairwise AUC 0.837278
test  1332 RMSE 1.71558 Pearson 0.580332 Spearman 0.591454 avg pairwise AUC 0.834972
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.292441 affinity loss 3.098656 pairwise loss 101.937851
valid 634 RMSE 1.614801 Pearson 0.591399 Spearman 0.587981 avg pairwise AUC 0.878385
test  1332 RMSE 1.666994 Pearson 0.593075 Spearman 0.605312 avg pairwise AUC 0.875896
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 11.988304 affinity loss 2.754885 pairwise loss 92.334184
valid 634 RMSE 1.926517 Pearson 0.551189 Spearman 0.557075 avg pairwise AUC 0.905429
test  1332 RMSE 1.666994 Pearson 0.593075 Spearman 0.605312 avg pairwise AUC 0.875896
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 11.25991 affinity loss 2.684428 pairwise loss 85.754823
valid 634 RMSE 1.653274 Pearson 0.599757 Spearman 0.599358 avg pairwise AUC 0.922002
test  1332 RMSE 1.666994 Pearson 0.593075 Spearman 0.605312 avg pairwise AUC 0.875896
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.478988 affinity loss 2.432895 pairwise loss 80.460924
valid 634 RMSE 1.631988 Pearson 0.603794 Spearman 0.609923 avg pairwise AUC 0.925647
test  1332 RMSE 1.666994 Pearson 0.593075 Spearman 0.605312 avg pairwise AUC 0.875896
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 10.016555 affinity loss 2.34874 pairwise loss 76.678149
valid 634 RMSE 1.56607 Pearson 0.622975 Spearman 0.624589 avg pairwise AUC 0.929095
test  1332 RMSE 1.568112 Pearson 0.651661 Spearman 0.669905 avg pairwise AUC 0.927618
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.513251 affinity loss 2.157325 pairwise loss 73.559252
valid 634 RMSE 1.540697 Pearson 0.636587 Spearman 0.631733 avg pairwise AUC 0.931222
test  1332 RMSE 1.531393 Pearson 0.672322 Spearman 0.687197 avg pairwise AUC 0.930588
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.155291 affinity loss 1.977822 pairwise loss 71.774696
valid 634 RMSE 1.665443 Pearson 0.64019 Spearman 0.64529 avg pairwise AUC 0.934884
test  1332 RMSE 1.531393 Pearson 0.672322 Spearman 0.687197 avg pairwise AUC 0.930588
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.896282 affinity loss 1.8993 pairwise loss 69.969823
valid 634 RMSE 1.511272 Pearson 0.658354 Spearman 0.658261 avg pairwise AUC 0.933238
test  1332 RMSE 1.472731 Pearson 0.706312 Spearman 0.717396 avg pairwise AUC 0.933374
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.478218 affinity loss 1.677209 pairwise loss 68.01009
valid 634 RMSE 1.669198 Pearson 0.650498 Spearman 0.654047 avg pairwise AUC 0.932317
test  1332 RMSE 1.472731 Pearson 0.706312 Spearman 0.717396 avg pairwise AUC 0.933374
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.238548 affinity loss 1.650562 pairwise loss 65.879857
train 5023 RMSE 1.176072 Pearson 0.824997 Spearman 0.828091 avg pairwise AUC 0.971723
valid 634 RMSE 1.614686 Pearson 0.641974 Spearman 0.649595 avg pairwise AUC 0.93454
test  1332 RMSE 1.472731 Pearson 0.706312 Spearman 0.717396 avg pairwise AUC 0.933374
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 8.037999 affinity loss 1.508421 pairwise loss 65.295776
valid 634 RMSE 1.584366 Pearson 0.656485 Spearman 0.664111 avg pairwise AUC 0.935427
test  1332 RMSE 1.472731 Pearson 0.706312 Spearman 0.717396 avg pairwise AUC 0.933374
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.790432 affinity loss 1.410828 pairwise loss 63.79604
valid 634 RMSE 1.514028 Pearson 0.673041 Spearman 0.666713 avg pairwise AUC 0.93661
test  1332 RMSE 1.472731 Pearson 0.706312 Spearman 0.717396 avg pairwise AUC 0.933374
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.605928 affinity loss 1.349476 pairwise loss 62.564517
valid 634 RMSE 1.494376 Pearson 0.681916 Spearman 0.678451 avg pairwise AUC 0.937597
test  1332 RMSE 1.456697 Pearson 0.722133 Spearman 0.726781 avg pairwise AUC 0.937576
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.399313 affinity loss 1.244541 pairwise loss 61.547715
valid 634 RMSE 1.523216 Pearson 0.657387 Spearman 0.651866 avg pairwise AUC 0.936914
test  1332 RMSE 1.456697 Pearson 0.722133 Spearman 0.726781 avg pairwise AUC 0.937576
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.219694 affinity loss 1.206224 pairwise loss 60.134699
valid 634 RMSE 1.52139 Pearson 0.668664 Spearman 0.665244 avg pairwise AUC 0.93807
test  1332 RMSE 1.456697 Pearson 0.722133 Spearman 0.726781 avg pairwise AUC 0.937576
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 7.037053 affinity loss 1.122377 pairwise loss 59.146765
valid 634 RMSE 1.475186 Pearson 0.686799 Spearman 0.678421 avg pairwise AUC 0.939641
test  1332 RMSE 1.43253 Pearson 0.722923 Spearman 0.730534 avg pairwise AUC 0.939904
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.935746 affinity loss 1.103543 pairwise loss 58.322032
valid 634 RMSE 1.598176 Pearson 0.66571 Spearman 0.661548 avg pairwise AUC 0.940926
test  1332 RMSE 1.43253 Pearson 0.722923 Spearman 0.730534 avg pairwise AUC 0.939904
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.763684 affinity loss 1.016296 pairwise loss 57.473875
valid 634 RMSE 1.550119 Pearson 0.673383 Spearman 0.66823 avg pairwise AUC 0.939904
test  1332 RMSE 1.43253 Pearson 0.722923 Spearman 0.730534 avg pairwise AUC 0.939904
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.282906 affinity loss 0.852011 pairwise loss 54.308952
valid 634 RMSE 1.543142 Pearson 0.687584 Spearman 0.682487 avg pairwise AUC 0.942072
test  1332 RMSE 1.43253 Pearson 0.722923 Spearman 0.730534 avg pairwise AUC 0.939904
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 6.058107 affinity loss 0.774995 pairwise loss 52.831124
train 5023 RMSE 0.784921 Pearson 0.922908 Spearman 0.92301 avg pairwise AUC 0.986527
valid 634 RMSE 1.483462 Pearson 0.690586 Spearman 0.683405 avg pairwise AUC 0.941524
test  1332 RMSE 1.43253 Pearson 0.722923 Spearman 0.730534 avg pairwise AUC 0.939904
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.915902 affinity loss 0.72317 pairwise loss 51.927328
valid 634 RMSE 1.516543 Pearson 0.674562 Spearman 0.670548 avg pairwise AUC 0.943178
test  1332 RMSE 1.43253 Pearson 0.722923 Spearman 0.730534 avg pairwise AUC 0.939904
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.817276 affinity loss 0.694739 pairwise loss 51.225367
valid 634 RMSE 1.550283 Pearson 0.679619 Spearman 0.671725 avg pairwise AUC 0.941314
test  1332 RMSE 1.43253 Pearson 0.722923 Spearman 0.730534 avg pairwise AUC 0.939904
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.736174 affinity loss 0.659781 pairwise loss 50.763924
valid 634 RMSE 1.550448 Pearson 0.683365 Spearman 0.672892 avg pairwise AUC 0.942275
test  1332 RMSE 1.43253 Pearson 0.722923 Spearman 0.730534 avg pairwise AUC 0.939904
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.639747 affinity loss 0.640309 pairwise loss 49.994379
valid 634 RMSE 1.532529 Pearson 0.685708 Spearman 0.680445 avg pairwise AUC 0.942831
test  1332 RMSE 1.43253 Pearson 0.722923 Spearman 0.730534 avg pairwise AUC 0.939904
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.552222 affinity loss 0.60693 pairwise loss 49.45292
valid 634 RMSE 1.499081 Pearson 0.692937 Spearman 0.686967 avg pairwise AUC 0.941736
test  1332 RMSE 1.43253 Pearson 0.722923 Spearman 0.730534 avg pairwise AUC 0.939904
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.488159 affinity loss 0.590412 pairwise loss 48.977471
valid 634 RMSE 1.536975 Pearson 0.684952 Spearman 0.676598 avg pairwise AUC 0.941691
test  1332 RMSE 1.43253 Pearson 0.722923 Spearman 0.730534 avg pairwise AUC 0.939904
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.418794 affinity loss 0.579779 pairwise loss 48.390149
valid 634 RMSE 1.547245 Pearson 0.659699 Spearman 0.655171 avg pairwise AUC 0.942104
test  1332 RMSE 1.43253 Pearson 0.722923 Spearman 0.730534 avg pairwise AUC 0.939904
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.331714 affinity loss 0.54772 pairwise loss 47.83994
valid 634 RMSE 1.513641 Pearson 0.677487 Spearman 0.669403 avg pairwise AUC 0.94262
test  1332 RMSE 1.43253 Pearson 0.722923 Spearman 0.730534 avg pairwise AUC 0.939904
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.280546 affinity loss 0.540326 pairwise loss 47.402203
valid 634 RMSE 1.539156 Pearson 0.667671 Spearman 0.667258 avg pairwise AUC 0.94175
test  1332 RMSE 1.43253 Pearson 0.722923 Spearman 0.730534 avg pairwise AUC 0.939904
Finished Training
------------------------------
repeat 4 fold 2 begin
train num: 5088 valid num: 672 test num: 1229
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 1019.629134 affinity loss 6.910381 pairwise loss 10127.186617
train 5088 RMSE 2.261442 Pearson 0.576184 Spearman 0.585719 avg pairwise AUC 0.847424
valid 672 RMSE 2.149892 Pearson 0.540432 Spearman 0.542339 avg pairwise AUC 0.835036
test  1229 RMSE 2.277825 Pearson 0.578492 Spearman 0.599087 avg pairwise AUC 0.845423
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.510746 affinity loss 3.210959 pairwise loss 102.997871
valid 672 RMSE 1.571971 Pearson 0.586653 Spearman 0.591941 avg pairwise AUC 0.884447
test  1229 RMSE 1.68003 Pearson 0.620053 Spearman 0.63816 avg pairwise AUC 0.888982
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 12.174268 affinity loss 2.842117 pairwise loss 93.321515
valid 672 RMSE 1.507497 Pearson 0.591309 Spearman 0.590085 avg pairwise AUC 0.903778
test  1229 RMSE 1.577549 Pearson 0.643776 Spearman 0.664303 avg pairwise AUC 0.910892
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 11.429511 affinity loss 2.739937 pairwise loss 86.895737
valid 672 RMSE 1.616067 Pearson 0.601143 Spearman 0.596016 avg pairwise AUC 0.914475
test  1229 RMSE 1.577549 Pearson 0.643776 Spearman 0.664303 avg pairwise AUC 0.910892
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.901339 affinity loss 2.763469 pairwise loss 81.378697
valid 672 RMSE 1.528409 Pearson 0.576969 Spearman 0.573974 avg pairwise AUC 0.918906
test  1229 RMSE 1.577549 Pearson 0.643776 Spearman 0.664303 avg pairwise AUC 0.910892
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 10.077887 affinity loss 2.324591 pairwise loss 77.532956
valid 672 RMSE 1.535722 Pearson 0.623825 Spearman 0.62878 avg pairwise AUC 0.925172
test  1229 RMSE 1.577549 Pearson 0.643776 Spearman 0.664303 avg pairwise AUC 0.910892
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.498767 affinity loss 2.215657 pairwise loss 72.831102
valid 672 RMSE 1.56231 Pearson 0.596192 Spearman 0.589788 avg pairwise AUC 0.92761
test  1229 RMSE 1.577549 Pearson 0.643776 Spearman 0.664303 avg pairwise AUC 0.910892
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.204803 affinity loss 2.129349 pairwise loss 70.754532
valid 672 RMSE 1.557731 Pearson 0.626103 Spearman 0.62441 avg pairwise AUC 0.930624
test  1229 RMSE 1.577549 Pearson 0.643776 Spearman 0.664303 avg pairwise AUC 0.910892
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.728185 affinity loss 1.883324 pairwise loss 68.448611
valid 672 RMSE 1.665724 Pearson 0.646781 Spearman 0.636872 avg pairwise AUC 0.934464
test  1229 RMSE 1.577549 Pearson 0.643776 Spearman 0.664303 avg pairwise AUC 0.910892
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.438746 affinity loss 1.815062 pairwise loss 66.236841
valid 672 RMSE 1.471483 Pearson 0.655798 Spearman 0.656067 avg pairwise AUC 0.934235
test  1229 RMSE 1.505983 Pearson 0.695709 Spearman 0.707764 avg pairwise AUC 0.936486
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.281932 affinity loss 1.737347 pairwise loss 65.445848
train 5088 RMSE 1.15622 Pearson 0.825972 Spearman 0.825416 avg pairwise AUC 0.972037
valid 672 RMSE 1.423016 Pearson 0.664929 Spearman 0.66157 avg pairwise AUC 0.934931
test  1229 RMSE 1.450092 Pearson 0.709768 Spearman 0.720863 avg pairwise AUC 0.936899
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 8.028735 affinity loss 1.623225 pairwise loss 64.0551
valid 672 RMSE 1.676998 Pearson 0.656276 Spearman 0.657256 avg pairwise AUC 0.935699
test  1229 RMSE 1.450092 Pearson 0.709768 Spearman 0.720863 avg pairwise AUC 0.936899
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.768932 affinity loss 1.441543 pairwise loss 63.273886
valid 672 RMSE 1.46792 Pearson 0.64433 Spearman 0.644661 avg pairwise AUC 0.936059
test  1229 RMSE 1.450092 Pearson 0.709768 Spearman 0.720863 avg pairwise AUC 0.936899
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.586232 affinity loss 1.403346 pairwise loss 61.828856
valid 672 RMSE 1.45001 Pearson 0.659559 Spearman 0.653282 avg pairwise AUC 0.934628
test  1229 RMSE 1.450092 Pearson 0.709768 Spearman 0.720863 avg pairwise AUC 0.936899
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.414681 affinity loss 1.381222 pairwise loss 60.334582
valid 672 RMSE 1.488614 Pearson 0.644105 Spearman 0.634952 avg pairwise AUC 0.937608
test  1229 RMSE 1.450092 Pearson 0.709768 Spearman 0.720863 avg pairwise AUC 0.936899
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.228967 affinity loss 1.244541 pairwise loss 59.84426
valid 672 RMSE 1.459301 Pearson 0.644934 Spearman 0.646596 avg pairwise AUC 0.938197
test  1229 RMSE 1.450092 Pearson 0.709768 Spearman 0.720863 avg pairwise AUC 0.936899
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 7.065115 affinity loss 1.185435 pairwise loss 58.796799
valid 672 RMSE 1.451806 Pearson 0.656959 Spearman 0.663441 avg pairwise AUC 0.937174
test  1229 RMSE 1.450092 Pearson 0.709768 Spearman 0.720863 avg pairwise AUC 0.936899
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.978281 affinity loss 1.181216 pairwise loss 57.970648
valid 672 RMSE 1.429906 Pearson 0.663455 Spearman 0.662306 avg pairwise AUC 0.940335
test  1229 RMSE 1.450092 Pearson 0.709768 Spearman 0.720863 avg pairwise AUC 0.936899
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.745607 affinity loss 1.057977 pairwise loss 56.8763
valid 672 RMSE 1.444371 Pearson 0.668054 Spearman 0.668537 avg pairwise AUC 0.940655
test  1229 RMSE 1.450092 Pearson 0.709768 Spearman 0.720863 avg pairwise AUC 0.936899
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.236737 affinity loss 0.881766 pairwise loss 53.549706
valid 672 RMSE 1.607048 Pearson 0.648393 Spearman 0.644355 avg pairwise AUC 0.941276
test  1229 RMSE 1.450092 Pearson 0.709768 Spearman 0.720863 avg pairwise AUC 0.936899
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 6.008846 affinity loss 0.799941 pairwise loss 52.089057
train 5088 RMSE 0.820511 Pearson 0.917532 Spearman 0.917071 avg pairwise AUC 0.986925
valid 672 RMSE 1.522601 Pearson 0.627935 Spearman 0.627648 avg pairwise AUC 0.941473
test  1229 RMSE 1.450092 Pearson 0.709768 Spearman 0.720863 avg pairwise AUC 0.936899
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.868757 affinity loss 0.764458 pairwise loss 51.04299
valid 672 RMSE 1.441524 Pearson 0.669652 Spearman 0.664706 avg pairwise AUC 0.941065
test  1229 RMSE 1.450092 Pearson 0.709768 Spearman 0.720863 avg pairwise AUC 0.936899
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.784649 affinity loss 0.721998 pairwise loss 50.62651
valid 672 RMSE 1.563802 Pearson 0.660145 Spearman 0.648822 avg pairwise AUC 0.940693
test  1229 RMSE 1.450092 Pearson 0.709768 Spearman 0.720863 avg pairwise AUC 0.936899
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.662861 affinity loss 0.691125 pairwise loss 49.717359
valid 672 RMSE 1.468922 Pearson 0.657564 Spearman 0.652704 avg pairwise AUC 0.940907
test  1229 RMSE 1.450092 Pearson 0.709768 Spearman 0.720863 avg pairwise AUC 0.936899
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.564577 affinity loss 0.64558 pairwise loss 49.189974
valid 672 RMSE 1.49996 Pearson 0.663094 Spearman 0.658008 avg pairwise AUC 0.940693
test  1229 RMSE 1.450092 Pearson 0.709768 Spearman 0.720863 avg pairwise AUC 0.936899
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.470336 affinity loss 0.589389 pairwise loss 48.809466
valid 672 RMSE 1.530087 Pearson 0.657068 Spearman 0.6531 avg pairwise AUC 0.941993
test  1229 RMSE 1.450092 Pearson 0.709768 Spearman 0.720863 avg pairwise AUC 0.936899
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.376784 affinity loss 0.572152 pairwise loss 48.046321
valid 672 RMSE 1.536867 Pearson 0.638495 Spearman 0.626463 avg pairwise AUC 0.941074
test  1229 RMSE 1.450092 Pearson 0.709768 Spearman 0.720863 avg pairwise AUC 0.936899
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.281208 affinity loss 0.542306 pairwise loss 47.389019
valid 672 RMSE 1.526528 Pearson 0.653675 Spearman 0.647936 avg pairwise AUC 0.94148
test  1229 RMSE 1.450092 Pearson 0.709768 Spearman 0.720863 avg pairwise AUC 0.936899
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.197727 affinity loss 0.523412 pairwise loss 46.743143
valid 672 RMSE 1.440236 Pearson 0.672182 Spearman 0.669779 avg pairwise AUC 0.942159
test  1229 RMSE 1.450092 Pearson 0.709768 Spearman 0.720863 avg pairwise AUC 0.936899
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.112273 affinity loss 0.506788 pairwise loss 46.054847
valid 672 RMSE 1.492157 Pearson 0.655385 Spearman 0.649848 avg pairwise AUC 0.940202
test  1229 RMSE 1.450092 Pearson 0.709768 Spearman 0.720863 avg pairwise AUC 0.936899
Finished Training
------------------------------
repeat 4 fold 3 begin
train num: 4982 valid num: 652 test num: 1355
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 2105.887566 affinity loss 16.413405 pairwise loss 20894.742286
train 4982 RMSE 1.943391 Pearson 0.57606 Spearman 0.58477 avg pairwise AUC 0.858089
valid 652 RMSE 2.138169 Pearson 0.503284 Spearman 0.495938 avg pairwise AUC 0.858086
test  1355 RMSE 2.086912 Pearson 0.6207 Spearman 0.632473 avg pairwise AUC 0.86178
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.294024 affinity loss 3.166016 pairwise loss 101.280073
valid 652 RMSE 1.9122 Pearson 0.540756 Spearman 0.53571 avg pairwise AUC 0.89498
test  1355 RMSE 1.872355 Pearson 0.633196 Spearman 0.649444 avg pairwise AUC 0.898513
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 12.302725 affinity loss 2.911614 pairwise loss 93.911102
valid 652 RMSE 1.819118 Pearson 0.542484 Spearman 0.536381 avg pairwise AUC 0.911556
test  1355 RMSE 1.768841 Pearson 0.659441 Spearman 0.672514 avg pairwise AUC 0.915933
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 11.415948 affinity loss 2.698889 pairwise loss 87.170588
valid 652 RMSE 1.808913 Pearson 0.601272 Spearman 0.592731 avg pairwise AUC 0.915598
test  1355 RMSE 1.819608 Pearson 0.660256 Spearman 0.672982 avg pairwise AUC 0.921805
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.59711 affinity loss 2.434068 pairwise loss 81.630425
valid 652 RMSE 1.615264 Pearson 0.617454 Spearman 0.616683 avg pairwise AUC 0.923004
test  1355 RMSE 1.633628 Pearson 0.675621 Spearman 0.690655 avg pairwise AUC 0.927524
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 10.017398 affinity loss 2.369719 pairwise loss 76.476792
valid 652 RMSE 1.772986 Pearson 0.631853 Spearman 0.640211 avg pairwise AUC 0.927942
test  1355 RMSE 1.633628 Pearson 0.675621 Spearman 0.690655 avg pairwise AUC 0.927524
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.528244 affinity loss 2.243437 pairwise loss 72.848061
valid 652 RMSE 1.610862 Pearson 0.629043 Spearman 0.62603 avg pairwise AUC 0.932516
test  1355 RMSE 1.623646 Pearson 0.68924 Spearman 0.692955 avg pairwise AUC 0.937498
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.070287 affinity loss 2.037248 pairwise loss 70.330381
valid 652 RMSE 1.535991 Pearson 0.65965 Spearman 0.664614 avg pairwise AUC 0.932306
test  1355 RMSE 1.607569 Pearson 0.685531 Spearman 0.70529 avg pairwise AUC 0.937531
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.857145 affinity loss 2.071879 pairwise loss 67.852658
valid 652 RMSE 1.519236 Pearson 0.664106 Spearman 0.672668 avg pairwise AUC 0.934657
test  1355 RMSE 1.553353 Pearson 0.70373 Spearman 0.700508 avg pairwise AUC 0.940132
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.440311 affinity loss 1.873058 pairwise loss 65.672528
valid 652 RMSE 1.524458 Pearson 0.665213 Spearman 0.667534 avg pairwise AUC 0.935455
test  1355 RMSE 1.553353 Pearson 0.70373 Spearman 0.700508 avg pairwise AUC 0.940132
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.168729 affinity loss 1.718949 pairwise loss 64.497797
train 4982 RMSE 1.177676 Pearson 0.82261 Spearman 0.824874 avg pairwise AUC 0.97436
valid 652 RMSE 1.523609 Pearson 0.682664 Spearman 0.686065 avg pairwise AUC 0.939345
test  1355 RMSE 1.553353 Pearson 0.70373 Spearman 0.700508 avg pairwise AUC 0.940132
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 7.859791 affinity loss 1.555111 pairwise loss 63.046797
valid 652 RMSE 1.483628 Pearson 0.696169 Spearman 0.691459 avg pairwise AUC 0.93759
test  1355 RMSE 1.53818 Pearson 0.717583 Spearman 0.719817 avg pairwise AUC 0.943922
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.71216 affinity loss 1.517049 pairwise loss 61.951105
valid 652 RMSE 1.567667 Pearson 0.69835 Spearman 0.684519 avg pairwise AUC 0.937664
test  1355 RMSE 1.53818 Pearson 0.717583 Spearman 0.719817 avg pairwise AUC 0.943922
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.518478 affinity loss 1.400845 pairwise loss 61.176325
valid 652 RMSE 1.515143 Pearson 0.67837 Spearman 0.682715 avg pairwise AUC 0.938966
test  1355 RMSE 1.53818 Pearson 0.717583 Spearman 0.719817 avg pairwise AUC 0.943922
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.305996 affinity loss 1.289228 pairwise loss 60.167679
valid 652 RMSE 1.435139 Pearson 0.710132 Spearman 0.709144 avg pairwise AUC 0.940633
test  1355 RMSE 1.554069 Pearson 0.705088 Spearman 0.716455 avg pairwise AUC 0.945603
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.14882 affinity loss 1.219764 pairwise loss 59.290558
valid 652 RMSE 1.764327 Pearson 0.701876 Spearman 0.700026 avg pairwise AUC 0.941297
test  1355 RMSE 1.554069 Pearson 0.705088 Spearman 0.716455 avg pairwise AUC 0.945603
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 7.005407 affinity loss 1.156683 pairwise loss 58.487232
valid 652 RMSE 1.444948 Pearson 0.706647 Spearman 0.706862 avg pairwise AUC 0.941628
test  1355 RMSE 1.554069 Pearson 0.705088 Spearman 0.716455 avg pairwise AUC 0.945603
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.851639 affinity loss 1.112079 pairwise loss 57.395593
valid 652 RMSE 1.451484 Pearson 0.720979 Spearman 0.709829 avg pairwise AUC 0.943647
test  1355 RMSE 1.554069 Pearson 0.705088 Spearman 0.716455 avg pairwise AUC 0.945603
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.677217 affinity loss 1.047308 pairwise loss 56.299086
valid 652 RMSE 1.470824 Pearson 0.712895 Spearman 0.707083 avg pairwise AUC 0.943461
test  1355 RMSE 1.554069 Pearson 0.705088 Spearman 0.716455 avg pairwise AUC 0.945603
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.150839 affinity loss 0.846142 pairwise loss 53.046974
valid 652 RMSE 1.473576 Pearson 0.701173 Spearman 0.702665 avg pairwise AUC 0.945289
test  1355 RMSE 1.554069 Pearson 0.705088 Spearman 0.716455 avg pairwise AUC 0.945603
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 5.937912 affinity loss 0.773116 pairwise loss 51.647959
train 4982 RMSE 0.786407 Pearson 0.91855 Spearman 0.915857 avg pairwise AUC 0.987758
valid 652 RMSE 1.481865 Pearson 0.701524 Spearman 0.695848 avg pairwise AUC 0.945428
test  1355 RMSE 1.554069 Pearson 0.705088 Spearman 0.716455 avg pairwise AUC 0.945603
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.819728 affinity loss 0.743841 pairwise loss 50.758865
valid 652 RMSE 1.42859 Pearson 0.716572 Spearman 0.713845 avg pairwise AUC 0.944828
test  1355 RMSE 1.504343 Pearson 0.726298 Spearman 0.732395 avg pairwise AUC 0.950116
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.703255 affinity loss 0.698034 pairwise loss 50.05221
valid 652 RMSE 1.491128 Pearson 0.6966 Spearman 0.700763 avg pairwise AUC 0.943747
test  1355 RMSE 1.504343 Pearson 0.726298 Spearman 0.732395 avg pairwise AUC 0.950116
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.599077 affinity loss 0.64278 pairwise loss 49.562976
valid 652 RMSE 1.50594 Pearson 0.696515 Spearman 0.694839 avg pairwise AUC 0.94279
test  1355 RMSE 1.504343 Pearson 0.726298 Spearman 0.732395 avg pairwise AUC 0.950116
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.532504 affinity loss 0.646408 pairwise loss 48.860955
valid 652 RMSE 1.563413 Pearson 0.69225 Spearman 0.691778 avg pairwise AUC 0.944799
test  1355 RMSE 1.504343 Pearson 0.726298 Spearman 0.732395 avg pairwise AUC 0.950116
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.462383 affinity loss 0.626515 pairwise loss 48.358679
valid 652 RMSE 1.50532 Pearson 0.686463 Spearman 0.689665 avg pairwise AUC 0.943836
test  1355 RMSE 1.504343 Pearson 0.726298 Spearman 0.732395 avg pairwise AUC 0.950116
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.344761 affinity loss 0.554376 pairwise loss 47.903852
valid 652 RMSE 1.483728 Pearson 0.707172 Spearman 0.701575 avg pairwise AUC 0.944714
test  1355 RMSE 1.504343 Pearson 0.726298 Spearman 0.732395 avg pairwise AUC 0.950116
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.301621 affinity loss 0.563664 pairwise loss 47.379579
valid 652 RMSE 1.511685 Pearson 0.69797 Spearman 0.698317 avg pairwise AUC 0.944686
test  1355 RMSE 1.504343 Pearson 0.726298 Spearman 0.732395 avg pairwise AUC 0.950116
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.217878 affinity loss 0.536777 pairwise loss 46.81101
valid 652 RMSE 1.495586 Pearson 0.699252 Spearman 0.696981 avg pairwise AUC 0.944593
test  1355 RMSE 1.504343 Pearson 0.726298 Spearman 0.732395 avg pairwise AUC 0.950116
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.134703 affinity loss 0.492161 pairwise loss 46.425418
valid 652 RMSE 1.503452 Pearson 0.697621 Spearman 0.69564 avg pairwise AUC 0.944124
test  1355 RMSE 1.504343 Pearson 0.726298 Spearman 0.732395 avg pairwise AUC 0.950116
Finished Training
------------------------------
repeat 4 fold 4 begin
train num: 5051 valid num: 625 test num: 1313
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 2927.580975 affinity loss 8.496865 pairwise loss 29190.840349
train 5051 RMSE 1.677021 Pearson 0.589196 Spearman 0.595614 avg pairwise AUC 0.848742
valid 625 RMSE 1.735 Pearson 0.511536 Spearman 0.515941 avg pairwise AUC 0.837391
test  1313 RMSE 1.76394 Pearson 0.507458 Spearman 0.506896 avg pairwise AUC 0.83028
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.420603 affinity loss 3.220286 pairwise loss 102.003163
valid 625 RMSE 1.711325 Pearson 0.539318 Spearman 0.534786 avg pairwise AUC 0.879393
test  1313 RMSE 1.744566 Pearson 0.556102 Spearman 0.561092 avg pairwise AUC 0.878856
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 11.84234 affinity loss 2.736277 pairwise loss 91.060628
valid 625 RMSE 1.685716 Pearson 0.554445 Spearman 0.561607 avg pairwise AUC 0.903142
test  1313 RMSE 1.676124 Pearson 0.570212 Spearman 0.574132 avg pairwise AUC 0.906494
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 10.988677 affinity loss 2.592939 pairwise loss 83.957378
valid 625 RMSE 1.561149 Pearson 0.595648 Spearman 0.589969 avg pairwise AUC 0.911986
test  1313 RMSE 1.601617 Pearson 0.589771 Spearman 0.598038 avg pairwise AUC 0.91816
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.252483 affinity loss 2.400152 pairwise loss 78.523313
valid 625 RMSE 1.549293 Pearson 0.614389 Spearman 0.609988 avg pairwise AUC 0.921365
test  1313 RMSE 1.577022 Pearson 0.613075 Spearman 0.616034 avg pairwise AUC 0.924277
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.74531 affinity loss 2.251426 pairwise loss 74.938843
valid 625 RMSE 1.525155 Pearson 0.630259 Spearman 0.616808 avg pairwise AUC 0.922912
test  1313 RMSE 1.578023 Pearson 0.621202 Spearman 0.629967 avg pairwise AUC 0.928312
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.290752 affinity loss 2.156919 pairwise loss 71.338333
valid 625 RMSE 1.644562 Pearson 0.629698 Spearman 0.628994 avg pairwise AUC 0.929231
test  1313 RMSE 1.578023 Pearson 0.621202 Spearman 0.629967 avg pairwise AUC 0.928312
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 8.969248 affinity loss 2.121975 pairwise loss 68.47273
valid 625 RMSE 1.484221 Pearson 0.652382 Spearman 0.652419 avg pairwise AUC 0.931244
test  1313 RMSE 1.558008 Pearson 0.635866 Spearman 0.646113 avg pairwise AUC 0.935676
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.677265 affinity loss 1.997569 pairwise loss 66.796963
valid 625 RMSE 1.530814 Pearson 0.654477 Spearman 0.642413 avg pairwise AUC 0.929895
test  1313 RMSE 1.558008 Pearson 0.635866 Spearman 0.646113 avg pairwise AUC 0.935676
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.336087 affinity loss 1.851456 pairwise loss 64.846313
valid 625 RMSE 1.465236 Pearson 0.657845 Spearman 0.65022 avg pairwise AUC 0.930327
test  1313 RMSE 1.511995 Pearson 0.649594 Spearman 0.658185 avg pairwise AUC 0.936324
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.108023 affinity loss 1.75431 pairwise loss 63.537125
train 5051 RMSE 1.228585 Pearson 0.820405 Spearman 0.822897 avg pairwise AUC 0.975151
valid 625 RMSE 1.475386 Pearson 0.671124 Spearman 0.665 avg pairwise AUC 0.933482
test  1313 RMSE 1.511995 Pearson 0.649594 Spearman 0.658185 avg pairwise AUC 0.936324
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 7.903614 affinity loss 1.650645 pairwise loss 62.52969
valid 625 RMSE 1.445235 Pearson 0.680731 Spearman 0.673112 avg pairwise AUC 0.934142
test  1313 RMSE 1.531979 Pearson 0.656255 Spearman 0.663847 avg pairwise AUC 0.938882
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.670425 affinity loss 1.533966 pairwise loss 61.364591
valid 625 RMSE 1.563577 Pearson 0.678754 Spearman 0.665196 avg pairwise AUC 0.935638
test  1313 RMSE 1.531979 Pearson 0.656255 Spearman 0.663847 avg pairwise AUC 0.938882
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.434607 affinity loss 1.379972 pairwise loss 60.546347
valid 625 RMSE 1.445178 Pearson 0.683983 Spearman 0.670759 avg pairwise AUC 0.936816
test  1313 RMSE 1.535956 Pearson 0.652457 Spearman 0.656193 avg pairwise AUC 0.939543
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.31067 affinity loss 1.364778 pairwise loss 59.458923
valid 625 RMSE 1.491598 Pearson 0.698926 Spearman 0.682671 avg pairwise AUC 0.939734
test  1313 RMSE 1.535956 Pearson 0.652457 Spearman 0.656193 avg pairwise AUC 0.939543
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.063178 affinity loss 1.267158 pairwise loss 57.9602
valid 625 RMSE 1.448319 Pearson 0.675345 Spearman 0.658379 avg pairwise AUC 0.938507
test  1313 RMSE 1.535956 Pearson 0.652457 Spearman 0.656193 avg pairwise AUC 0.939543
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 6.936873 affinity loss 1.164373 pairwise loss 57.725004
valid 625 RMSE 1.481439 Pearson 0.677595 Spearman 0.659358 avg pairwise AUC 0.939115
test  1313 RMSE 1.535956 Pearson 0.652457 Spearman 0.656193 avg pairwise AUC 0.939543
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.829123 affinity loss 1.135484 pairwise loss 56.93639
valid 625 RMSE 1.426016 Pearson 0.687705 Spearman 0.679261 avg pairwise AUC 0.940592
test  1313 RMSE 1.511152 Pearson 0.65808 Spearman 0.661328 avg pairwise AUC 0.943323
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.704305 affinity loss 1.124624 pairwise loss 55.796814
valid 625 RMSE 1.512367 Pearson 0.687336 Spearman 0.672058 avg pairwise AUC 0.939495
test  1313 RMSE 1.511152 Pearson 0.65808 Spearman 0.661328 avg pairwise AUC 0.943323
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.241972 affinity loss 0.924499 pairwise loss 53.174732
valid 625 RMSE 1.406293 Pearson 0.705966 Spearman 0.691814 avg pairwise AUC 0.941434
test  1313 RMSE 1.506281 Pearson 0.666115 Spearman 0.665251 avg pairwise AUC 0.943439
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 5.927991 affinity loss 0.781285 pairwise loss 51.467051
train 5051 RMSE 0.794809 Pearson 0.923136 Spearman 0.922427 avg pairwise AUC 0.988511
valid 625 RMSE 1.412457 Pearson 0.697961 Spearman 0.682114 avg pairwise AUC 0.942296
test  1313 RMSE 1.506281 Pearson 0.666115 Spearman 0.665251 avg pairwise AUC 0.943439
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.778937 affinity loss 0.734897 pairwise loss 50.440401
valid 625 RMSE 1.503816 Pearson 0.703341 Spearman 0.68839 avg pairwise AUC 0.941764
test  1313 RMSE 1.506281 Pearson 0.666115 Spearman 0.665251 avg pairwise AUC 0.943439
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.681429 affinity loss 0.705698 pairwise loss 49.757305
valid 625 RMSE 1.424166 Pearson 0.706177 Spearman 0.698632 avg pairwise AUC 0.942507
test  1313 RMSE 1.506281 Pearson 0.666115 Spearman 0.665251 avg pairwise AUC 0.943439
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.620689 affinity loss 0.696756 pairwise loss 49.239329
valid 625 RMSE 1.440149 Pearson 0.705725 Spearman 0.692916 avg pairwise AUC 0.941797
test  1313 RMSE 1.506281 Pearson 0.666115 Spearman 0.665251 avg pairwise AUC 0.943439
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.497712 affinity loss 0.632616 pairwise loss 48.650964
valid 625 RMSE 1.395854 Pearson 0.707509 Spearman 0.694306 avg pairwise AUC 0.942138
test  1313 RMSE 1.543219 Pearson 0.650315 Spearman 0.649379 avg pairwise AUC 0.944084
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.393528 affinity loss 0.60106 pairwise loss 47.924681
valid 625 RMSE 1.448715 Pearson 0.70209 Spearman 0.69329 avg pairwise AUC 0.94271
test  1313 RMSE 1.543219 Pearson 0.650315 Spearman 0.649379 avg pairwise AUC 0.944084
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.351404 affinity loss 0.588477 pairwise loss 47.629263
valid 625 RMSE 1.462503 Pearson 0.702399 Spearman 0.695456 avg pairwise AUC 0.943361
test  1313 RMSE 1.543219 Pearson 0.650315 Spearman 0.649379 avg pairwise AUC 0.944084
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.266989 affinity loss 0.559234 pairwise loss 47.077549
valid 625 RMSE 1.418977 Pearson 0.705024 Spearman 0.689757 avg pairwise AUC 0.943398
test  1313 RMSE 1.543219 Pearson 0.650315 Spearman 0.649379 avg pairwise AUC 0.944084
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.19903 affinity loss 0.539288 pairwise loss 46.597418
valid 625 RMSE 1.427458 Pearson 0.699611 Spearman 0.683095 avg pairwise AUC 0.942718
test  1313 RMSE 1.543219 Pearson 0.650315 Spearman 0.649379 avg pairwise AUC 0.944084
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.116866 affinity loss 0.513935 pairwise loss 46.029312
valid 625 RMSE 1.446981 Pearson 0.697318 Spearman 0.685786 avg pairwise AUC 0.942914
test  1313 RMSE 1.543219 Pearson 0.650315 Spearman 0.649379 avg pairwise AUC 0.944084
Finished Training
------------------------------
repeat 4 fold 5 begin
train num: 4624 valid num: 605 test num: 1760
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 974.886238 affinity loss 14.688042 pairwise loss 9601.982061
train 4624 RMSE 1.707992 Pearson 0.580833 Spearman 0.602025 avg pairwise AUC 0.854911
valid 605 RMSE 1.647551 Pearson 0.548873 Spearman 0.555419 avg pairwise AUC 0.842976
test  1760 RMSE 1.800739 Pearson 0.435577 Spearman 0.48286 avg pairwise AUC 0.819163
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 12.453289 affinity loss 3.218682 pairwise loss 92.346068
valid 605 RMSE 2.047069 Pearson 0.570395 Spearman 0.583829 avg pairwise AUC 0.888657
test  1760 RMSE 1.800739 Pearson 0.435577 Spearman 0.48286 avg pairwise AUC 0.819163
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 11.213246 affinity loss 2.845392 pairwise loss 83.67854
valid 605 RMSE 1.719086 Pearson 0.596254 Spearman 0.614655 avg pairwise AUC 0.907319
test  1760 RMSE 1.800739 Pearson 0.435577 Spearman 0.48286 avg pairwise AUC 0.819163
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 10.618594 affinity loss 2.714491 pairwise loss 79.041025
valid 605 RMSE 1.599472 Pearson 0.609741 Spearman 0.61269 avg pairwise AUC 0.915884
test  1760 RMSE 1.764869 Pearson 0.504652 Spearman 0.487906 avg pairwise AUC 0.895327
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 9.710758 affinity loss 2.437425 pairwise loss 72.73332
valid 605 RMSE 1.49955 Pearson 0.65 Spearman 0.653904 avg pairwise AUC 0.918972
test  1760 RMSE 1.583243 Pearson 0.561919 Spearman 0.550707 avg pairwise AUC 0.898657
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.339426 affinity loss 2.373346 pairwise loss 69.660801
valid 605 RMSE 1.555445 Pearson 0.639799 Spearman 0.651782 avg pairwise AUC 0.92491
test  1760 RMSE 1.583243 Pearson 0.561919 Spearman 0.550707 avg pairwise AUC 0.898657
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 8.847301 affinity loss 2.220729 pairwise loss 66.265711
valid 605 RMSE 1.531698 Pearson 0.660918 Spearman 0.670739 avg pairwise AUC 0.931069
test  1760 RMSE 1.583243 Pearson 0.561919 Spearman 0.550707 avg pairwise AUC 0.898657
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 8.510499 affinity loss 2.052284 pairwise loss 64.582148
valid 605 RMSE 1.52471 Pearson 0.656458 Spearman 0.663982 avg pairwise AUC 0.934415
test  1760 RMSE 1.583243 Pearson 0.561919 Spearman 0.550707 avg pairwise AUC 0.898657
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.248748 affinity loss 1.96364 pairwise loss 62.851085
valid 605 RMSE 1.488842 Pearson 0.663338 Spearman 0.674899 avg pairwise AUC 0.934465
test  1760 RMSE 1.522602 Pearson 0.582676 Spearman 0.567721 avg pairwise AUC 0.9084
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 7.922901 affinity loss 1.77779 pairwise loss 61.451113
valid 605 RMSE 1.477093 Pearson 0.678325 Spearman 0.682375 avg pairwise AUC 0.935353
test  1760 RMSE 1.497587 Pearson 0.606126 Spearman 0.598363 avg pairwise AUC 0.906719
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 7.683856 affinity loss 1.684007 pairwise loss 59.998486
train 4624 RMSE 1.237875 Pearson 0.837083 Spearman 0.836319 avg pairwise AUC 0.975848
valid 605 RMSE 1.466965 Pearson 0.686345 Spearman 0.697689 avg pairwise AUC 0.935694
test  1760 RMSE 1.480322 Pearson 0.624383 Spearman 0.616307 avg pairwise AUC 0.908617
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 7.420992 affinity loss 1.554073 pairwise loss 58.669194
valid 605 RMSE 1.42078 Pearson 0.689313 Spearman 0.699222 avg pairwise AUC 0.938285
test  1760 RMSE 1.505333 Pearson 0.604805 Spearman 0.598465 avg pairwise AUC 0.909626
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.311159 affinity loss 1.517279 pairwise loss 57.938792
valid 605 RMSE 1.453855 Pearson 0.690774 Spearman 0.696891 avg pairwise AUC 0.940498
test  1760 RMSE 1.505333 Pearson 0.604805 Spearman 0.598465 avg pairwise AUC 0.909626
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.058034 affinity loss 1.383071 pairwise loss 56.749626
valid 605 RMSE 1.449143 Pearson 0.702418 Spearman 0.707865 avg pairwise AUC 0.939602
test  1760 RMSE 1.505333 Pearson 0.604805 Spearman 0.598465 avg pairwise AUC 0.909626
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 6.944204 affinity loss 1.366082 pairwise loss 55.781221
valid 605 RMSE 1.437818 Pearson 0.694347 Spearman 0.705032 avg pairwise AUC 0.940139
test  1760 RMSE 1.505333 Pearson 0.604805 Spearman 0.598465 avg pairwise AUC 0.909626
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 6.852054 affinity loss 1.359551 pairwise loss 54.925024
valid 605 RMSE 1.419721 Pearson 0.710213 Spearman 0.712396 avg pairwise AUC 0.941888
test  1760 RMSE 1.529095 Pearson 0.617433 Spearman 0.614489 avg pairwise AUC 0.910004
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 6.579181 affinity loss 1.172834 pairwise loss 54.063467
valid 605 RMSE 1.427698 Pearson 0.720041 Spearman 0.723053 avg pairwise AUC 0.94109
test  1760 RMSE 1.529095 Pearson 0.617433 Spearman 0.614489 avg pairwise AUC 0.910004
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.43901 affinity loss 1.147825 pairwise loss 52.911852
valid 605 RMSE 1.566702 Pearson 0.69835 Spearman 0.705699 avg pairwise AUC 0.941288
test  1760 RMSE 1.529095 Pearson 0.617433 Spearman 0.614489 avg pairwise AUC 0.910004
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.373483 affinity loss 1.178413 pairwise loss 51.950696
valid 605 RMSE 1.398976 Pearson 0.70884 Spearman 0.719059 avg pairwise AUC 0.944602
test  1760 RMSE 1.484724 Pearson 0.621184 Spearman 0.617482 avg pairwise AUC 0.911183
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 5.831282 affinity loss 0.896428 pairwise loss 49.348536
valid 605 RMSE 1.396707 Pearson 0.720083 Spearman 0.720901 avg pairwise AUC 0.943968
test  1760 RMSE 1.580883 Pearson 0.600737 Spearman 0.588509 avg pairwise AUC 0.910959
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 5.589381 affinity loss 0.783069 pairwise loss 48.063112
train 4624 RMSE 0.834264 Pearson 0.92126 Spearman 0.915565 avg pairwise AUC 0.989446
valid 605 RMSE 1.397957 Pearson 0.726133 Spearman 0.727127 avg pairwise AUC 0.943957
test  1760 RMSE 1.580883 Pearson 0.600737 Spearman 0.588509 avg pairwise AUC 0.910959
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.465531 affinity loss 0.746417 pairwise loss 47.191142
valid 605 RMSE 1.446294 Pearson 0.703457 Spearman 0.706618 avg pairwise AUC 0.944357
test  1760 RMSE 1.580883 Pearson 0.600737 Spearman 0.588509 avg pairwise AUC 0.910959
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.412484 affinity loss 0.744915 pairwise loss 46.675684
valid 605 RMSE 1.575749 Pearson 0.704527 Spearman 0.725633 avg pairwise AUC 0.943392
test  1760 RMSE 1.580883 Pearson 0.600737 Spearman 0.588509 avg pairwise AUC 0.910959
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.310942 affinity loss 0.723927 pairwise loss 45.870147
valid 605 RMSE 1.391451 Pearson 0.716789 Spearman 0.719944 avg pairwise AUC 0.94298
test  1760 RMSE 1.511355 Pearson 0.613283 Spearman 0.604461 avg pairwise AUC 0.908347
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.195108 affinity loss 0.640289 pairwise loss 45.548186
valid 605 RMSE 1.429487 Pearson 0.708872 Spearman 0.706636 avg pairwise AUC 0.94364
test  1760 RMSE 1.511355 Pearson 0.613283 Spearman 0.604461 avg pairwise AUC 0.908347
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.116401 affinity loss 0.617289 pairwise loss 44.991113
valid 605 RMSE 1.398608 Pearson 0.709562 Spearman 0.714859 avg pairwise AUC 0.943916
test  1760 RMSE 1.511355 Pearson 0.613283 Spearman 0.604461 avg pairwise AUC 0.908347
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.018934 affinity loss 0.585187 pairwise loss 44.337467
valid 605 RMSE 1.445104 Pearson 0.713605 Spearman 0.716967 avg pairwise AUC 0.94286
test  1760 RMSE 1.511355 Pearson 0.613283 Spearman 0.604461 avg pairwise AUC 0.908347
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 4.944136 affinity loss 0.569363 pairwise loss 43.74773
valid 605 RMSE 1.398972 Pearson 0.717458 Spearman 0.722548 avg pairwise AUC 0.943417
test  1760 RMSE 1.511355 Pearson 0.613283 Spearman 0.604461 avg pairwise AUC 0.908347
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 4.861146 affinity loss 0.528903 pairwise loss 43.322434
valid 605 RMSE 1.397575 Pearson 0.715132 Spearman 0.712842 avg pairwise AUC 0.943128
test  1760 RMSE 1.511355 Pearson 0.613283 Spearman 0.604461 avg pairwise AUC 0.908347
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 4.842723 affinity loss 0.551717 pairwise loss 42.910067
valid 605 RMSE 1.413158 Pearson 0.716729 Spearman 0.715519 avg pairwise AUC 0.943469
test  1760 RMSE 1.511355 Pearson 0.613283 Spearman 0.604461 avg pairwise AUC 0.908347
Finished Training
------------------------------
fold avg performance [1.48830787 0.68451766 0.68752653 0.93587   ]
/home/junseok/workspace/monn/src/pdbbind_utils.py:198: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  data_pack = [np.array(data) for data in data_pack]
setting: new_compound
fold 0 train  4998 test  1372 valid  619
fold 1 train  5040 test  1282 valid  667
fold 2 train  4937 test  1422 valid  630
fold 3 train  4698 test  1663 valid  628
fold 4 train  5052 test  1250 valid  687
repeat 5 fold 1 begin
train num: 4998 valid num: 619 test num: 1372
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 1236.264224 affinity loss 25.861652 pairwise loss 12104.025026
train 4998 RMSE 1.704843 Pearson 0.584053 Spearman 0.590136 avg pairwise AUC 0.853476
valid 619 RMSE 1.648696 Pearson 0.560888 Spearman 0.556594 avg pairwise AUC 0.833999
test  1372 RMSE 1.732594 Pearson 0.522753 Spearman 0.528744 avg pairwise AUC 0.841911
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.079348 affinity loss 3.195863 pairwise loss 98.834852
valid 619 RMSE 1.559304 Pearson 0.60279 Spearman 0.598629 avg pairwise AUC 0.880197
test  1372 RMSE 1.655174 Pearson 0.549031 Spearman 0.561028 avg pairwise AUC 0.884986
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 11.914254 affinity loss 2.882976 pairwise loss 90.312777
valid 619 RMSE 1.572805 Pearson 0.614066 Spearman 0.611538 avg pairwise AUC 0.902584
test  1372 RMSE 1.655174 Pearson 0.549031 Spearman 0.561028 avg pairwise AUC 0.884986
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 11.284969 affinity loss 2.873604 pairwise loss 84.11365
valid 619 RMSE 2.129642 Pearson 0.646986 Spearman 0.649618 avg pairwise AUC 0.914019
test  1372 RMSE 1.655174 Pearson 0.549031 Spearman 0.561028 avg pairwise AUC 0.884986
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.419281 affinity loss 2.516809 pairwise loss 79.024718
valid 619 RMSE 1.518692 Pearson 0.647146 Spearman 0.658542 avg pairwise AUC 0.919628
test  1372 RMSE 1.592424 Pearson 0.610535 Spearman 0.623684 avg pairwise AUC 0.917841
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.985644 affinity loss 2.442369 pairwise loss 75.432746
valid 619 RMSE 1.475596 Pearson 0.662283 Spearman 0.669799 avg pairwise AUC 0.925801
test  1372 RMSE 1.575342 Pearson 0.614894 Spearman 0.627521 avg pairwise AUC 0.923966
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.37443 affinity loss 2.239495 pairwise loss 71.349352
valid 619 RMSE 1.570618 Pearson 0.648784 Spearman 0.66607 avg pairwise AUC 0.929002
test  1372 RMSE 1.575342 Pearson 0.614894 Spearman 0.627521 avg pairwise AUC 0.923966
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.001877 affinity loss 2.077579 pairwise loss 69.24298
valid 619 RMSE 1.507932 Pearson 0.677511 Spearman 0.685864 avg pairwise AUC 0.930832
test  1372 RMSE 1.575342 Pearson 0.614894 Spearman 0.627521 avg pairwise AUC 0.923966
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.680051 affinity loss 1.961104 pairwise loss 67.189473
valid 619 RMSE 1.44716 Pearson 0.685412 Spearman 0.690258 avg pairwise AUC 0.934561
test  1372 RMSE 1.504856 Pearson 0.656691 Spearman 0.664192 avg pairwise AUC 0.930027
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.337032 affinity loss 1.858626 pairwise loss 64.784061
valid 619 RMSE 1.422034 Pearson 0.69016 Spearman 0.691457 avg pairwise AUC 0.937042
test  1372 RMSE 1.508194 Pearson 0.651448 Spearman 0.663458 avg pairwise AUC 0.933113
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.135372 affinity loss 1.772898 pairwise loss 63.624745
train 4998 RMSE 1.436902 Pearson 0.823999 Spearman 0.82551 avg pairwise AUC 0.972386
valid 619 RMSE 1.611154 Pearson 0.70344 Spearman 0.706292 avg pairwise AUC 0.935258
test  1372 RMSE 1.508194 Pearson 0.651448 Spearman 0.663458 avg pairwise AUC 0.933113
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 7.906773 affinity loss 1.6648 pairwise loss 62.419735
valid 619 RMSE 1.461697 Pearson 0.691582 Spearman 0.694059 avg pairwise AUC 0.938763
test  1372 RMSE 1.508194 Pearson 0.651448 Spearman 0.663458 avg pairwise AUC 0.933113
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.633476 affinity loss 1.559625 pairwise loss 60.738515
valid 619 RMSE 1.427965 Pearson 0.689655 Spearman 0.686251 avg pairwise AUC 0.936245
test  1372 RMSE 1.508194 Pearson 0.651448 Spearman 0.663458 avg pairwise AUC 0.933113
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.448075 affinity loss 1.455634 pairwise loss 59.924404
valid 619 RMSE 1.551625 Pearson 0.70734 Spearman 0.708056 avg pairwise AUC 0.938716
test  1372 RMSE 1.508194 Pearson 0.651448 Spearman 0.663458 avg pairwise AUC 0.933113
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.287337 affinity loss 1.407699 pairwise loss 58.796374
valid 619 RMSE 1.470661 Pearson 0.675563 Spearman 0.6856 avg pairwise AUC 0.939736
test  1372 RMSE 1.508194 Pearson 0.651448 Spearman 0.663458 avg pairwise AUC 0.933113
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.188519 affinity loss 1.404631 pairwise loss 57.83888
valid 619 RMSE 1.44792 Pearson 0.702424 Spearman 0.701006 avg pairwise AUC 0.937515
test  1372 RMSE 1.508194 Pearson 0.651448 Spearman 0.663458 avg pairwise AUC 0.933113
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 7.030419 affinity loss 1.31268 pairwise loss 57.177394
valid 619 RMSE 1.463718 Pearson 0.679952 Spearman 0.678646 avg pairwise AUC 0.940217
test  1372 RMSE 1.508194 Pearson 0.651448 Spearman 0.663458 avg pairwise AUC 0.933113
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.825542 affinity loss 1.160671 pairwise loss 56.648713
valid 619 RMSE 1.459902 Pearson 0.678723 Spearman 0.683345 avg pairwise AUC 0.941469
test  1372 RMSE 1.508194 Pearson 0.651448 Spearman 0.663458 avg pairwise AUC 0.933113
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.696316 affinity loss 1.132219 pairwise loss 55.640974
valid 619 RMSE 1.442715 Pearson 0.68667 Spearman 0.681553 avg pairwise AUC 0.941661
test  1372 RMSE 1.508194 Pearson 0.651448 Spearman 0.663458 avg pairwise AUC 0.933113
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.09924 affinity loss 0.882279 pairwise loss 52.169608
valid 619 RMSE 1.515523 Pearson 0.682431 Spearman 0.680945 avg pairwise AUC 0.942999
test  1372 RMSE 1.508194 Pearson 0.651448 Spearman 0.663458 avg pairwise AUC 0.933113
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 5.864926 affinity loss 0.794647 pairwise loss 50.702789
train 4998 RMSE 0.818086 Pearson 0.91788 Spearman 0.91767 avg pairwise AUC 0.986925
valid 619 RMSE 1.431927 Pearson 0.704053 Spearman 0.698483 avg pairwise AUC 0.943227
test  1372 RMSE 1.508194 Pearson 0.651448 Spearman 0.663458 avg pairwise AUC 0.933113
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.76041 affinity loss 0.756182 pairwise loss 50.042282
valid 619 RMSE 1.479481 Pearson 0.688702 Spearman 0.682842 avg pairwise AUC 0.94278
test  1372 RMSE 1.508194 Pearson 0.651448 Spearman 0.663458 avg pairwise AUC 0.933113
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.672836 affinity loss 0.764742 pairwise loss 49.080942
valid 619 RMSE 1.488896 Pearson 0.690236 Spearman 0.686976 avg pairwise AUC 0.942725
test  1372 RMSE 1.508194 Pearson 0.651448 Spearman 0.663458 avg pairwise AUC 0.933113
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.562947 affinity loss 0.698705 pairwise loss 48.642413
valid 619 RMSE 1.484082 Pearson 0.68853 Spearman 0.682451 avg pairwise AUC 0.943704
test  1372 RMSE 1.508194 Pearson 0.651448 Spearman 0.663458 avg pairwise AUC 0.933113
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.503572 affinity loss 0.698391 pairwise loss 48.051801
valid 619 RMSE 1.496446 Pearson 0.686446 Spearman 0.681874 avg pairwise AUC 0.942899
test  1372 RMSE 1.508194 Pearson 0.651448 Spearman 0.663458 avg pairwise AUC 0.933113
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.349162 affinity loss 0.628563 pairwise loss 47.205996
valid 619 RMSE 1.635076 Pearson 0.685825 Spearman 0.681096 avg pairwise AUC 0.941888
test  1372 RMSE 1.508194 Pearson 0.651448 Spearman 0.663458 avg pairwise AUC 0.933113
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.275101 affinity loss 0.608432 pairwise loss 46.666695
valid 619 RMSE 1.677974 Pearson 0.675381 Spearman 0.663701 avg pairwise AUC 0.943319
test  1372 RMSE 1.508194 Pearson 0.651448 Spearman 0.663458 avg pairwise AUC 0.933113
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.201599 affinity loss 0.594121 pairwise loss 46.074782
valid 619 RMSE 1.501377 Pearson 0.68197 Spearman 0.672401 avg pairwise AUC 0.942688
test  1372 RMSE 1.508194 Pearson 0.651448 Spearman 0.663458 avg pairwise AUC 0.933113
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.13443 affinity loss 0.547935 pairwise loss 45.864949
valid 619 RMSE 1.492736 Pearson 0.68584 Spearman 0.678967 avg pairwise AUC 0.942226
test  1372 RMSE 1.508194 Pearson 0.651448 Spearman 0.663458 avg pairwise AUC 0.933113
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.062365 affinity loss 0.513661 pairwise loss 45.487044
valid 619 RMSE 1.51744 Pearson 0.678122 Spearman 0.671219 avg pairwise AUC 0.944036
test  1372 RMSE 1.508194 Pearson 0.651448 Spearman 0.663458 avg pairwise AUC 0.933113
Finished Training
------------------------------
repeat 5 fold 2 begin
train num: 5040 valid num: 667 test num: 1282
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 2314.43847 affinity loss 16.695836 pairwise loss 22977.425202
train 5040 RMSE 1.66418 Pearson 0.581311 Spearman 0.586811 avg pairwise AUC 0.858409
valid 667 RMSE 1.662925 Pearson 0.583749 Spearman 0.588611 avg pairwise AUC 0.85461
test  1282 RMSE 1.792244 Pearson 0.501786 Spearman 0.529436 avg pairwise AUC 0.844056
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.227063 affinity loss 3.005542 pairwise loss 102.215207
valid 667 RMSE 1.6447 Pearson 0.597635 Spearman 0.602406 avg pairwise AUC 0.887873
test  1282 RMSE 1.764274 Pearson 0.534494 Spearman 0.571206 avg pairwise AUC 0.878543
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 11.795711 affinity loss 2.637237 pairwise loss 91.584738
valid 667 RMSE 1.724428 Pearson 0.597755 Spearman 0.602206 avg pairwise AUC 0.908545
test  1282 RMSE 1.764274 Pearson 0.534494 Spearman 0.571206 avg pairwise AUC 0.878543
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 10.939612 affinity loss 2.443594 pairwise loss 84.960184
valid 667 RMSE 1.622026 Pearson 0.612592 Spearman 0.618878 avg pairwise AUC 0.921326
test  1282 RMSE 1.695277 Pearson 0.560651 Spearman 0.597536 avg pairwise AUC 0.91597
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.223366 affinity loss 2.328834 pairwise loss 78.945321
valid 667 RMSE 1.619788 Pearson 0.625391 Spearman 0.630549 avg pairwise AUC 0.924774
test  1282 RMSE 1.74434 Pearson 0.552681 Spearman 0.614672 avg pairwise AUC 0.91899
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.811582 affinity loss 2.222097 pairwise loss 75.894844
valid 667 RMSE 1.773964 Pearson 0.646843 Spearman 0.653949 avg pairwise AUC 0.927656
test  1282 RMSE 1.74434 Pearson 0.552681 Spearman 0.614672 avg pairwise AUC 0.91899
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.238032 affinity loss 1.961928 pairwise loss 72.761044
valid 667 RMSE 1.676931 Pearson 0.628696 Spearman 0.640598 avg pairwise AUC 0.933866
test  1282 RMSE 1.74434 Pearson 0.552681 Spearman 0.614672 avg pairwise AUC 0.91899
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.077445 affinity loss 2.065558 pairwise loss 70.118873
valid 667 RMSE 1.82488 Pearson 0.670755 Spearman 0.679665 avg pairwise AUC 0.933087
test  1282 RMSE 1.74434 Pearson 0.552681 Spearman 0.614672 avg pairwise AUC 0.91899
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.602265 affinity loss 1.756545 pairwise loss 68.457199
valid 667 RMSE 1.511531 Pearson 0.683562 Spearman 0.691825 avg pairwise AUC 0.936734
test  1282 RMSE 1.614314 Pearson 0.634469 Spearman 0.662575 avg pairwise AUC 0.929633
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.316668 affinity loss 1.556605 pairwise loss 67.600633
valid 667 RMSE 1.549644 Pearson 0.655939 Spearman 0.664297 avg pairwise AUC 0.93638
test  1282 RMSE 1.614314 Pearson 0.634469 Spearman 0.662575 avg pairwise AUC 0.929633
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.03781 affinity loss 1.47192 pairwise loss 65.658898
train 5040 RMSE 1.082142 Pearson 0.845742 Spearman 0.844577 avg pairwise AUC 0.973639
valid 667 RMSE 1.516023 Pearson 0.680015 Spearman 0.691695 avg pairwise AUC 0.938983
test  1282 RMSE 1.614314 Pearson 0.634469 Spearman 0.662575 avg pairwise AUC 0.929633
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 7.816952 affinity loss 1.41062 pairwise loss 64.063314
valid 667 RMSE 1.628181 Pearson 0.646547 Spearman 0.652589 avg pairwise AUC 0.94043
test  1282 RMSE 1.614314 Pearson 0.634469 Spearman 0.662575 avg pairwise AUC 0.929633
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.667858 affinity loss 1.392656 pairwise loss 62.75202
valid 667 RMSE 1.662047 Pearson 0.669759 Spearman 0.688002 avg pairwise AUC 0.941832
test  1282 RMSE 1.614314 Pearson 0.634469 Spearman 0.662575 avg pairwise AUC 0.929633
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.375828 affinity loss 1.25136 pairwise loss 61.244683
valid 667 RMSE 1.498048 Pearson 0.688253 Spearman 0.69674 avg pairwise AUC 0.940617
test  1282 RMSE 1.685085 Pearson 0.602586 Spearman 0.650463 avg pairwise AUC 0.934189
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.308705 affinity loss 1.264795 pairwise loss 60.439101
valid 667 RMSE 1.524815 Pearson 0.67761 Spearman 0.692087 avg pairwise AUC 0.943284
test  1282 RMSE 1.685085 Pearson 0.602586 Spearman 0.650463 avg pairwise AUC 0.934189
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.113266 affinity loss 1.179551 pairwise loss 59.33715
valid 667 RMSE 1.574291 Pearson 0.687097 Spearman 0.698076 avg pairwise AUC 0.942891
test  1282 RMSE 1.685085 Pearson 0.602586 Spearman 0.650463 avg pairwise AUC 0.934189
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 6.958513 affinity loss 1.117446 pairwise loss 58.41066
valid 667 RMSE 1.550116 Pearson 0.675557 Spearman 0.693401 avg pairwise AUC 0.945166
test  1282 RMSE 1.685085 Pearson 0.602586 Spearman 0.650463 avg pairwise AUC 0.934189
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.817265 affinity loss 1.045989 pairwise loss 57.712757
valid 667 RMSE 1.547818 Pearson 0.700155 Spearman 0.707521 avg pairwise AUC 0.94389
test  1282 RMSE 1.685085 Pearson 0.602586 Spearman 0.650463 avg pairwise AUC 0.934189
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.701813 affinity loss 1.022022 pairwise loss 56.797903
valid 667 RMSE 1.498282 Pearson 0.689492 Spearman 0.699028 avg pairwise AUC 0.944515
test  1282 RMSE 1.685085 Pearson 0.602586 Spearman 0.650463 avg pairwise AUC 0.934189
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.156333 affinity loss 0.806696 pairwise loss 53.496364
valid 667 RMSE 1.563704 Pearson 0.676198 Spearman 0.690719 avg pairwise AUC 0.946409
test  1282 RMSE 1.685085 Pearson 0.602586 Spearman 0.650463 avg pairwise AUC 0.934189
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 5.938579 affinity loss 0.738416 pairwise loss 52.001632
train 5040 RMSE 0.781519 Pearson 0.925839 Spearman 0.923564 avg pairwise AUC 0.988063
valid 667 RMSE 1.526701 Pearson 0.694412 Spearman 0.707075 avg pairwise AUC 0.947188
test  1282 RMSE 1.685085 Pearson 0.602586 Spearman 0.650463 avg pairwise AUC 0.934189
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.792196 affinity loss 0.683241 pairwise loss 51.089549
valid 667 RMSE 1.544286 Pearson 0.67872 Spearman 0.695956 avg pairwise AUC 0.947035
test  1282 RMSE 1.685085 Pearson 0.602586 Spearman 0.650463 avg pairwise AUC 0.934189
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.724085 affinity loss 0.681794 pairwise loss 50.422913
valid 667 RMSE 1.490663 Pearson 0.696287 Spearman 0.709034 avg pairwise AUC 0.946548
test  1282 RMSE 1.633014 Pearson 0.629718 Spearman 0.659119 avg pairwise AUC 0.93901
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.578207 affinity loss 0.6077 pairwise loss 49.705072
valid 667 RMSE 1.557772 Pearson 0.69215 Spearman 0.703778 avg pairwise AUC 0.946464
test  1282 RMSE 1.633014 Pearson 0.629718 Spearman 0.659119 avg pairwise AUC 0.93901
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.503853 affinity loss 0.590054 pairwise loss 49.137987
valid 667 RMSE 1.58227 Pearson 0.676767 Spearman 0.689672 avg pairwise AUC 0.948566
test  1282 RMSE 1.633014 Pearson 0.629718 Spearman 0.659119 avg pairwise AUC 0.93901
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.415856 affinity loss 0.572399 pairwise loss 48.434566
valid 667 RMSE 1.504217 Pearson 0.696805 Spearman 0.71089 avg pairwise AUC 0.948314
test  1282 RMSE 1.633014 Pearson 0.629718 Spearman 0.659119 avg pairwise AUC 0.93901
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.34518 affinity loss 0.532384 pairwise loss 48.127963
valid 667 RMSE 1.585564 Pearson 0.679353 Spearman 0.690183 avg pairwise AUC 0.947585
test  1282 RMSE 1.633014 Pearson 0.629718 Spearman 0.659119 avg pairwise AUC 0.93901
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.274662 affinity loss 0.511245 pairwise loss 47.63417
valid 667 RMSE 1.531704 Pearson 0.692999 Spearman 0.700436 avg pairwise AUC 0.946906
test  1282 RMSE 1.633014 Pearson 0.629718 Spearman 0.659119 avg pairwise AUC 0.93901
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.20635 affinity loss 0.506982 pairwise loss 46.993677
valid 667 RMSE 1.556869 Pearson 0.688787 Spearman 0.703844 avg pairwise AUC 0.948583
test  1282 RMSE 1.633014 Pearson 0.629718 Spearman 0.659119 avg pairwise AUC 0.93901
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.127113 affinity loss 0.461747 pairwise loss 46.65366
valid 667 RMSE 1.559971 Pearson 0.681071 Spearman 0.685352 avg pairwise AUC 0.947874
test  1282 RMSE 1.633014 Pearson 0.629718 Spearman 0.659119 avg pairwise AUC 0.93901
Finished Training
------------------------------
repeat 5 fold 3 begin
train num: 4937 valid num: 630 test num: 1422
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 1410.134967 affinity loss 12.323848 pairwise loss 13978.110684
train 4937 RMSE 1.89835 Pearson 0.570773 Spearman 0.581142 avg pairwise AUC 0.855796
valid 630 RMSE 1.918548 Pearson 0.527004 Spearman 0.523493 avg pairwise AUC 0.855851
test  1422 RMSE 1.836709 Pearson 0.549776 Spearman 0.555157 avg pairwise AUC 0.842432
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.386909 affinity loss 3.274499 pairwise loss 101.124095
valid 630 RMSE 1.974479 Pearson 0.549881 Spearman 0.560477 avg pairwise AUC 0.891687
test  1422 RMSE 1.836709 Pearson 0.549776 Spearman 0.555157 avg pairwise AUC 0.842432
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 12.026316 affinity loss 2.795621 pairwise loss 92.306944
valid 630 RMSE 1.587273 Pearson 0.591492 Spearman 0.599734 avg pairwise AUC 0.913274
test  1422 RMSE 1.60421 Pearson 0.590225 Spearman 0.594676 avg pairwise AUC 0.902915
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 11.369989 affinity loss 2.745811 pairwise loss 86.241783
valid 630 RMSE 1.608855 Pearson 0.616548 Spearman 0.626716 avg pairwise AUC 0.922743
test  1422 RMSE 1.60421 Pearson 0.590225 Spearman 0.594676 avg pairwise AUC 0.902915
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.757238 affinity loss 2.650541 pairwise loss 81.06697
valid 630 RMSE 1.543957 Pearson 0.622831 Spearman 0.631819 avg pairwise AUC 0.92901
test  1422 RMSE 1.533961 Pearson 0.634845 Spearman 0.640512 avg pairwise AUC 0.919573
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 10.113256 affinity loss 2.391398 pairwise loss 77.218577
valid 630 RMSE 1.572706 Pearson 0.633609 Spearman 0.661765 avg pairwise AUC 0.932365
test  1422 RMSE 1.533961 Pearson 0.634845 Spearman 0.640512 avg pairwise AUC 0.919573
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.747038 affinity loss 2.300327 pairwise loss 74.467112
valid 630 RMSE 1.5761 Pearson 0.6369 Spearman 0.649559 avg pairwise AUC 0.934066
test  1422 RMSE 1.533961 Pearson 0.634845 Spearman 0.640512 avg pairwise AUC 0.919573
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.309739 affinity loss 2.068107 pairwise loss 72.416317
valid 630 RMSE 1.534412 Pearson 0.681206 Spearman 0.68864 avg pairwise AUC 0.937618
test  1422 RMSE 1.583931 Pearson 0.668318 Spearman 0.67602 avg pairwise AUC 0.926018
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.918651 affinity loss 1.965916 pairwise loss 69.527359
valid 630 RMSE 1.498628 Pearson 0.6505 Spearman 0.666029 avg pairwise AUC 0.937141
test  1422 RMSE 1.47815 Pearson 0.667515 Spearman 0.6764 avg pairwise AUC 0.927262
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.597187 affinity loss 1.872638 pairwise loss 67.245488
valid 630 RMSE 1.435241 Pearson 0.687936 Spearman 0.699645 avg pairwise AUC 0.939821
test  1422 RMSE 1.479955 Pearson 0.671591 Spearman 0.679893 avg pairwise AUC 0.929906
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.28362 affinity loss 1.667901 pairwise loss 66.157189
train 4937 RMSE 1.213798 Pearson 0.815516 Spearman 0.818989 avg pairwise AUC 0.970873
valid 630 RMSE 1.45302 Pearson 0.679301 Spearman 0.680963 avg pairwise AUC 0.939559
test  1422 RMSE 1.479955 Pearson 0.671591 Spearman 0.679893 avg pairwise AUC 0.929906
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 8.013079 affinity loss 1.545978 pairwise loss 64.671005
valid 630 RMSE 1.585205 Pearson 0.679948 Spearman 0.687221 avg pairwise AUC 0.940347
test  1422 RMSE 1.479955 Pearson 0.671591 Spearman 0.679893 avg pairwise AUC 0.929906
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.874522 affinity loss 1.464744 pairwise loss 64.097784
valid 630 RMSE 1.441973 Pearson 0.687839 Spearman 0.693759 avg pairwise AUC 0.939155
test  1422 RMSE 1.479955 Pearson 0.671591 Spearman 0.679893 avg pairwise AUC 0.929906
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.737064 affinity loss 1.532808 pairwise loss 62.042556
valid 630 RMSE 1.445897 Pearson 0.699115 Spearman 0.700403 avg pairwise AUC 0.942339
test  1422 RMSE 1.479955 Pearson 0.671591 Spearman 0.679893 avg pairwise AUC 0.929906
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.541598 affinity loss 1.418332 pairwise loss 61.232665
valid 630 RMSE 1.475395 Pearson 0.696806 Spearman 0.697473 avg pairwise AUC 0.944346
test  1422 RMSE 1.479955 Pearson 0.671591 Spearman 0.679893 avg pairwise AUC 0.929906
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.371529 affinity loss 1.322238 pairwise loss 60.492908
valid 630 RMSE 1.473384 Pearson 0.70309 Spearman 0.702615 avg pairwise AUC 0.942368
test  1422 RMSE 1.479955 Pearson 0.671591 Spearman 0.679893 avg pairwise AUC 0.929906
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 7.16711 affinity loss 1.226833 pairwise loss 59.402775
valid 630 RMSE 1.460325 Pearson 0.697267 Spearman 0.696223 avg pairwise AUC 0.944926
test  1422 RMSE 1.479955 Pearson 0.671591 Spearman 0.679893 avg pairwise AUC 0.929906
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 7.128266 affinity loss 1.243138 pairwise loss 58.85128
valid 630 RMSE 1.433313 Pearson 0.699517 Spearman 0.701137 avg pairwise AUC 0.944561
test  1422 RMSE 1.447998 Pearson 0.694168 Spearman 0.702092 avg pairwise AUC 0.935235
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.936927 affinity loss 1.139002 pairwise loss 57.979251
valid 630 RMSE 1.45895 Pearson 0.708827 Spearman 0.704307 avg pairwise AUC 0.94479
test  1422 RMSE 1.447998 Pearson 0.694168 Spearman 0.702092 avg pairwise AUC 0.935235
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.36751 affinity loss 0.901551 pairwise loss 54.659594
valid 630 RMSE 1.446967 Pearson 0.707108 Spearman 0.707931 avg pairwise AUC 0.947285
test  1422 RMSE 1.447998 Pearson 0.694168 Spearman 0.702092 avg pairwise AUC 0.935235
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 6.127035 affinity loss 0.813306 pairwise loss 53.13729
train 4937 RMSE 0.849256 Pearson 0.917907 Spearman 0.915164 avg pairwise AUC 0.985869
valid 630 RMSE 1.464738 Pearson 0.702548 Spearman 0.699854 avg pairwise AUC 0.946807
test  1422 RMSE 1.447998 Pearson 0.694168 Spearman 0.702092 avg pairwise AUC 0.935235
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 6.023156 affinity loss 0.796434 pairwise loss 52.267227
valid 630 RMSE 1.486542 Pearson 0.707784 Spearman 0.69894 avg pairwise AUC 0.947036
test  1422 RMSE 1.447998 Pearson 0.694168 Spearman 0.702092 avg pairwise AUC 0.935235
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.901908 affinity loss 0.760147 pairwise loss 51.417616
valid 630 RMSE 1.450278 Pearson 0.705023 Spearman 0.702986 avg pairwise AUC 0.947003
test  1422 RMSE 1.447998 Pearson 0.694168 Spearman 0.702092 avg pairwise AUC 0.935235
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.807352 affinity loss 0.703862 pairwise loss 51.034897
valid 630 RMSE 1.440264 Pearson 0.707066 Spearman 0.707131 avg pairwise AUC 0.947505
test  1422 RMSE 1.447998 Pearson 0.694168 Spearman 0.702092 avg pairwise AUC 0.935235
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.712827 affinity loss 0.698865 pairwise loss 50.139624
valid 630 RMSE 1.448352 Pearson 0.699991 Spearman 0.6953 avg pairwise AUC 0.947835
test  1422 RMSE 1.447998 Pearson 0.694168 Spearman 0.702092 avg pairwise AUC 0.935235
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.61017 affinity loss 0.648192 pairwise loss 49.619788
valid 630 RMSE 1.39156 Pearson 0.72122 Spearman 0.721276 avg pairwise AUC 0.946534
test  1422 RMSE 1.473649 Pearson 0.685665 Spearman 0.693232 avg pairwise AUC 0.936815
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.560857 affinity loss 0.643754 pairwise loss 49.171025
valid 630 RMSE 1.467166 Pearson 0.715099 Spearman 0.711139 avg pairwise AUC 0.947676
test  1422 RMSE 1.473649 Pearson 0.685665 Spearman 0.693232 avg pairwise AUC 0.936815
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.46438 affinity loss 0.615164 pairwise loss 48.492161
valid 630 RMSE 1.43739 Pearson 0.716349 Spearman 0.715392 avg pairwise AUC 0.948153
test  1422 RMSE 1.473649 Pearson 0.685665 Spearman 0.693232 avg pairwise AUC 0.936815
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.403763 affinity loss 0.578913 pairwise loss 48.2485
valid 630 RMSE 1.427255 Pearson 0.703094 Spearman 0.696326 avg pairwise AUC 0.947816
test  1422 RMSE 1.473649 Pearson 0.685665 Spearman 0.693232 avg pairwise AUC 0.936815
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.310591 affinity loss 0.552313 pairwise loss 47.582786
valid 630 RMSE 1.456737 Pearson 0.696793 Spearman 0.681439 avg pairwise AUC 0.947658
test  1422 RMSE 1.473649 Pearson 0.685665 Spearman 0.693232 avg pairwise AUC 0.936815
Finished Training
------------------------------
repeat 5 fold 4 begin
train num: 4698 valid num: 628 test num: 1663
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 951.062391 affinity loss 11.222986 pairwise loss 9398.394182
train 4698 RMSE 1.879195 Pearson 0.587874 Spearman 0.601542 avg pairwise AUC 0.856659
valid 628 RMSE 1.961953 Pearson 0.557912 Spearman 0.582327 avg pairwise AUC 0.851102
test  1663 RMSE 1.991853 Pearson 0.60202 Spearman 0.609081 avg pairwise AUC 0.84125
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 12.671072 affinity loss 3.013206 pairwise loss 96.578659
valid 628 RMSE 1.666249 Pearson 0.575592 Spearman 0.603874 avg pairwise AUC 0.893503
test  1663 RMSE 1.709996 Pearson 0.616832 Spearman 0.625187 avg pairwise AUC 0.883108
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 11.333857 affinity loss 2.630304 pairwise loss 87.035526
valid 628 RMSE 1.718607 Pearson 0.576342 Spearman 0.599502 avg pairwise AUC 0.914959
test  1663 RMSE 1.709996 Pearson 0.616832 Spearman 0.625187 avg pairwise AUC 0.883108
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 10.650181 affinity loss 2.572232 pairwise loss 80.779486
valid 628 RMSE 2.001997 Pearson 0.638139 Spearman 0.664367 avg pairwise AUC 0.923242
test  1663 RMSE 1.709996 Pearson 0.616832 Spearman 0.625187 avg pairwise AUC 0.883108
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.118068 affinity loss 2.558785 pairwise loss 75.592833
valid 628 RMSE 1.950401 Pearson 0.634139 Spearman 0.654288 avg pairwise AUC 0.929406
test  1663 RMSE 1.709996 Pearson 0.616832 Spearman 0.625187 avg pairwise AUC 0.883108
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.464743 affinity loss 2.227087 pairwise loss 72.376556
valid 628 RMSE 1.571019 Pearson 0.65062 Spearman 0.673053 avg pairwise AUC 0.930853
test  1663 RMSE 1.629106 Pearson 0.668731 Spearman 0.659678 avg pairwise AUC 0.91407
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.083114 affinity loss 2.116094 pairwise loss 69.670202
valid 628 RMSE 1.823859 Pearson 0.671598 Spearman 0.697054 avg pairwise AUC 0.936709
test  1663 RMSE 1.629106 Pearson 0.668731 Spearman 0.659678 avg pairwise AUC 0.91407
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 8.725893 affinity loss 2.029093 pairwise loss 66.967999
valid 628 RMSE 1.528107 Pearson 0.664021 Spearman 0.686671 avg pairwise AUC 0.936267
test  1663 RMSE 1.658877 Pearson 0.632567 Spearman 0.63185 avg pairwise AUC 0.914157
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.459743 affinity loss 1.827987 pairwise loss 66.317563
valid 628 RMSE 1.55416 Pearson 0.678376 Spearman 0.703948 avg pairwise AUC 0.937658
test  1663 RMSE 1.658877 Pearson 0.632567 Spearman 0.63185 avg pairwise AUC 0.914157
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.278428 affinity loss 1.909366 pairwise loss 63.690618
valid 628 RMSE 1.570931 Pearson 0.684976 Spearman 0.708311 avg pairwise AUC 0.940234
test  1663 RMSE 1.658877 Pearson 0.632567 Spearman 0.63185 avg pairwise AUC 0.914157
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 7.900384 affinity loss 1.666235 pairwise loss 62.341495
train 4698 RMSE 1.188755 Pearson 0.822753 Spearman 0.827388 avg pairwise AUC 0.974415
valid 628 RMSE 1.49363 Pearson 0.685903 Spearman 0.702232 avg pairwise AUC 0.941904
test  1663 RMSE 1.578296 Pearson 0.688331 Spearman 0.673884 avg pairwise AUC 0.919784
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 7.630496 affinity loss 1.509828 pairwise loss 61.206675
valid 628 RMSE 1.827951 Pearson 0.667559 Spearman 0.683995 avg pairwise AUC 0.94274
test  1663 RMSE 1.578296 Pearson 0.688331 Spearman 0.673884 avg pairwise AUC 0.919784
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.457596 affinity loss 1.454988 pairwise loss 60.026081
valid 628 RMSE 1.518993 Pearson 0.670173 Spearman 0.689605 avg pairwise AUC 0.943884
test  1663 RMSE 1.578296 Pearson 0.688331 Spearman 0.673884 avg pairwise AUC 0.919784
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.291747 affinity loss 1.399952 pairwise loss 58.917952
valid 628 RMSE 1.677961 Pearson 0.649169 Spearman 0.674573 avg pairwise AUC 0.942608
test  1663 RMSE 1.578296 Pearson 0.688331 Spearman 0.673884 avg pairwise AUC 0.919784
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.113361 affinity loss 1.322503 pairwise loss 57.908577
valid 628 RMSE 1.501549 Pearson 0.68352 Spearman 0.698866 avg pairwise AUC 0.944045
test  1663 RMSE 1.578296 Pearson 0.688331 Spearman 0.673884 avg pairwise AUC 0.919784
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 6.933507 affinity loss 1.206973 pairwise loss 57.265337
valid 628 RMSE 1.452851 Pearson 0.697699 Spearman 0.714321 avg pairwise AUC 0.944695
test  1663 RMSE 1.488358 Pearson 0.71687 Spearman 0.695404 avg pairwise AUC 0.922249
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 6.80186 affinity loss 1.191897 pairwise loss 56.099631
valid 628 RMSE 1.58052 Pearson 0.666274 Spearman 0.680581 avg pairwise AUC 0.946074
test  1663 RMSE 1.488358 Pearson 0.71687 Spearman 0.695404 avg pairwise AUC 0.922249
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.675473 affinity loss 1.157382 pairwise loss 55.18091
valid 628 RMSE 1.483364 Pearson 0.686437 Spearman 0.700956 avg pairwise AUC 0.945458
test  1663 RMSE 1.488358 Pearson 0.71687 Spearman 0.695404 avg pairwise AUC 0.922249
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.527002 affinity loss 1.077533 pairwise loss 54.49469
valid 628 RMSE 1.585491 Pearson 0.671541 Spearman 0.687565 avg pairwise AUC 0.945896
test  1663 RMSE 1.488358 Pearson 0.71687 Spearman 0.695404 avg pairwise AUC 0.922249
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.02841 affinity loss 0.886671 pairwise loss 51.417392
valid 628 RMSE 1.492194 Pearson 0.691829 Spearman 0.702419 avg pairwise AUC 0.947626
test  1663 RMSE 1.488358 Pearson 0.71687 Spearman 0.695404 avg pairwise AUC 0.922249
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 5.823975 affinity loss 0.823965 pairwise loss 50.000098
train 4698 RMSE 0.793976 Pearson 0.918175 Spearman 0.915156 avg pairwise AUC 0.988767
valid 628 RMSE 1.52153 Pearson 0.677707 Spearman 0.685989 avg pairwise AUC 0.947647
test  1663 RMSE 1.488358 Pearson 0.71687 Spearman 0.695404 avg pairwise AUC 0.922249
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.693914 affinity loss 0.772498 pairwise loss 49.214154
valid 628 RMSE 1.579447 Pearson 0.682556 Spearman 0.69354 avg pairwise AUC 0.94736
test  1663 RMSE 1.488358 Pearson 0.71687 Spearman 0.695404 avg pairwise AUC 0.922249
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.627489 affinity loss 0.791519 pairwise loss 48.359691
valid 628 RMSE 1.50904 Pearson 0.678751 Spearman 0.685832 avg pairwise AUC 0.948559
test  1663 RMSE 1.488358 Pearson 0.71687 Spearman 0.695404 avg pairwise AUC 0.922249
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.496741 affinity loss 0.705295 pairwise loss 47.914461
valid 628 RMSE 1.577204 Pearson 0.673214 Spearman 0.681006 avg pairwise AUC 0.947333
test  1663 RMSE 1.488358 Pearson 0.71687 Spearman 0.695404 avg pairwise AUC 0.922249
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.418235 affinity loss 0.702699 pairwise loss 47.155368
valid 628 RMSE 1.600485 Pearson 0.672284 Spearman 0.688627 avg pairwise AUC 0.947008
test  1663 RMSE 1.488358 Pearson 0.71687 Spearman 0.695404 avg pairwise AUC 0.922249
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.356937 affinity loss 0.677226 pairwise loss 46.797105
valid 628 RMSE 1.520732 Pearson 0.682638 Spearman 0.695137 avg pairwise AUC 0.946214
test  1663 RMSE 1.488358 Pearson 0.71687 Spearman 0.695404 avg pairwise AUC 0.922249
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.250861 affinity loss 0.615421 pairwise loss 46.354402
valid 628 RMSE 1.546081 Pearson 0.681308 Spearman 0.68919 avg pairwise AUC 0.948268
test  1663 RMSE 1.488358 Pearson 0.71687 Spearman 0.695404 avg pairwise AUC 0.922249
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.170383 affinity loss 0.572107 pairwise loss 45.982759
valid 628 RMSE 1.597529 Pearson 0.681568 Spearman 0.68991 avg pairwise AUC 0.947623
test  1663 RMSE 1.488358 Pearson 0.71687 Spearman 0.695404 avg pairwise AUC 0.922249
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.109995 affinity loss 0.567911 pairwise loss 45.420836
valid 628 RMSE 1.524697 Pearson 0.685559 Spearman 0.695879 avg pairwise AUC 0.946191
test  1663 RMSE 1.488358 Pearson 0.71687 Spearman 0.695404 avg pairwise AUC 0.922249
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.031951 affinity loss 0.538429 pairwise loss 44.935219
valid 628 RMSE 1.5109 Pearson 0.693301 Spearman 0.70504 avg pairwise AUC 0.947054
test  1663 RMSE 1.488358 Pearson 0.71687 Spearman 0.695404 avg pairwise AUC 0.922249
Finished Training
------------------------------
repeat 5 fold 5 begin
train num: 5052 valid num: 687 test num: 1250
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 1174.315498 affinity loss 13.807097 pairwise loss 11605.083737
train 5052 RMSE 1.714394 Pearson 0.596264 Spearman 0.605297 avg pairwise AUC 0.855331
valid 687 RMSE 1.713969 Pearson 0.545073 Spearman 0.552604 avg pairwise AUC 0.846665
test  1250 RMSE 1.721366 Pearson 0.58855 Spearman 0.58352 avg pairwise AUC 0.852684
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.111763 affinity loss 3.116307 pairwise loss 99.954562
valid 687 RMSE 2.454472 Pearson 0.57496 Spearman 0.58722 avg pairwise AUC 0.890435
test  1250 RMSE 1.721366 Pearson 0.58855 Spearman 0.58352 avg pairwise AUC 0.852684
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 12.262885 affinity loss 3.098744 pairwise loss 91.641408
valid 687 RMSE 1.631316 Pearson 0.591518 Spearman 0.603441 avg pairwise AUC 0.907888
test  1250 RMSE 1.600653 Pearson 0.623902 Spearman 0.619463 avg pairwise AUC 0.913801
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 11.217112 affinity loss 2.666272 pairwise loss 85.508403
valid 687 RMSE 1.576918 Pearson 0.607185 Spearman 0.622983 avg pairwise AUC 0.91333
test  1250 RMSE 1.54007 Pearson 0.653447 Spearman 0.653459 avg pairwise AUC 0.919646
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.65915 affinity loss 2.565349 pairwise loss 80.938009
valid 687 RMSE 1.532827 Pearson 0.630771 Spearman 0.644513 avg pairwise AUC 0.919229
test  1250 RMSE 1.50576 Pearson 0.680494 Spearman 0.681153 avg pairwise AUC 0.924189
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 10.107175 affinity loss 2.407136 pairwise loss 77.000395
valid 687 RMSE 1.601658 Pearson 0.642253 Spearman 0.662397 avg pairwise AUC 0.920527
test  1250 RMSE 1.50576 Pearson 0.680494 Spearman 0.681153 avg pairwise AUC 0.924189
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.695692 affinity loss 2.324831 pairwise loss 73.708604
valid 687 RMSE 1.532896 Pearson 0.638723 Spearman 0.652046 avg pairwise AUC 0.925254
test  1250 RMSE 1.50576 Pearson 0.680494 Spearman 0.681153 avg pairwise AUC 0.924189
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.246067 affinity loss 2.108677 pairwise loss 71.373899
valid 687 RMSE 1.586188 Pearson 0.629163 Spearman 0.641822 avg pairwise AUC 0.927598
test  1250 RMSE 1.50576 Pearson 0.680494 Spearman 0.681153 avg pairwise AUC 0.924189
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.895625 affinity loss 1.944806 pairwise loss 69.508193
valid 687 RMSE 1.559849 Pearson 0.627947 Spearman 0.653816 avg pairwise AUC 0.92902
test  1250 RMSE 1.50576 Pearson 0.680494 Spearman 0.681153 avg pairwise AUC 0.924189
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.662362 affinity loss 1.835652 pairwise loss 68.267103
valid 687 RMSE 1.492358 Pearson 0.651629 Spearman 0.671987 avg pairwise AUC 0.927758
test  1250 RMSE 1.384329 Pearson 0.728537 Spearman 0.725315 avg pairwise AUC 0.937035
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.339725 affinity loss 1.756461 pairwise loss 65.832642
train 5052 RMSE 1.179139 Pearson 0.83051 Spearman 0.830399 avg pairwise AUC 0.970549
valid 687 RMSE 1.465014 Pearson 0.661715 Spearman 0.67985 avg pairwise AUC 0.92767
test  1250 RMSE 1.39827 Pearson 0.724922 Spearman 0.722651 avg pairwise AUC 0.937697
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 8.098789 affinity loss 1.575674 pairwise loss 65.231151
valid 687 RMSE 1.585328 Pearson 0.640552 Spearman 0.66043 avg pairwise AUC 0.931276
test  1250 RMSE 1.39827 Pearson 0.724922 Spearman 0.722651 avg pairwise AUC 0.937697
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.898221 affinity loss 1.513447 pairwise loss 63.847738
valid 687 RMSE 1.547358 Pearson 0.634391 Spearman 0.65514 avg pairwise AUC 0.93353
test  1250 RMSE 1.39827 Pearson 0.724922 Spearman 0.722651 avg pairwise AUC 0.937697
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.596818 affinity loss 1.385843 pairwise loss 62.109747
valid 687 RMSE 1.599513 Pearson 0.627168 Spearman 0.640645 avg pairwise AUC 0.933368
test  1250 RMSE 1.39827 Pearson 0.724922 Spearman 0.722651 avg pairwise AUC 0.937697
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.468055 affinity loss 1.333517 pairwise loss 61.345381
valid 687 RMSE 1.607642 Pearson 0.628138 Spearman 0.644209 avg pairwise AUC 0.934398
test  1250 RMSE 1.39827 Pearson 0.724922 Spearman 0.722651 avg pairwise AUC 0.937697
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.287146 affinity loss 1.31944 pairwise loss 59.677064
valid 687 RMSE 1.537635 Pearson 0.650798 Spearman 0.664181 avg pairwise AUC 0.935041
test  1250 RMSE 1.39827 Pearson 0.724922 Spearman 0.722651 avg pairwise AUC 0.937697
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 7.079975 affinity loss 1.190832 pairwise loss 58.891432
valid 687 RMSE 1.496893 Pearson 0.65942 Spearman 0.674307 avg pairwise AUC 0.934408
test  1250 RMSE 1.39827 Pearson 0.724922 Spearman 0.722651 avg pairwise AUC 0.937697
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 7.000218 affinity loss 1.168531 pairwise loss 58.316864
valid 687 RMSE 1.563263 Pearson 0.62874 Spearman 0.645337 avg pairwise AUC 0.93639
test  1250 RMSE 1.39827 Pearson 0.724922 Spearman 0.722651 avg pairwise AUC 0.937697
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.87006 affinity loss 1.148224 pairwise loss 57.218362
valid 687 RMSE 1.576687 Pearson 0.629663 Spearman 0.641519 avg pairwise AUC 0.937196
test  1250 RMSE 1.39827 Pearson 0.724922 Spearman 0.722651 avg pairwise AUC 0.937697
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.303628 affinity loss 0.884257 pairwise loss 54.193708
valid 687 RMSE 1.517297 Pearson 0.657911 Spearman 0.669972 avg pairwise AUC 0.936931
test  1250 RMSE 1.39827 Pearson 0.724922 Spearman 0.722651 avg pairwise AUC 0.937697
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 6.062642 affinity loss 0.804187 pairwise loss 52.58454
train 5052 RMSE 0.814954 Pearson 0.917975 Spearman 0.918346 avg pairwise AUC 0.986762
valid 687 RMSE 1.523087 Pearson 0.661349 Spearman 0.672244 avg pairwise AUC 0.936896
test  1250 RMSE 1.39827 Pearson 0.724922 Spearman 0.722651 avg pairwise AUC 0.937697
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.941468 affinity loss 0.755295 pairwise loss 51.861723
valid 687 RMSE 1.551912 Pearson 0.646082 Spearman 0.662725 avg pairwise AUC 0.936655
test  1250 RMSE 1.39827 Pearson 0.724922 Spearman 0.722651 avg pairwise AUC 0.937697
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.811 affinity loss 0.69188 pairwise loss 51.191195
valid 687 RMSE 1.547575 Pearson 0.642887 Spearman 0.655674 avg pairwise AUC 0.938369
test  1250 RMSE 1.39827 Pearson 0.724922 Spearman 0.722651 avg pairwise AUC 0.937697
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.676179 affinity loss 0.656146 pairwise loss 50.200333
valid 687 RMSE 1.562691 Pearson 0.64582 Spearman 0.661265 avg pairwise AUC 0.936604
test  1250 RMSE 1.39827 Pearson 0.724922 Spearman 0.722651 avg pairwise AUC 0.937697
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.623393 affinity loss 0.660978 pairwise loss 49.624152
valid 687 RMSE 1.557564 Pearson 0.657427 Spearman 0.668237 avg pairwise AUC 0.938588
test  1250 RMSE 1.39827 Pearson 0.724922 Spearman 0.722651 avg pairwise AUC 0.937697
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.533605 affinity loss 0.624264 pairwise loss 49.093413
valid 687 RMSE 1.596823 Pearson 0.637435 Spearman 0.651571 avg pairwise AUC 0.937409
test  1250 RMSE 1.39827 Pearson 0.724922 Spearman 0.722651 avg pairwise AUC 0.937697
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.437664 affinity loss 0.577527 pairwise loss 48.601374
valid 687 RMSE 1.569935 Pearson 0.64842 Spearman 0.656916 avg pairwise AUC 0.936869
test  1250 RMSE 1.39827 Pearson 0.724922 Spearman 0.722651 avg pairwise AUC 0.937697
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.367003 affinity loss 0.552135 pairwise loss 48.148678
valid 687 RMSE 1.562848 Pearson 0.634242 Spearman 0.652726 avg pairwise AUC 0.93746
test  1250 RMSE 1.39827 Pearson 0.724922 Spearman 0.722651 avg pairwise AUC 0.937697
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.267892 affinity loss 0.523561 pairwise loss 47.44331
valid 687 RMSE 1.56941 Pearson 0.633564 Spearman 0.648295 avg pairwise AUC 0.9376
test  1250 RMSE 1.39827 Pearson 0.724922 Spearman 0.722651 avg pairwise AUC 0.937697
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.224475 affinity loss 0.51998 pairwise loss 47.044953
valid 687 RMSE 1.608724 Pearson 0.621414 Spearman 0.638779 avg pairwise AUC 0.937794
test  1250 RMSE 1.39827 Pearson 0.724922 Spearman 0.722651 avg pairwise AUC 0.937697
Finished Training
------------------------------
fold avg performance [1.50029704 0.68172438 0.68677273 0.93377684]
/home/junseok/workspace/monn/src/pdbbind_utils.py:198: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  data_pack = [np.array(data) for data in data_pack]
setting: new_compound
fold 0 train  4907 test  1397 valid  685
fold 1 train  4929 test  1316 valid  744
fold 2 train  5059 test  1296 valid  634
fold 3 train  4949 test  1359 valid  681
fold 4 train  4674 test  1621 valid  694
repeat 6 fold 1 begin
train num: 4907 valid num: 685 test num: 1397
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 1208.862714 affinity loss 8.697224 pairwise loss 12001.653981
train 4907 RMSE 2.195217 Pearson 0.588963 Spearman 0.602678 avg pairwise AUC 0.856651
valid 685 RMSE 2.258571 Pearson 0.527928 Spearman 0.54881 avg pairwise AUC 0.848535
test  1397 RMSE 2.261558 Pearson 0.537898 Spearman 0.5431 avg pairwise AUC 0.85148
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.409036 affinity loss 3.195257 pairwise loss 102.137793
valid 685 RMSE 1.736188 Pearson 0.571828 Spearman 0.597214 avg pairwise AUC 0.892853
test  1397 RMSE 1.730058 Pearson 0.597771 Spearman 0.598974 avg pairwise AUC 0.893317
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 12.14089 affinity loss 2.895206 pairwise loss 92.456835
valid 685 RMSE 1.713123 Pearson 0.571836 Spearman 0.601313 avg pairwise AUC 0.906712
test  1397 RMSE 1.681878 Pearson 0.615868 Spearman 0.614465 avg pairwise AUC 0.906924
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 11.237882 affinity loss 2.591244 pairwise loss 86.466377
valid 685 RMSE 1.734391 Pearson 0.574068 Spearman 0.60344 avg pairwise AUC 0.911548
test  1397 RMSE 1.681878 Pearson 0.615868 Spearman 0.614465 avg pairwise AUC 0.906924
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.610372 affinity loss 2.483914 pairwise loss 81.264584
valid 685 RMSE 2.241007 Pearson 0.550384 Spearman 0.622884 avg pairwise AUC 0.920247
test  1397 RMSE 1.681878 Pearson 0.615868 Spearman 0.614465 avg pairwise AUC 0.906924
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 10.323462 affinity loss 2.618266 pairwise loss 77.051958
valid 685 RMSE 1.672071 Pearson 0.59331 Spearman 0.623095 avg pairwise AUC 0.925449
test  1397 RMSE 1.590993 Pearson 0.66154 Spearman 0.665188 avg pairwise AUC 0.926551
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.682297 affinity loss 2.248479 pairwise loss 74.338182
valid 685 RMSE 1.651192 Pearson 0.630446 Spearman 0.657739 avg pairwise AUC 0.929783
test  1397 RMSE 1.600722 Pearson 0.687721 Spearman 0.687893 avg pairwise AUC 0.930249
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.24572 affinity loss 2.168056 pairwise loss 70.776642
valid 685 RMSE 2.387687 Pearson 0.600886 Spearman 0.627267 avg pairwise AUC 0.928845
test  1397 RMSE 1.600722 Pearson 0.687721 Spearman 0.687893 avg pairwise AUC 0.930249
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.873897 affinity loss 1.985766 pairwise loss 68.881313
valid 685 RMSE 1.626564 Pearson 0.617011 Spearman 0.638009 avg pairwise AUC 0.931944
test  1397 RMSE 1.505161 Pearson 0.702921 Spearman 0.70239 avg pairwise AUC 0.93334
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.582888 affinity loss 1.790015 pairwise loss 67.928729
valid 685 RMSE 1.611065 Pearson 0.63643 Spearman 0.658326 avg pairwise AUC 0.931742
test  1397 RMSE 1.511891 Pearson 0.708797 Spearman 0.709025 avg pairwise AUC 0.932189
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.318196 affinity loss 1.765636 pairwise loss 65.5256
train 4907 RMSE 1.215926 Pearson 0.807943 Spearman 0.816505 avg pairwise AUC 0.973032
valid 685 RMSE 1.584264 Pearson 0.65632 Spearman 0.680153 avg pairwise AUC 0.931953
test  1397 RMSE 1.481164 Pearson 0.720979 Spearman 0.71119 avg pairwise AUC 0.933939
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 8.008538 affinity loss 1.567907 pairwise loss 64.406309
valid 685 RMSE 1.659965 Pearson 0.639566 Spearman 0.664289 avg pairwise AUC 0.933938
test  1397 RMSE 1.481164 Pearson 0.720979 Spearman 0.71119 avg pairwise AUC 0.933939
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.790456 affinity loss 1.500218 pairwise loss 62.902377
valid 685 RMSE 1.60967 Pearson 0.646184 Spearman 0.672307 avg pairwise AUC 0.933856
test  1397 RMSE 1.481164 Pearson 0.720979 Spearman 0.71119 avg pairwise AUC 0.933939
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.664348 affinity loss 1.52383 pairwise loss 61.405179
valid 685 RMSE 1.616775 Pearson 0.652601 Spearman 0.669411 avg pairwise AUC 0.934675
test  1397 RMSE 1.481164 Pearson 0.720979 Spearman 0.71119 avg pairwise AUC 0.933939
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.406766 affinity loss 1.317989 pairwise loss 60.887769
valid 685 RMSE 1.694407 Pearson 0.642808 Spearman 0.658875 avg pairwise AUC 0.933754
test  1397 RMSE 1.481164 Pearson 0.720979 Spearman 0.71119 avg pairwise AUC 0.933939
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.307182 affinity loss 1.285568 pairwise loss 60.216138
valid 685 RMSE 1.669656 Pearson 0.655096 Spearman 0.669717 avg pairwise AUC 0.935183
test  1397 RMSE 1.481164 Pearson 0.720979 Spearman 0.71119 avg pairwise AUC 0.933939
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 7.084645 affinity loss 1.193126 pairwise loss 58.915192
valid 685 RMSE 1.774249 Pearson 0.646393 Spearman 0.663158 avg pairwise AUC 0.934119
test  1397 RMSE 1.481164 Pearson 0.720979 Spearman 0.71119 avg pairwise AUC 0.933939
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.975343 affinity loss 1.19739 pairwise loss 57.779529
valid 685 RMSE 1.61997 Pearson 0.653947 Spearman 0.668676 avg pairwise AUC 0.935876
test  1397 RMSE 1.481164 Pearson 0.720979 Spearman 0.71119 avg pairwise AUC 0.933939
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.909351 affinity loss 1.182533 pairwise loss 57.268179
valid 685 RMSE 1.546453 Pearson 0.673717 Spearman 0.685297 avg pairwise AUC 0.936226
test  1397 RMSE 1.454381 Pearson 0.725118 Spearman 0.717045 avg pairwise AUC 0.939112
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.278074 affinity loss 0.890778 pairwise loss 53.872962
valid 685 RMSE 1.596246 Pearson 0.671746 Spearman 0.682109 avg pairwise AUC 0.935516
test  1397 RMSE 1.454381 Pearson 0.725118 Spearman 0.717045 avg pairwise AUC 0.939112
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 6.043068 affinity loss 0.805139 pairwise loss 52.379287
train 4907 RMSE 0.849537 Pearson 0.916234 Spearman 0.916084 avg pairwise AUC 0.986991
valid 685 RMSE 1.587493 Pearson 0.671198 Spearman 0.686251 avg pairwise AUC 0.936251
test  1397 RMSE 1.454381 Pearson 0.725118 Spearman 0.717045 avg pairwise AUC 0.939112
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.908412 affinity loss 0.751454 pairwise loss 51.569577
valid 685 RMSE 1.569319 Pearson 0.673561 Spearman 0.68357 avg pairwise AUC 0.935534
test  1397 RMSE 1.454381 Pearson 0.725118 Spearman 0.717045 avg pairwise AUC 0.939112
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.818675 affinity loss 0.743414 pairwise loss 50.752606
valid 685 RMSE 1.64172 Pearson 0.670856 Spearman 0.684298 avg pairwise AUC 0.93546
test  1397 RMSE 1.454381 Pearson 0.725118 Spearman 0.717045 avg pairwise AUC 0.939112
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.708693 affinity loss 0.692239 pairwise loss 50.164544
valid 685 RMSE 1.556262 Pearson 0.672155 Spearman 0.684257 avg pairwise AUC 0.935585
test  1397 RMSE 1.454381 Pearson 0.725118 Spearman 0.717045 avg pairwise AUC 0.939112
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.630337 affinity loss 0.65966 pairwise loss 49.706772
valid 685 RMSE 1.57725 Pearson 0.66456 Spearman 0.676863 avg pairwise AUC 0.936622
test  1397 RMSE 1.454381 Pearson 0.725118 Spearman 0.717045 avg pairwise AUC 0.939112
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.521605 affinity loss 0.63301 pairwise loss 48.885946
valid 685 RMSE 1.588736 Pearson 0.666659 Spearman 0.678872 avg pairwise AUC 0.935512
test  1397 RMSE 1.454381 Pearson 0.725118 Spearman 0.717045 avg pairwise AUC 0.939112
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.463013 affinity loss 0.59353 pairwise loss 48.694836
valid 685 RMSE 1.598812 Pearson 0.665662 Spearman 0.678475 avg pairwise AUC 0.935039
test  1397 RMSE 1.454381 Pearson 0.725118 Spearman 0.717045 avg pairwise AUC 0.939112
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.378622 affinity loss 0.569736 pairwise loss 48.088861
valid 685 RMSE 1.620043 Pearson 0.667744 Spearman 0.679717 avg pairwise AUC 0.937796
test  1397 RMSE 1.454381 Pearson 0.725118 Spearman 0.717045 avg pairwise AUC 0.939112
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.265548 affinity loss 0.530477 pairwise loss 47.350716
valid 685 RMSE 1.59834 Pearson 0.663161 Spearman 0.670664 avg pairwise AUC 0.936086
test  1397 RMSE 1.454381 Pearson 0.725118 Spearman 0.717045 avg pairwise AUC 0.939112
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.192835 affinity loss 0.517247 pairwise loss 46.755878
valid 685 RMSE 1.599477 Pearson 0.657121 Spearman 0.671068 avg pairwise AUC 0.93552
test  1397 RMSE 1.454381 Pearson 0.725118 Spearman 0.717045 avg pairwise AUC 0.939112
Finished Training
------------------------------
repeat 6 fold 2 begin
train num: 4929 valid num: 744 test num: 1316
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 1401.576599 affinity loss 12.190826 pairwise loss 13893.857404
train 4929 RMSE 2.077082 Pearson 0.579503 Spearman 0.584296 avg pairwise AUC 0.856883
valid 744 RMSE 2.113123 Pearson 0.580241 Spearman 0.57985 avg pairwise AUC 0.845615
test  1316 RMSE 2.181105 Pearson 0.523136 Spearman 0.541898 avg pairwise AUC 0.839935
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.118822 affinity loss 3.14628 pairwise loss 99.725421
valid 744 RMSE 1.727258 Pearson 0.602505 Spearman 0.609226 avg pairwise AUC 0.883955
test  1316 RMSE 1.739689 Pearson 0.554123 Spearman 0.571883 avg pairwise AUC 0.881101
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 11.971966 affinity loss 2.8385 pairwise loss 91.334656
valid 744 RMSE 1.666579 Pearson 0.628754 Spearman 0.627344 avg pairwise AUC 0.90431
test  1316 RMSE 1.689196 Pearson 0.570998 Spearman 0.589307 avg pairwise AUC 0.901482
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 11.207316 affinity loss 2.732227 pairwise loss 84.750891
valid 744 RMSE 1.798038 Pearson 0.62401 Spearman 0.635729 avg pairwise AUC 0.915811
test  1316 RMSE 1.689196 Pearson 0.570998 Spearman 0.589307 avg pairwise AUC 0.901482
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.735495 affinity loss 2.707166 pairwise loss 80.283286
valid 744 RMSE 1.595292 Pearson 0.667946 Spearman 0.67058 avg pairwise AUC 0.915634
test  1316 RMSE 1.645507 Pearson 0.606544 Spearman 0.627815 avg pairwise AUC 0.913071
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 10.182214 affinity loss 2.487114 pairwise loss 76.951003
valid 744 RMSE 1.855328 Pearson 0.656709 Spearman 0.662634 avg pairwise AUC 0.925471
test  1316 RMSE 1.645507 Pearson 0.606544 Spearman 0.627815 avg pairwise AUC 0.913071
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.508058 affinity loss 2.220825 pairwise loss 72.87233
valid 744 RMSE 1.583525 Pearson 0.68702 Spearman 0.692372 avg pairwise AUC 0.928112
test  1316 RMSE 1.649499 Pearson 0.634593 Spearman 0.653082 avg pairwise AUC 0.924393
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.119288 affinity loss 2.083141 pairwise loss 70.36147
valid 744 RMSE 1.584483 Pearson 0.665522 Spearman 0.669929 avg pairwise AUC 0.929675
test  1316 RMSE 1.649499 Pearson 0.634593 Spearman 0.653082 avg pairwise AUC 0.924393
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.716796 affinity loss 1.979303 pairwise loss 67.374928
valid 744 RMSE 1.552709 Pearson 0.682029 Spearman 0.682243 avg pairwise AUC 0.929936
test  1316 RMSE 1.588202 Pearson 0.62938 Spearman 0.647661 avg pairwise AUC 0.926819
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.644319 affinity loss 2.027242 pairwise loss 66.170773
valid 744 RMSE 1.485488 Pearson 0.70813 Spearman 0.706118 avg pairwise AUC 0.932321
test  1316 RMSE 1.58604 Pearson 0.634364 Spearman 0.652891 avg pairwise AUC 0.929898
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.194313 affinity loss 1.796888 pairwise loss 63.974244
train 4929 RMSE 1.245439 Pearson 0.809033 Spearman 0.812087 avg pairwise AUC 0.975043
valid 744 RMSE 1.492162 Pearson 0.716897 Spearman 0.718938 avg pairwise AUC 0.934222
test  1316 RMSE 1.58604 Pearson 0.634364 Spearman 0.652891 avg pairwise AUC 0.929898
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 7.90406 affinity loss 1.689801 pairwise loss 62.142588
valid 744 RMSE 1.465571 Pearson 0.721733 Spearman 0.709671 avg pairwise AUC 0.933672
test  1316 RMSE 1.54783 Pearson 0.655958 Spearman 0.674419 avg pairwise AUC 0.932266
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.896299 affinity loss 1.817512 pairwise loss 60.787878
valid 744 RMSE 1.706904 Pearson 0.730442 Spearman 0.7171 avg pairwise AUC 0.932064
test  1316 RMSE 1.54783 Pearson 0.655958 Spearman 0.674419 avg pairwise AUC 0.932266
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.578271 affinity loss 1.511751 pairwise loss 60.665199
valid 744 RMSE 1.405534 Pearson 0.738291 Spearman 0.727093 avg pairwise AUC 0.937225
test  1316 RMSE 1.501547 Pearson 0.677324 Spearman 0.687797 avg pairwise AUC 0.935003
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.502172 affinity loss 1.614932 pairwise loss 58.872393
valid 744 RMSE 1.454535 Pearson 0.751727 Spearman 0.741337 avg pairwise AUC 0.935386
test  1316 RMSE 1.501547 Pearson 0.677324 Spearman 0.687797 avg pairwise AUC 0.935003
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.172307 affinity loss 1.323941 pairwise loss 58.483653
valid 744 RMSE 1.419871 Pearson 0.73286 Spearman 0.724889 avg pairwise AUC 0.93729
test  1316 RMSE 1.501547 Pearson 0.677324 Spearman 0.687797 avg pairwise AUC 0.935003
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 7.126162 affinity loss 1.38275 pairwise loss 57.434122
valid 744 RMSE 1.374338 Pearson 0.750738 Spearman 0.738987 avg pairwise AUC 0.937873
test  1316 RMSE 1.535257 Pearson 0.668066 Spearman 0.682805 avg pairwise AUC 0.935364
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.94945 affinity loss 1.248598 pairwise loss 57.008522
valid 744 RMSE 1.431364 Pearson 0.747702 Spearman 0.73559 avg pairwise AUC 0.937691
test  1316 RMSE 1.535257 Pearson 0.668066 Spearman 0.682805 avg pairwise AUC 0.935364
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.818025 affinity loss 1.289699 pairwise loss 55.283251
valid 744 RMSE 1.359039 Pearson 0.756928 Spearman 0.742716 avg pairwise AUC 0.937542
test  1316 RMSE 1.515114 Pearson 0.670902 Spearman 0.684777 avg pairwise AUC 0.934235
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.213737 affinity loss 0.969923 pairwise loss 52.438134
valid 744 RMSE 1.3838 Pearson 0.750874 Spearman 0.741106 avg pairwise AUC 0.938832
test  1316 RMSE 1.515114 Pearson 0.670902 Spearman 0.684777 avg pairwise AUC 0.934235
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 5.993865 affinity loss 0.863761 pairwise loss 51.30104
train 4929 RMSE 0.853441 Pearson 0.911265 Spearman 0.908959 avg pairwise AUC 0.98813
valid 744 RMSE 1.38128 Pearson 0.755934 Spearman 0.742882 avg pairwise AUC 0.939605
test  1316 RMSE 1.515114 Pearson 0.670902 Spearman 0.684777 avg pairwise AUC 0.934235
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.889793 affinity loss 0.866594 pairwise loss 50.23199
valid 744 RMSE 1.401695 Pearson 0.746968 Spearman 0.73604 avg pairwise AUC 0.94038
test  1316 RMSE 1.515114 Pearson 0.670902 Spearman 0.684777 avg pairwise AUC 0.934235
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.765158 affinity loss 0.788195 pairwise loss 49.769627
valid 744 RMSE 1.418805 Pearson 0.741908 Spearman 0.732657 avg pairwise AUC 0.939152
test  1316 RMSE 1.515114 Pearson 0.670902 Spearman 0.684777 avg pairwise AUC 0.934235
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.663723 affinity loss 0.765658 pairwise loss 48.980656
valid 744 RMSE 1.504063 Pearson 0.729881 Spearman 0.716672 avg pairwise AUC 0.938781
test  1316 RMSE 1.515114 Pearson 0.670902 Spearman 0.684777 avg pairwise AUC 0.934235
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.516109 affinity loss 0.696173 pairwise loss 48.199365
valid 744 RMSE 1.628932 Pearson 0.672305 Spearman 0.730164 avg pairwise AUC 0.938955
test  1316 RMSE 1.515114 Pearson 0.670902 Spearman 0.684777 avg pairwise AUC 0.934235
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.479472 affinity loss 0.683233 pairwise loss 47.962386
valid 744 RMSE 1.397182 Pearson 0.745761 Spearman 0.733471 avg pairwise AUC 0.938876
test  1316 RMSE 1.515114 Pearson 0.670902 Spearman 0.684777 avg pairwise AUC 0.934235
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.375125 affinity loss 0.653665 pairwise loss 47.2146
valid 744 RMSE 1.39656 Pearson 0.746253 Spearman 0.734802 avg pairwise AUC 0.938993
test  1316 RMSE 1.515114 Pearson 0.670902 Spearman 0.684777 avg pairwise AUC 0.934235
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.289962 affinity loss 0.617507 pairwise loss 46.724546
valid 744 RMSE 1.400938 Pearson 0.748687 Spearman 0.735064 avg pairwise AUC 0.938318
test  1316 RMSE 1.515114 Pearson 0.670902 Spearman 0.684777 avg pairwise AUC 0.934235
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.205959 affinity loss 0.589674 pairwise loss 46.162846
valid 744 RMSE 1.453732 Pearson 0.731171 Spearman 0.717803 avg pairwise AUC 0.938551
test  1316 RMSE 1.515114 Pearson 0.670902 Spearman 0.684777 avg pairwise AUC 0.934235
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.116028 affinity loss 0.572414 pairwise loss 45.43614
valid 744 RMSE 1.492401 Pearson 0.73033 Spearman 0.717651 avg pairwise AUC 0.938948
test  1316 RMSE 1.515114 Pearson 0.670902 Spearman 0.684777 avg pairwise AUC 0.934235
Finished Training
------------------------------
repeat 6 fold 3 begin
train num: 5059 valid num: 634 test num: 1296
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 2071.893815 affinity loss 12.43524 pairwise loss 20594.585492
train 5059 RMSE 1.688032 Pearson 0.589076 Spearman 0.5987 avg pairwise AUC 0.852737
valid 634 RMSE 1.712216 Pearson 0.530527 Spearman 0.52068 avg pairwise AUC 0.846301
test  1296 RMSE 1.725219 Pearson 0.537616 Spearman 0.559521 avg pairwise AUC 0.842951
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.071164 affinity loss 2.981874 pairwise loss 100.892901
valid 634 RMSE 1.631549 Pearson 0.575921 Spearman 0.55934 avg pairwise AUC 0.88778
test  1296 RMSE 1.663806 Pearson 0.563829 Spearman 0.584933 avg pairwise AUC 0.888797
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 12.094429 affinity loss 2.881533 pairwise loss 92.128953
valid 634 RMSE 1.805043 Pearson 0.605714 Spearman 0.594979 avg pairwise AUC 0.906466
test  1296 RMSE 1.663806 Pearson 0.563829 Spearman 0.584933 avg pairwise AUC 0.888797
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 11.112301 affinity loss 2.521962 pairwise loss 85.903386
valid 634 RMSE 1.737271 Pearson 0.612173 Spearman 0.602044 avg pairwise AUC 0.914946
test  1296 RMSE 1.663806 Pearson 0.563829 Spearman 0.584933 avg pairwise AUC 0.888797
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.513584 affinity loss 2.508016 pairwise loss 80.055686
valid 634 RMSE 1.642145 Pearson 0.63265 Spearman 0.624578 avg pairwise AUC 0.922704
test  1296 RMSE 1.663806 Pearson 0.563829 Spearman 0.584933 avg pairwise AUC 0.888797
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.992091 affinity loss 2.355643 pairwise loss 76.36448
valid 634 RMSE 1.636705 Pearson 0.614583 Spearman 0.605111 avg pairwise AUC 0.927212
test  1296 RMSE 1.663806 Pearson 0.563829 Spearman 0.584933 avg pairwise AUC 0.888797
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.423475 affinity loss 2.121425 pairwise loss 73.020497
valid 634 RMSE 1.578609 Pearson 0.638377 Spearman 0.626965 avg pairwise AUC 0.926613
test  1296 RMSE 1.579623 Pearson 0.650183 Spearman 0.665592 avg pairwise AUC 0.932355
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.042139 affinity loss 2.008367 pairwise loss 70.337719
valid 634 RMSE 1.576376 Pearson 0.630053 Spearman 0.624979 avg pairwise AUC 0.930699
test  1296 RMSE 1.51694 Pearson 0.66882 Spearman 0.677986 avg pairwise AUC 0.936602
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.957502 affinity loss 2.098321 pairwise loss 68.59181
valid 634 RMSE 1.927877 Pearson 0.630411 Spearman 0.626935 avg pairwise AUC 0.92942
test  1296 RMSE 1.51694 Pearson 0.66882 Spearman 0.677986 avg pairwise AUC 0.936602
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.536207 affinity loss 1.906378 pairwise loss 66.298295
valid 634 RMSE 1.578736 Pearson 0.626669 Spearman 0.629346 avg pairwise AUC 0.929886
test  1296 RMSE 1.51694 Pearson 0.66882 Spearman 0.677986 avg pairwise AUC 0.936602
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.229917 affinity loss 1.779003 pairwise loss 64.509143
train 5059 RMSE 1.168722 Pearson 0.819959 Spearman 0.818916 avg pairwise AUC 0.973161
valid 634 RMSE 1.54215 Pearson 0.655248 Spearman 0.6475 avg pairwise AUC 0.933224
test  1296 RMSE 1.50043 Pearson 0.683795 Spearman 0.696327 avg pairwise AUC 0.939825
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 7.933337 affinity loss 1.565061 pairwise loss 63.682755
valid 634 RMSE 1.595458 Pearson 0.671648 Spearman 0.66124 avg pairwise AUC 0.935101
test  1296 RMSE 1.50043 Pearson 0.683795 Spearman 0.696327 avg pairwise AUC 0.939825
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.685291 affinity loss 1.457123 pairwise loss 62.281677
valid 634 RMSE 1.544868 Pearson 0.661647 Spearman 0.643622 avg pairwise AUC 0.933616
test  1296 RMSE 1.50043 Pearson 0.683795 Spearman 0.696327 avg pairwise AUC 0.939825
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.490492 affinity loss 1.355377 pairwise loss 61.351142
valid 634 RMSE 1.593852 Pearson 0.66288 Spearman 0.658336 avg pairwise AUC 0.933696
test  1296 RMSE 1.50043 Pearson 0.683795 Spearman 0.696327 avg pairwise AUC 0.939825
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.334901 affinity loss 1.31371 pairwise loss 60.211904
valid 634 RMSE 1.541815 Pearson 0.65804 Spearman 0.649704 avg pairwise AUC 0.932391
test  1296 RMSE 1.497464 Pearson 0.683148 Spearman 0.691387 avg pairwise AUC 0.941894
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.1844 affinity loss 1.291924 pairwise loss 58.924753
valid 634 RMSE 1.539079 Pearson 0.654709 Spearman 0.637481 avg pairwise AUC 0.936509
test  1296 RMSE 1.479091 Pearson 0.690573 Spearman 0.695499 avg pairwise AUC 0.944514
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 7.007055 affinity loss 1.153513 pairwise loss 58.535424
valid 634 RMSE 1.594387 Pearson 0.669202 Spearman 0.658503 avg pairwise AUC 0.935438
test  1296 RMSE 1.479091 Pearson 0.690573 Spearman 0.695499 avg pairwise AUC 0.944514
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.888459 affinity loss 1.156229 pairwise loss 57.322304
valid 634 RMSE 1.682903 Pearson 0.669513 Spearman 0.655221 avg pairwise AUC 0.936507
test  1296 RMSE 1.479091 Pearson 0.690573 Spearman 0.695499 avg pairwise AUC 0.944514
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.727549 affinity loss 1.08795 pairwise loss 56.395983
valid 634 RMSE 1.601485 Pearson 0.631256 Spearman 0.615139 avg pairwise AUC 0.938399
test  1296 RMSE 1.479091 Pearson 0.690573 Spearman 0.695499 avg pairwise AUC 0.944514
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.198114 affinity loss 0.839925 pairwise loss 53.581889
valid 634 RMSE 1.541223 Pearson 0.659644 Spearman 0.645591 avg pairwise AUC 0.938825
test  1296 RMSE 1.479091 Pearson 0.690573 Spearman 0.695499 avg pairwise AUC 0.944514
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 5.954498 affinity loss 0.788106 pairwise loss 51.663923
train 5059 RMSE 0.783508 Pearson 0.923952 Spearman 0.923546 avg pairwise AUC 0.987675
valid 634 RMSE 1.53475 Pearson 0.673171 Spearman 0.658303 avg pairwise AUC 0.939084
test  1296 RMSE 1.4848 Pearson 0.700046 Spearman 0.707645 avg pairwise AUC 0.947025
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.827098 affinity loss 0.740673 pairwise loss 50.864245
valid 634 RMSE 1.602252 Pearson 0.666645 Spearman 0.660014 avg pairwise AUC 0.937769
test  1296 RMSE 1.4848 Pearson 0.700046 Spearman 0.707645 avg pairwise AUC 0.947025
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.724108 affinity loss 0.740728 pairwise loss 49.833796
valid 634 RMSE 1.603175 Pearson 0.677695 Spearman 0.66392 avg pairwise AUC 0.938568
test  1296 RMSE 1.4848 Pearson 0.700046 Spearman 0.707645 avg pairwise AUC 0.947025
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.591212 affinity loss 0.643664 pairwise loss 49.475479
valid 634 RMSE 1.572691 Pearson 0.66268 Spearman 0.642739 avg pairwise AUC 0.93878
test  1296 RMSE 1.4848 Pearson 0.700046 Spearman 0.707645 avg pairwise AUC 0.947025
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.543736 affinity loss 0.65236 pairwise loss 48.91376
valid 634 RMSE 1.508567 Pearson 0.681601 Spearman 0.662897 avg pairwise AUC 0.938174
test  1296 RMSE 1.469109 Pearson 0.705148 Spearman 0.711608 avg pairwise AUC 0.947571
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.417352 affinity loss 0.587149 pairwise loss 48.302028
valid 634 RMSE 1.579171 Pearson 0.668526 Spearman 0.655395 avg pairwise AUC 0.939106
test  1296 RMSE 1.469109 Pearson 0.705148 Spearman 0.711608 avg pairwise AUC 0.947571
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.373387 affinity loss 0.583174 pairwise loss 47.90213
valid 634 RMSE 1.724631 Pearson 0.670868 Spearman 0.655036 avg pairwise AUC 0.937833
test  1296 RMSE 1.469109 Pearson 0.705148 Spearman 0.711608 avg pairwise AUC 0.947571
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.267444 affinity loss 0.556576 pairwise loss 47.108678
valid 634 RMSE 1.567241 Pearson 0.659455 Spearman 0.645354 avg pairwise AUC 0.937927
test  1296 RMSE 1.469109 Pearson 0.705148 Spearman 0.711608 avg pairwise AUC 0.947571
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.169721 affinity loss 0.500764 pairwise loss 46.689573
valid 634 RMSE 1.556277 Pearson 0.661965 Spearman 0.640659 avg pairwise AUC 0.936809
test  1296 RMSE 1.469109 Pearson 0.705148 Spearman 0.711608 avg pairwise AUC 0.947571
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.129375 affinity loss 0.506436 pairwise loss 46.229385
valid 634 RMSE 1.554874 Pearson 0.670519 Spearman 0.656027 avg pairwise AUC 0.936888
test  1296 RMSE 1.469109 Pearson 0.705148 Spearman 0.711608 avg pairwise AUC 0.947571
Finished Training
------------------------------
repeat 6 fold 4 begin
train num: 4949 valid num: 681 test num: 1359
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 1603.450231 affinity loss 12.452712 pairwise loss 15909.974365
train 4949 RMSE 1.702297 Pearson 0.542592 Spearman 0.562669 avg pairwise AUC 0.860813
valid 681 RMSE 2.008459 Pearson 0.579663 Spearman 0.589416 avg pairwise AUC 0.860998
test  1359 RMSE 1.737091 Pearson 0.573561 Spearman 0.586147 avg pairwise AUC 0.84562
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 12.983314 affinity loss 3.087125 pairwise loss 98.961888
valid 681 RMSE 2.108228 Pearson 0.633454 Spearman 0.644982 avg pairwise AUC 0.896368
test  1359 RMSE 1.737091 Pearson 0.573561 Spearman 0.586147 avg pairwise AUC 0.84562
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 11.679891 affinity loss 2.731008 pairwise loss 89.488835
valid 681 RMSE 1.997666 Pearson 0.658516 Spearman 0.672652 avg pairwise AUC 0.915579
test  1359 RMSE 1.726053 Pearson 0.648253 Spearman 0.65666 avg pairwise AUC 0.902608
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 10.929061 affinity loss 2.642936 pairwise loss 82.86125
valid 681 RMSE 1.838081 Pearson 0.668079 Spearman 0.680587 avg pairwise AUC 0.927286
test  1359 RMSE 1.722319 Pearson 0.661088 Spearman 0.66715 avg pairwise AUC 0.915674
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.165651 affinity loss 2.317221 pairwise loss 78.484301
valid 681 RMSE 1.83292 Pearson 0.693846 Spearman 0.703679 avg pairwise AUC 0.935204
test  1359 RMSE 1.620688 Pearson 0.672397 Spearman 0.677579 avg pairwise AUC 0.921677
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.850445 affinity loss 2.420005 pairwise loss 74.304402
valid 681 RMSE 1.796155 Pearson 0.688444 Spearman 0.70335 avg pairwise AUC 0.935697
test  1359 RMSE 1.553147 Pearson 0.67329 Spearman 0.680802 avg pairwise AUC 0.921458
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.337911 affinity loss 2.198958 pairwise loss 71.389521
valid 681 RMSE 1.742216 Pearson 0.69124 Spearman 0.707493 avg pairwise AUC 0.940393
test  1359 RMSE 1.522017 Pearson 0.674207 Spearman 0.677097 avg pairwise AUC 0.926154
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 8.888854 affinity loss 1.989831 pairwise loss 68.990235
valid 681 RMSE 1.70959 Pearson 0.729223 Spearman 0.738093 avg pairwise AUC 0.942121
test  1359 RMSE 1.529128 Pearson 0.689348 Spearman 0.69462 avg pairwise AUC 0.928278
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.59034 affinity loss 1.919661 pairwise loss 66.706787
valid 681 RMSE 1.670087 Pearson 0.726663 Spearman 0.741317 avg pairwise AUC 0.941931
test  1359 RMSE 1.479128 Pearson 0.698034 Spearman 0.705027 avg pairwise AUC 0.927359
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.353447 affinity loss 1.892642 pairwise loss 64.608046
valid 681 RMSE 1.560537 Pearson 0.741735 Spearman 0.749845 avg pairwise AUC 0.941591
test  1359 RMSE 1.505951 Pearson 0.6821 Spearman 0.685958 avg pairwise AUC 0.928008
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.028661 affinity loss 1.751034 pairwise loss 62.776275
train 4949 RMSE 1.197792 Pearson 0.809544 Spearman 0.815531 avg pairwise AUC 0.974618
valid 681 RMSE 1.664092 Pearson 0.740536 Spearman 0.749808 avg pairwise AUC 0.944437
test  1359 RMSE 1.505951 Pearson 0.6821 Spearman 0.685958 avg pairwise AUC 0.928008
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 7.750714 affinity loss 1.59921 pairwise loss 61.515038
valid 681 RMSE 1.600522 Pearson 0.73274 Spearman 0.741003 avg pairwise AUC 0.944775
test  1359 RMSE 1.505951 Pearson 0.6821 Spearman 0.685958 avg pairwise AUC 0.928008
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.773902 affinity loss 1.623266 pairwise loss 61.50636
valid 681 RMSE 1.70003 Pearson 0.760231 Spearman 0.772153 avg pairwise AUC 0.945655
test  1359 RMSE 1.505951 Pearson 0.6821 Spearman 0.685958 avg pairwise AUC 0.928008
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.492618 affinity loss 1.500229 pairwise loss 59.923887
valid 681 RMSE 1.609278 Pearson 0.760924 Spearman 0.769335 avg pairwise AUC 0.947217
test  1359 RMSE 1.505951 Pearson 0.6821 Spearman 0.685958 avg pairwise AUC 0.928008
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.217875 affinity loss 1.313674 pairwise loss 59.042005
valid 681 RMSE 1.506182 Pearson 0.761375 Spearman 0.768883 avg pairwise AUC 0.945977
test  1359 RMSE 1.506136 Pearson 0.705143 Spearman 0.704537 avg pairwise AUC 0.932311
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.105814 affinity loss 1.277584 pairwise loss 58.282296
valid 681 RMSE 1.604596 Pearson 0.764079 Spearman 0.773099 avg pairwise AUC 0.946138
test  1359 RMSE 1.506136 Pearson 0.705143 Spearman 0.704537 avg pairwise AUC 0.932311
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 6.997874 affinity loss 1.294994 pairwise loss 57.0288
valid 681 RMSE 1.531904 Pearson 0.751857 Spearman 0.766463 avg pairwise AUC 0.947834
test  1359 RMSE 1.506136 Pearson 0.705143 Spearman 0.704537 avg pairwise AUC 0.932311
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.789655 affinity loss 1.173425 pairwise loss 56.162302
valid 681 RMSE 1.478167 Pearson 0.770552 Spearman 0.77497 avg pairwise AUC 0.948332
test  1359 RMSE 1.477303 Pearson 0.699043 Spearman 0.691262 avg pairwise AUC 0.934112
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.686353 affinity loss 1.086557 pairwise loss 55.997953
valid 681 RMSE 1.614868 Pearson 0.782638 Spearman 0.788038 avg pairwise AUC 0.948716
test  1359 RMSE 1.477303 Pearson 0.699043 Spearman 0.691262 avg pairwise AUC 0.934112
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.212386 affinity loss 0.931651 pairwise loss 52.807345
valid 681 RMSE 1.478921 Pearson 0.774237 Spearman 0.784692 avg pairwise AUC 0.949317
test  1359 RMSE 1.477303 Pearson 0.699043 Spearman 0.691262 avg pairwise AUC 0.934112
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 5.934241 affinity loss 0.83392 pairwise loss 51.003218
train 4949 RMSE 0.828111 Pearson 0.908641 Spearman 0.910582 avg pairwise AUC 0.988319
valid 681 RMSE 1.53334 Pearson 0.759207 Spearman 0.772923 avg pairwise AUC 0.949348
test  1359 RMSE 1.477303 Pearson 0.699043 Spearman 0.691262 avg pairwise AUC 0.934112
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.811489 affinity loss 0.777589 pairwise loss 50.338993
valid 681 RMSE 1.451106 Pearson 0.77979 Spearman 0.78723 avg pairwise AUC 0.95057
test  1359 RMSE 1.455459 Pearson 0.709096 Spearman 0.710423 avg pairwise AUC 0.936036
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.737458 affinity loss 0.769695 pairwise loss 49.677627
valid 681 RMSE 1.590856 Pearson 0.778955 Spearman 0.787464 avg pairwise AUC 0.950177
test  1359 RMSE 1.455459 Pearson 0.709096 Spearman 0.710423 avg pairwise AUC 0.936036
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.598821 affinity loss 0.702045 pairwise loss 48.967764
valid 681 RMSE 1.429512 Pearson 0.785237 Spearman 0.792736 avg pairwise AUC 0.949824
test  1359 RMSE 1.433585 Pearson 0.721683 Spearman 0.719981 avg pairwise AUC 0.935632
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.531436 affinity loss 0.691522 pairwise loss 48.39914
valid 681 RMSE 1.509289 Pearson 0.773204 Spearman 0.781416 avg pairwise AUC 0.950642
test  1359 RMSE 1.433585 Pearson 0.721683 Spearman 0.719981 avg pairwise AUC 0.935632
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.436437 affinity loss 0.633036 pairwise loss 48.034012
valid 681 RMSE 1.586155 Pearson 0.774561 Spearman 0.780938 avg pairwise AUC 0.950265
test  1359 RMSE 1.433585 Pearson 0.721683 Spearman 0.719981 avg pairwise AUC 0.935632
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.384052 affinity loss 0.624453 pairwise loss 47.595982
valid 681 RMSE 1.466849 Pearson 0.786243 Spearman 0.787185 avg pairwise AUC 0.950916
test  1359 RMSE 1.433585 Pearson 0.721683 Spearman 0.719981 avg pairwise AUC 0.935632
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.288777 affinity loss 0.58689 pairwise loss 47.018861
valid 681 RMSE 1.451563 Pearson 0.781268 Spearman 0.78191 avg pairwise AUC 0.94984
test  1359 RMSE 1.433585 Pearson 0.721683 Spearman 0.719981 avg pairwise AUC 0.935632
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.230567 affinity loss 0.577448 pairwise loss 46.531188
valid 681 RMSE 1.462024 Pearson 0.777594 Spearman 0.773978 avg pairwise AUC 0.95046
test  1359 RMSE 1.433585 Pearson 0.721683 Spearman 0.719981 avg pairwise AUC 0.935632
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.151676 affinity loss 0.532153 pairwise loss 46.195229
valid 681 RMSE 1.501391 Pearson 0.773219 Spearman 0.787421 avg pairwise AUC 0.951096
test  1359 RMSE 1.433585 Pearson 0.721683 Spearman 0.719981 avg pairwise AUC 0.935632
Finished Training
------------------------------
repeat 6 fold 5 begin
train num: 4674 valid num: 694 test num: 1621
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 908.048209 affinity loss 6.067528 pairwise loss 9019.806562
train 4674 RMSE 1.952347 Pearson 0.593402 Spearman 0.598367 avg pairwise AUC 0.859947
valid 694 RMSE 1.940369 Pearson 0.521441 Spearman 0.540827 avg pairwise AUC 0.845687
test  1621 RMSE 1.824435 Pearson 0.584462 Spearman 0.583356 avg pairwise AUC 0.837916
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.050393 affinity loss 3.455483 pairwise loss 95.949095
valid 694 RMSE 1.773854 Pearson 0.548093 Spearman 0.575858 avg pairwise AUC 0.882095
test  1621 RMSE 1.833289 Pearson 0.553659 Spearman 0.569189 avg pairwise AUC 0.878153
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 11.682627 affinity loss 2.908559 pairwise loss 87.740673
valid 694 RMSE 1.902902 Pearson 0.547388 Spearman 0.580604 avg pairwise AUC 0.890346
test  1621 RMSE 1.833289 Pearson 0.553659 Spearman 0.569189 avg pairwise AUC 0.878153
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 10.934531 affinity loss 2.787906 pairwise loss 81.466251
valid 694 RMSE 1.728988 Pearson 0.552487 Spearman 0.593281 avg pairwise AUC 0.903472
test  1621 RMSE 1.715295 Pearson 0.592351 Spearman 0.602747 avg pairwise AUC 0.896436
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 9.988394 affinity loss 2.356871 pairwise loss 76.315238
valid 694 RMSE 1.61802 Pearson 0.588823 Spearman 0.616476 avg pairwise AUC 0.915536
test  1621 RMSE 1.556246 Pearson 0.609152 Spearman 0.622033 avg pairwise AUC 0.909365
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.66821 affinity loss 2.471562 pairwise loss 71.966483
valid 694 RMSE 1.610273 Pearson 0.598055 Spearman 0.617638 avg pairwise AUC 0.917715
test  1621 RMSE 1.600482 Pearson 0.609053 Spearman 0.614271 avg pairwise AUC 0.909964
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.215963 affinity loss 2.208894 pairwise loss 70.070682
valid 694 RMSE 1.680225 Pearson 0.582648 Spearman 0.609207 avg pairwise AUC 0.922093
test  1621 RMSE 1.600482 Pearson 0.609053 Spearman 0.614271 avg pairwise AUC 0.909964
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 8.767366 affinity loss 2.041696 pairwise loss 67.256694
valid 694 RMSE 1.592038 Pearson 0.615811 Spearman 0.635291 avg pairwise AUC 0.922389
test  1621 RMSE 1.524675 Pearson 0.642911 Spearman 0.651419 avg pairwise AUC 0.915135
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.484866 affinity loss 1.907275 pairwise loss 65.77591
valid 694 RMSE 1.831487 Pearson 0.616058 Spearman 0.64363 avg pairwise AUC 0.924745
test  1621 RMSE 1.524675 Pearson 0.642911 Spearman 0.651419 avg pairwise AUC 0.915135
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.138644 affinity loss 1.752516 pairwise loss 63.861276
valid 694 RMSE 1.66018 Pearson 0.629587 Spearman 0.644406 avg pairwise AUC 0.923095
test  1621 RMSE 1.524675 Pearson 0.642911 Spearman 0.651419 avg pairwise AUC 0.915135
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 7.79998 affinity loss 1.592706 pairwise loss 62.072741
train 4674 RMSE 1.173651 Pearson 0.838469 Spearman 0.831777 avg pairwise AUC 0.973419
valid 694 RMSE 1.569674 Pearson 0.616471 Spearman 0.63268 avg pairwise AUC 0.927451
test  1621 RMSE 1.517536 Pearson 0.632765 Spearman 0.638351 avg pairwise AUC 0.917853
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 7.557654 affinity loss 1.493973 pairwise loss 60.636805
valid 694 RMSE 1.64018 Pearson 0.629079 Spearman 0.65679 avg pairwise AUC 0.926181
test  1621 RMSE 1.517536 Pearson 0.632765 Spearman 0.638351 avg pairwise AUC 0.917853
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.468067 affinity loss 1.48211 pairwise loss 59.859571
valid 694 RMSE 1.66318 Pearson 0.641204 Spearman 0.659918 avg pairwise AUC 0.929693
test  1621 RMSE 1.517536 Pearson 0.632765 Spearman 0.638351 avg pairwise AUC 0.917853
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.216221 affinity loss 1.37392 pairwise loss 58.423011
valid 694 RMSE 1.620031 Pearson 0.624778 Spearman 0.647927 avg pairwise AUC 0.929889
test  1621 RMSE 1.517536 Pearson 0.632765 Spearman 0.638351 avg pairwise AUC 0.917853
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.006415 affinity loss 1.278574 pairwise loss 57.278414
valid 694 RMSE 1.5593 Pearson 0.640732 Spearman 0.657512 avg pairwise AUC 0.928242
test  1621 RMSE 1.498368 Pearson 0.653317 Spearman 0.665129 avg pairwise AUC 0.918413
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 6.869325 affinity loss 1.265378 pairwise loss 56.039467
valid 694 RMSE 1.640307 Pearson 0.630964 Spearman 0.650516 avg pairwise AUC 0.927525
test  1621 RMSE 1.498368 Pearson 0.653317 Spearman 0.665129 avg pairwise AUC 0.918413
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 6.703637 affinity loss 1.140248 pairwise loss 55.633895
valid 694 RMSE 1.579648 Pearson 0.625516 Spearman 0.635356 avg pairwise AUC 0.929148
test  1621 RMSE 1.498368 Pearson 0.653317 Spearman 0.665129 avg pairwise AUC 0.918413
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.520627 affinity loss 1.07666 pairwise loss 54.439671
valid 694 RMSE 1.567154 Pearson 0.64342 Spearman 0.648654 avg pairwise AUC 0.930917
test  1621 RMSE 1.498368 Pearson 0.653317 Spearman 0.665129 avg pairwise AUC 0.918413
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.431018 affinity loss 1.067177 pairwise loss 53.638405
valid 694 RMSE 1.580164 Pearson 0.631454 Spearman 0.651902 avg pairwise AUC 0.927962
test  1621 RMSE 1.498368 Pearson 0.653317 Spearman 0.665129 avg pairwise AUC 0.918413
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 5.930578 affinity loss 0.867146 pairwise loss 50.634316
valid 694 RMSE 1.543387 Pearson 0.645244 Spearman 0.663007 avg pairwise AUC 0.932268
test  1621 RMSE 1.44107 Pearson 0.682641 Spearman 0.689131 avg pairwise AUC 0.920354
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 5.696542 affinity loss 0.788497 pairwise loss 49.080448
train 4674 RMSE 0.775284 Pearson 0.927297 Spearman 0.923222 avg pairwise AUC 0.98837
valid 694 RMSE 1.548596 Pearson 0.649227 Spearman 0.66329 avg pairwise AUC 0.93135
test  1621 RMSE 1.44107 Pearson 0.682641 Spearman 0.689131 avg pairwise AUC 0.920354
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.584313 affinity loss 0.753217 pairwise loss 48.310958
valid 694 RMSE 1.581087 Pearson 0.644348 Spearman 0.655847 avg pairwise AUC 0.929142
test  1621 RMSE 1.44107 Pearson 0.682641 Spearman 0.689131 avg pairwise AUC 0.920354
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.479276 affinity loss 0.707867 pairwise loss 47.71408
valid 694 RMSE 1.545965 Pearson 0.647314 Spearman 0.652477 avg pairwise AUC 0.93048
test  1621 RMSE 1.44107 Pearson 0.682641 Spearman 0.689131 avg pairwise AUC 0.920354
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.395254 affinity loss 0.658018 pairwise loss 47.372366
valid 694 RMSE 1.522409 Pearson 0.664128 Spearman 0.671233 avg pairwise AUC 0.931322
test  1621 RMSE 1.462016 Pearson 0.681316 Spearman 0.684878 avg pairwise AUC 0.919048
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.288481 affinity loss 0.640254 pairwise loss 46.482262
valid 694 RMSE 1.571942 Pearson 0.645388 Spearman 0.653373 avg pairwise AUC 0.930146
test  1621 RMSE 1.462016 Pearson 0.681316 Spearman 0.684878 avg pairwise AUC 0.919048
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.212677 affinity loss 0.602155 pairwise loss 46.105223
valid 694 RMSE 1.630743 Pearson 0.646637 Spearman 0.652327 avg pairwise AUC 0.930565
test  1621 RMSE 1.462016 Pearson 0.681316 Spearman 0.684878 avg pairwise AUC 0.919048
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.118427 affinity loss 0.575115 pairwise loss 45.433123
valid 694 RMSE 1.571758 Pearson 0.653513 Spearman 0.664735 avg pairwise AUC 0.93012
test  1621 RMSE 1.462016 Pearson 0.681316 Spearman 0.684878 avg pairwise AUC 0.919048
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.067131 affinity loss 0.570338 pairwise loss 44.967931
valid 694 RMSE 1.584802 Pearson 0.640462 Spearman 0.645695 avg pairwise AUC 0.930606
test  1621 RMSE 1.462016 Pearson 0.681316 Spearman 0.684878 avg pairwise AUC 0.919048
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 4.954792 affinity loss 0.511659 pairwise loss 44.431332
valid 694 RMSE 1.616243 Pearson 0.631781 Spearman 0.647201 avg pairwise AUC 0.929376
test  1621 RMSE 1.462016 Pearson 0.681316 Spearman 0.684878 avg pairwise AUC 0.919048
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 4.899251 affinity loss 0.50348 pairwise loss 43.957714
valid 694 RMSE 1.584191 Pearson 0.648445 Spearman 0.657909 avg pairwise AUC 0.930581
test  1621 RMSE 1.462016 Pearson 0.681316 Spearman 0.684878 avg pairwise AUC 0.919048
Finished Training
------------------------------
fold avg performance [1.46684081 0.70083363 0.70365761 0.93511971]
/home/junseok/workspace/monn/src/pdbbind_utils.py:198: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  data_pack = [np.array(data) for data in data_pack]
setting: new_compound
fold 0 train  4988 test  1296 valid  705
fold 1 train  4911 test  1494 valid  584
fold 2 train  4688 test  1600 valid  701
fold 3 train  4992 test  1303 valid  694
fold 4 train  4988 test  1296 valid  705
repeat 7 fold 1 begin
train num: 4988 valid num: 705 test num: 1296
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 883.278101 affinity loss 22.248837 pairwise loss 8610.292066
train 4988 RMSE 1.80845 Pearson 0.592923 Spearman 0.600149 avg pairwise AUC 0.851032
valid 705 RMSE 1.886945 Pearson 0.584248 Spearman 0.609758 avg pairwise AUC 0.834611
test  1296 RMSE 1.993692 Pearson 0.540354 Spearman 0.571135 avg pairwise AUC 0.848538
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.087144 affinity loss 3.034692 pairwise loss 100.524522
valid 705 RMSE 1.632533 Pearson 0.598436 Spearman 0.617057 avg pairwise AUC 0.880672
test  1296 RMSE 1.763594 Pearson 0.567688 Spearman 0.592725 avg pairwise AUC 0.891472
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 11.871125 affinity loss 2.692045 pairwise loss 91.790806
valid 705 RMSE 1.589049 Pearson 0.62231 Spearman 0.646189 avg pairwise AUC 0.901404
test  1296 RMSE 1.725016 Pearson 0.591949 Spearman 0.623591 avg pairwise AUC 0.912793
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 11.155693 affinity loss 2.659751 pairwise loss 84.959423
valid 705 RMSE 1.545177 Pearson 0.642776 Spearman 0.663577 avg pairwise AUC 0.909746
test  1296 RMSE 1.696536 Pearson 0.608982 Spearman 0.637196 avg pairwise AUC 0.921974
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.632241 affinity loss 2.509665 pairwise loss 81.22576
valid 705 RMSE 2.264667 Pearson 0.658788 Spearman 0.677775 avg pairwise AUC 0.911203
test  1296 RMSE 1.696536 Pearson 0.608982 Spearman 0.637196 avg pairwise AUC 0.921974
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 10.010329 affinity loss 2.380192 pairwise loss 76.301366
valid 705 RMSE 1.507129 Pearson 0.65929 Spearman 0.675026 avg pairwise AUC 0.917565
test  1296 RMSE 1.641827 Pearson 0.6333 Spearman 0.664001 avg pairwise AUC 0.930186
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.432084 affinity loss 2.133671 pairwise loss 72.984129
valid 705 RMSE 1.745763 Pearson 0.663224 Spearman 0.679555 avg pairwise AUC 0.921564
test  1296 RMSE 1.641827 Pearson 0.6333 Spearman 0.664001 avg pairwise AUC 0.930186
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.034409 affinity loss 2.004894 pairwise loss 70.295147
valid 705 RMSE 1.580694 Pearson 0.634028 Spearman 0.643754 avg pairwise AUC 0.92503
test  1296 RMSE 1.641827 Pearson 0.6333 Spearman 0.664001 avg pairwise AUC 0.930186
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.678146 affinity loss 1.889431 pairwise loss 67.887141
valid 705 RMSE 1.503362 Pearson 0.671969 Spearman 0.674344 avg pairwise AUC 0.925717
test  1296 RMSE 1.591838 Pearson 0.667116 Spearman 0.694343 avg pairwise AUC 0.938423
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.317469 affinity loss 1.7135 pairwise loss 66.039683
valid 705 RMSE 1.520505 Pearson 0.673092 Spearman 0.682804 avg pairwise AUC 0.923511
test  1296 RMSE 1.591838 Pearson 0.667116 Spearman 0.694343 avg pairwise AUC 0.938423
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.206163 affinity loss 1.744751 pairwise loss 64.614116
train 4988 RMSE 1.480236 Pearson 0.831217 Spearman 0.830687 avg pairwise AUC 0.972508
valid 705 RMSE 1.788656 Pearson 0.667927 Spearman 0.67768 avg pairwise AUC 0.927483
test  1296 RMSE 1.591838 Pearson 0.667116 Spearman 0.694343 avg pairwise AUC 0.938423
learning rate: 0.0005
epoch 11 batch 0
epoch 11 batch 100
epoch: 11 total loss 7.901548 affinity loss 1.583096 pairwise loss 63.184516
valid 705 RMSE 1.543658 Pearson 0.689544 Spearman 0.700805 avg pairwise AUC 0.927184
test  1296 RMSE 1.591838 Pearson 0.667116 Spearman 0.694343 avg pairwise AUC 0.938423
learning rate: 0.0005
epoch 12 batch 0
epoch 12 batch 100
epoch: 12 total loss 7.651196 affinity loss 1.439983 pairwise loss 62.112135
valid 705 RMSE 1.56321 Pearson 0.69401 Spearman 0.698573 avg pairwise AUC 0.927607
test  1296 RMSE 1.591838 Pearson 0.667116 Spearman 0.694343 avg pairwise AUC 0.938423
learning rate: 0.0005
epoch 13 batch 0
epoch 13 batch 100
epoch: 13 total loss 7.467408 affinity loss 1.345542 pairwise loss 61.218663
valid 705 RMSE 1.411267 Pearson 0.713651 Spearman 0.718373 avg pairwise AUC 0.927739
test  1296 RMSE 1.534296 Pearson 0.693413 Spearman 0.708927 avg pairwise AUC 0.94143
learning rate: 0.0005
epoch 14 batch 0
epoch 14 batch 100
epoch: 14 total loss 7.296159 affinity loss 1.272832 pairwise loss 60.233264
valid 705 RMSE 1.488313 Pearson 0.678486 Spearman 0.685199 avg pairwise AUC 0.930557
test  1296 RMSE 1.534296 Pearson 0.693413 Spearman 0.708927 avg pairwise AUC 0.94143
learning rate: 0.0005
epoch 15 batch 0
epoch 15 batch 100
epoch: 15 total loss 7.093124 affinity loss 1.212707 pairwise loss 58.804171
valid 705 RMSE 1.466956 Pearson 0.683999 Spearman 0.693004 avg pairwise AUC 0.928537
test  1296 RMSE 1.534296 Pearson 0.693413 Spearman 0.708927 avg pairwise AUC 0.94143
learning rate: 0.0005
epoch 16 batch 0
epoch 16 batch 100
epoch: 16 total loss 6.964298 affinity loss 1.177537 pairwise loss 57.867613
valid 705 RMSE 1.581282 Pearson 0.703373 Spearman 0.711599 avg pairwise AUC 0.930652
test  1296 RMSE 1.534296 Pearson 0.693413 Spearman 0.708927 avg pairwise AUC 0.94143
learning rate: 0.0005
epoch 17 batch 0
epoch 17 batch 100
epoch: 17 total loss 6.836393 affinity loss 1.136093 pairwise loss 57.003001
valid 705 RMSE 1.528128 Pearson 0.694213 Spearman 0.700487 avg pairwise AUC 0.930837
test  1296 RMSE 1.534296 Pearson 0.693413 Spearman 0.708927 avg pairwise AUC 0.94143
learning rate: 0.0005
epoch 18 batch 0
epoch 18 batch 100
epoch: 18 total loss 6.658357 affinity loss 1.10675 pairwise loss 55.516064
valid 705 RMSE 1.499111 Pearson 0.700742 Spearman 0.704147 avg pairwise AUC 0.930185
test  1296 RMSE 1.534296 Pearson 0.693413 Spearman 0.708927 avg pairwise AUC 0.94143
learning rate: 0.00025
epoch 19 batch 0
epoch 19 batch 100
epoch: 19 total loss 6.117448 affinity loss 0.863477 pairwise loss 52.539714
valid 705 RMSE 1.482304 Pearson 0.68972 Spearman 0.694167 avg pairwise AUC 0.93184
test  1296 RMSE 1.534296 Pearson 0.693413 Spearman 0.708927 avg pairwise AUC 0.94143
learning rate: 0.00025
epoch 20 batch 0
epoch 20 batch 100
epoch: 20 total loss 5.935995 affinity loss 0.804967 pairwise loss 51.310279
train 4988 RMSE 0.84845 Pearson 0.918518 Spearman 0.916407 avg pairwise AUC 0.98704
valid 705 RMSE 1.465748 Pearson 0.702419 Spearman 0.704985 avg pairwise AUC 0.932732
test  1296 RMSE 1.534296 Pearson 0.693413 Spearman 0.708927 avg pairwise AUC 0.94143
learning rate: 0.00025
epoch 21 batch 0
epoch 21 batch 100
epoch: 21 total loss 5.820126 affinity loss 0.751089 pairwise loss 50.690372
valid 705 RMSE 1.561557 Pearson 0.686457 Spearman 0.690689 avg pairwise AUC 0.933284
test  1296 RMSE 1.534296 Pearson 0.693413 Spearman 0.708927 avg pairwise AUC 0.94143
learning rate: 0.00025
epoch 22 batch 0
epoch 22 batch 100
epoch: 22 total loss 5.698573 affinity loss 0.712779 pairwise loss 49.857931
valid 705 RMSE 1.507757 Pearson 0.693188 Spearman 0.698459 avg pairwise AUC 0.933931
test  1296 RMSE 1.534296 Pearson 0.693413 Spearman 0.708927 avg pairwise AUC 0.94143
learning rate: 0.00025
epoch 23 batch 0
epoch 23 batch 100
epoch: 23 total loss 5.614709 affinity loss 0.695567 pairwise loss 49.191422
valid 705 RMSE 1.519643 Pearson 0.690077 Spearman 0.689835 avg pairwise AUC 0.932679
test  1296 RMSE 1.534296 Pearson 0.693413 Spearman 0.708927 avg pairwise AUC 0.94143
learning rate: 0.00025
epoch 24 batch 0
epoch 24 batch 100
epoch: 24 total loss 5.486378 affinity loss 0.627271 pairwise loss 48.591076
valid 705 RMSE 1.514807 Pearson 0.688974 Spearman 0.698204 avg pairwise AUC 0.933594
test  1296 RMSE 1.534296 Pearson 0.693413 Spearman 0.708927 avg pairwise AUC 0.94143
learning rate: 0.00025
epoch 25 batch 0
epoch 25 batch 100
epoch: 25 total loss 5.437549 affinity loss 0.645077 pairwise loss 47.924716
valid 705 RMSE 1.528455 Pearson 0.678738 Spearman 0.680615 avg pairwise AUC 0.93346
test  1296 RMSE 1.534296 Pearson 0.693413 Spearman 0.708927 avg pairwise AUC 0.94143
learning rate: 0.00025
epoch 26 batch 0
epoch 26 batch 100
epoch: 26 total loss 5.342144 affinity loss 0.592877 pairwise loss 47.492661
valid 705 RMSE 1.502638 Pearson 0.690299 Spearman 0.695888 avg pairwise AUC 0.932874
test  1296 RMSE 1.534296 Pearson 0.693413 Spearman 0.708927 avg pairwise AUC 0.94143
learning rate: 0.00025
epoch 27 batch 0
epoch 27 batch 100
epoch: 27 total loss 5.285848 affinity loss 0.57092 pairwise loss 47.149273
valid 705 RMSE 1.541052 Pearson 0.686564 Spearman 0.685544 avg pairwise AUC 0.934311
test  1296 RMSE 1.534296 Pearson 0.693413 Spearman 0.708927 avg pairwise AUC 0.94143
learning rate: 0.00025
epoch 28 batch 0
epoch 28 batch 100
epoch: 28 total loss 5.165219 affinity loss 0.518728 pairwise loss 46.464905
valid 705 RMSE 1.499124 Pearson 0.701222 Spearman 0.701588 avg pairwise AUC 0.935074
test  1296 RMSE 1.534296 Pearson 0.693413 Spearman 0.708927 avg pairwise AUC 0.94143
learning rate: 0.00025
epoch 29 batch 0
epoch 29 batch 100
epoch: 29 total loss 5.133424 affinity loss 0.539103 pairwise loss 45.943203
valid 705 RMSE 1.480618 Pearson 0.691112 Spearman 0.693696 avg pairwise AUC 0.933916
test  1296 RMSE 1.534296 Pearson 0.693413 Spearman 0.708927 avg pairwise AUC 0.94143
Finished Training
------------------------------
repeat 7 fold 2 begin
train num: 4911 valid num: 584 test num: 1494
atom dict size: 75 , bond dict size: 12 , word dict size: 21
total num params 2143245
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/junseok/miniconda3/envs/dti/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate: 0.0005
epoch 0 batch 0
epoch 0 batch 100
epoch: 0 total loss 2974.886133 affinity loss 13.620978 pairwise loss 29612.650591
train 4911 RMSE 1.700247 Pearson 0.567661 Spearman 0.578212 avg pairwise AUC 0.849637
valid 584 RMSE 1.731417 Pearson 0.541916 Spearman 0.562681 avg pairwise AUC 0.830423
test  1494 RMSE 1.76617 Pearson 0.527618 Spearman 0.550984 avg pairwise AUC 0.83103
learning rate: 0.0005
epoch 1 batch 0
epoch 1 batch 100
epoch: 1 total loss 13.135658 affinity loss 3.052112 pairwise loss 100.83546
valid 584 RMSE 1.679104 Pearson 0.569906 Spearman 0.576663 avg pairwise AUC 0.8824
test  1494 RMSE 1.676097 Pearson 0.582182 Spearman 0.589482 avg pairwise AUC 0.880351
learning rate: 0.0005
epoch 2 batch 0
epoch 2 batch 100
epoch: 2 total loss 11.965388 affinity loss 2.844168 pairwise loss 91.212195
valid 584 RMSE 1.722009 Pearson 0.572947 Spearman 0.612935 avg pairwise AUC 0.906397
test  1494 RMSE 1.676097 Pearson 0.582182 Spearman 0.589482 avg pairwise AUC 0.880351
learning rate: 0.0005
epoch 3 batch 0
epoch 3 batch 100
epoch: 3 total loss 11.234245 affinity loss 2.804589 pairwise loss 84.29656
valid 584 RMSE 1.590522 Pearson 0.615811 Spearman 0.635085 avg pairwise AUC 0.91453
test  1494 RMSE 1.65975 Pearson 0.599434 Spearman 0.609898 avg pairwise AUC 0.908575
learning rate: 0.0005
epoch 4 batch 0
epoch 4 batch 100
epoch: 4 total loss 10.499018 affinity loss 2.522258 pairwise loss 79.767593
valid 584 RMSE 1.56467 Pearson 0.634725 Spearman 0.650985 avg pairwise AUC 0.920108
test  1494 RMSE 1.615687 Pearson 0.622411 Spearman 0.631715 avg pairwise AUC 0.914035
learning rate: 0.0005
epoch 5 batch 0
epoch 5 batch 100
epoch: 5 total loss 9.97017 affinity loss 2.47773 pairwise loss 74.924391
valid 584 RMSE 1.521524 Pearson 0.660001 Spearman 0.669081 avg pairwise AUC 0.924847
test  1494 RMSE 1.593964 Pearson 0.638907 Spearman 0.646617 avg pairwise AUC 0.918145
learning rate: 0.0005
epoch 6 batch 0
epoch 6 batch 100
epoch: 6 total loss 9.53153 affinity loss 2.353334 pairwise loss 71.781966
valid 584 RMSE 1.603551 Pearson 0.641445 Spearman 0.653756 avg pairwise AUC 0.925902
test  1494 RMSE 1.593964 Pearson 0.638907 Spearman 0.646617 avg pairwise AUC 0.918145
learning rate: 0.0005
epoch 7 batch 0
epoch 7 batch 100
epoch: 7 total loss 9.082148 affinity loss 2.191264 pairwise loss 68.908847
valid 584 RMSE 1.562385 Pearson 0.680369 Spearman 0.690592 avg pairwise AUC 0.926848
test  1494 RMSE 1.593964 Pearson 0.638907 Spearman 0.646617 avg pairwise AUC 0.918145
learning rate: 0.0005
epoch 8 batch 0
epoch 8 batch 100
epoch: 8 total loss 8.702234 affinity loss 1.964292 pairwise loss 67.379421
valid 584 RMSE 1.738388 Pearson 0.654592 Spearman 0.66091 avg pairwise AUC 0.928907
test  1494 RMSE 1.593964 Pearson 0.638907 Spearman 0.646617 avg pairwise AUC 0.918145
learning rate: 0.0005
epoch 9 batch 0
epoch 9 batch 100
epoch: 9 total loss 8.486957 affinity loss 1.970047 pairwise loss 65.169106
valid 584 RMSE 1.483424 Pearson 0.68449 Spearman 0.69019 avg pairwise AUC 0.931771
test  1494 RMSE 1.53149 Pearson 0.667894 Spearman 0.668535 avg pairwise AUC 0.924868
learning rate: 0.0005
epoch 10 batch 0
epoch 10 batch 100
epoch: 10 total loss 8.122714 affinity loss 1.71416 pairwise loss 64.085533
train 4911 RMSE 1.170681 Pearson 0.819666 Spearman 0.822079 avg pairwise AUC 0.973581
